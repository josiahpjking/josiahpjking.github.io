<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Things | Josiah King</title>
    <link>https://josiahpjking.github.io/publication/</link>
      <atom:link href="https://josiahpjking.github.io/publication/index.xml" rel="self" type="application/rss+xml" />
    <description>Things</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 21 May 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://josiahpjking.github.io/img/icon-192.png</url>
      <title>Things</title>
      <link>https://josiahpjking.github.io/publication/</link>
    </image>
    
    <item>
      <title>Centering Predictors</title>
      <link>https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/</guid>
      <description>
&lt;script src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;!-- # Centering predictors in standard linear regression --&gt;
&lt;!-- It makes little difference whether you mean-center or standardise a predictor in your basic regression model. These are simple linear transformations of a predictor $x$, and it does nothing to the significance of our coefficients.   --&gt;
&lt;!-- It will, however, change the meaning, and significance, of the intercept term. Why? Because the intercept provides an estimated mean $y$ where $x = 0$, and by centering we are changing what being &#34;zero&#34; on $x$ means. Scaling (or &#34;standardising&#34;) a predictor does just the same as mean-centering, but also multiples the estimate of the coefficient for $x$ by the standard deviation of $x$ $(s_x)$, and this makes no difference to the statistical inferences made.   --&gt;
&lt;!-- Let&#39;s look at it in a nice little thought example.  --&gt;
&lt;div id=&#34;early-birds-introducing-a-silly-toy-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Early birds: Introducing a silly toy example&lt;/h2&gt;
&lt;p&gt;Suppose we are interested in evaluating the veracity of the idiom “the early bird catches the worm”. We observe 120 birds, noting down the time at which each one arrives in the garden, and then how many worms they have caught by the end of the day:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;!-- Our question can easily be thought about in terms of the linear model:  --&gt;
&lt;!-- $$ --&gt;
&lt;!-- \text{worms eaten} \sim \beta_0 + \beta_1 \cdot \text{arrival time} + \epsilon --&gt;
&lt;!-- $$ --&gt;
&lt;!-- Which can be added to our visualisation as in the below. Our estimate $\hat{\beta}_0$ is represented by the larger black point - where the line intersects the y-axis. Our estimate $\hat{\beta}_1$ is the increase in the height of the blue line associated with an increase of 1 on the x-axis.  --&gt;
&lt;!-- i.e.  --&gt;
&lt;!-- - $\hat{\beta}_0$: estimated number of worms caught by a bird that arrives at midnight.   --&gt;
&lt;!-- - $\hat{\beta}_1$: estimated number of additional worms caught for every hour later that a bird arrives (the slope of the line).  --&gt;
&lt;!-- We can mean-center, standardise, minimum-center, _anything_-center our predictor variable, without making any changes to our inferences about $\hat{\beta}_1$ or the overall fit of our model. When applying a linear transformation of this sort to an explanatory variable, we are simply changing &#34;what zero means&#34; on our x-axis. The model stays just the same (the slope of the line remains identical) as we essentially simply change the location of the y-axis relative to the bulk of the data (and so change the meaning of our intercept term $\hat{\beta}_0$.  --&gt;
&lt;!-- Note that standardising the predictor (bottom right plot) also changes what moving from 0 to 1 on the x-axis represents - in this case it now represents 1 standard deviation. In doing so, our estimate $\hat{\beta}_1$ is multiplied by the standard deviation of the predictor.  --&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-predictors-in-standard-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering predictors in standard regression&lt;/h2&gt;
&lt;p&gt;In our model&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; $  _0 + _1  + $, linear transformations of our predictor (such as mean-centering/standardising etc) make no difference to the estimated slope. They change the intercept estimate, because they change where “zero” is.
One way to think about this is changing where the y-axis cuts the x-axis - we are simply shifting it right/left-wards, and thus moving the intercept estimate (see the plots below, in which the data and regression model are indentical, but the intercept (larger black dot) is shifted according to what zero represents on the x-axis).
&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;!-- ## centering with an interaction --&gt;
&lt;!-- When we have interactions in our model, the logic of centering a predictor stays the same - we are moving &#34;where zero is&#34; - but the implications of this may initially seem more pronounced in our model summary.  --&gt;
&lt;!-- In the model $y \sim \beta_0 + \beta_1 \cdot x + \beta_2 \cdot x_2 + \beta_3 \cdot x \cdot x_2 + \epsilon$, mean centering $x$ alters what the estimate is for the $x_2$ coefficient $\beta_2$, because this is the estimated effect of $x_2$ _conditional upon $x = 0$._ Mean centering makes &#34;zero&#34; on $x$ represent the mean, so we now have the effect of $x_2$ conditional upon $x = \bar{x}$. The significance of the conditional $\beta_2$ term may change after applying a linear transformation to $x$, but that is because _the meaning of these $\beta_2$ also changes._  --&gt;
&lt;!-- The interaction remains the same (and as above, scaling will multiple estimates by $s_x$).  --&gt;
&lt;p&gt;When you have an interaction, applying a linear transformation to a predictor again makes no difference to our estimate of the interaction term. It will change the intercept and the conditional effect of the interacting variable, again because it changes “what zero means”.&lt;br /&gt;
You can see this intuition in the visualisation below, in which we have a continuous (arrival_time) &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; categorical (blackbird vs wren) interaction. The difference between blackbirds and wrens (distance between large black and large brown dots) “at zero” on x-axis is different depending on the transformation of x.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-predictors-in-mlm&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Centering predictors in MLM&lt;/h1&gt;
&lt;p&gt;Suppose that we had birds clustered into different gardens. The average arrival time varies between gardens (if you want some context for the example, imagine that we’re on an island and all the island birds nest in the forest in the center of the island. Some gardens are further away than others, so the average arrival time for birds in these gardens is later than those closer to the forest).&lt;/p&gt;
&lt;p&gt;There are two different mechanisms going on here, generally known as between and within effects. Gardens to which birds on average arrive later seem to result in a greater yield of worms (maybe the worms are slow to wake up and there are more of them around later in the day?). However, &lt;em&gt;within&lt;/em&gt; a given garden it would seem that the later a bird arrives the fewer worms they catch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we were &lt;em&gt;only&lt;/em&gt; interested in the between effects, we might be inclined to fit a linear regression with cluster robust variance estimates. If we are potentially interested in both, then we’ll likely want to use a mixed effects model.&lt;/p&gt;
&lt;p&gt;However, we have some options of how to fit our model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;random effect (re)&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
mod_re &amp;lt;- lmer(nworms~arrival_time+(1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Within&lt;/strong&gt;&lt;br /&gt;
We can group mean center, which essentially provides our “within” estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% 
  group_by(gardenid) %&amp;gt;%
  mutate(
    arrival_time_groupcentered = arrival_time - mean(arrival_time)
  )

mod_within &amp;lt;- lmer(nworms ~ arrival_time_groupcentered + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mundlak&lt;/strong&gt;
We can also specify our between effect, by including the group means. One possibility here is the “Mundlak” approach, in which the raw (not group-mean centered) predictor is included along with the group means&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% group_by(gardenid) %&amp;gt;%
  mutate(
    garden_m = mean(arrival_time)
  )

mod_mundlak &amp;lt;- lmer(nworms ~ arrival_time + garden_m + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Within-between&lt;/strong&gt;&lt;br /&gt;
We also have the “within-between” approach. The within-between model uses the group-mean centered values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod_withinbetween &amp;lt;- lmer(nworms ~ arrival_time_groupcentered + garden_m + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;model-estimates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model estimates&lt;/h3&gt;
&lt;p&gt;We’ve got similar estimates in all models for the within-group effect, but note that the between-group effect is quite different in the Mundlak and Within-between models. What exactly do they represent?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 6
##   name          intercept arrival_time garden_m sd_intercept sd_residual
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 re                31.3         -2.82    NA           8.90         2.33
## 2 within            11.9         -2.98    NA           2.66         2.33
## 3 mundlak            4.27        -2.98     4.09        0.983        2.33
## 4 withinbetween      4.27        -2.98     1.11        0.983        2.33&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mundlak-vs-within-between&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mundlak vs Within-between&lt;/h2&gt;
&lt;p&gt;To understand the difference in the estimates of the between effect for the Mundlak model and the Within-between model, let’s take a specific datapoint.
Bird number 21 arrived at her garden at 5am, but unfortunately caught zero worms:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the Mundlak model, the coefficient estimate for the group mean effect of 4.09 represents the answer to the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in the hypothetical world where Bird 21’s garden has an average arrival time of 4:10am, rather than the observed 3:10am, and Bird 21 continues to wake up at 5, how many more worms will she get?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can visualise this counterfactual scenario (in blue below), by increasing the mean arrival time for the garden by 1hr. The Mundlak between coefficient is the estimated difference between the actual predicted (red) and the counterfactual predicted (blue), assuming that Bird 21 &lt;strong&gt;doesn’t&lt;/strong&gt; change her arrival time.
&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The within-between model, on the other hand, provides the estimate for the group mean effect of 1.11, which assumes that an increase in the average arrival time for birds in the garden will also entail Bird 21’s arrival time increasing. So if Bird 21 continues to arrive at the same time relative to the other birds in that garden, and they all simply arrive an hour later, this is how many worms she gets.
It answers the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the hypothetical world where Bird 21’s garden has an average arrival time of 4:10am as opposed to the observed 3:10am (thereby Bird 21 would have an arrival time of 6am as opposed to the observed 5am), how many more worms will she get?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2021-05-21-centering-predictors/index.en_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;blah blah blah.&lt;br /&gt;
I just wanted to makes some plots really.&lt;/p&gt;
&lt;p&gt;For a (much) better discussion, see:
Bell, A., Fairbrother, M. &amp;amp; Jones, K. &lt;em&gt;Fixed and random effects models: making an informed choice.&lt;/em&gt; Qual Quant 53, 1051–1074 (2019). &lt;a href=&#34;https://doi.org/10.1007/s11135-018-0802-x&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s11135-018-0802-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Additionally, for a discussion on the limitations of using group means as a level-2 predictor, see Croon, M. A., &amp;amp; van Veldhoven, M. J. P. M. (2007). &lt;em&gt;Predicting group-level outcome variables from variables measured at the individual level: A latent variable multilevel model.&lt;/em&gt; Psychological Methods, 12(1), 45–57. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.12.1.45&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/1082-989X.12.1.45&lt;/a&gt; and the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/MicroMacroMultilevel/MicroMacroMultilevel.pdf&#34;&gt;MicroMacroMultilevel&lt;/a&gt; which provides the functionality to calculate adjusted group means to include as predictors of group-level outcomes.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Let’s just ignore the fact that we should possibly be fitting a poisson regression here.. &lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Many labs 5: replication of Crosby, Moni &amp; Richardson 2008.</title>
      <link>https://josiahpjking.github.io/publication/many-labs-5-crosby-monin-richardson/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/many-labs-5-crosby-monin-richardson/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Many labs 5: replication of Crosby, Moni &amp; Richardson 2008.</title>
      <link>https://josiahpjking.github.io/publication/many-labs-5/</link>
      <pubDate>Fri, 13 Nov 2020 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/many-labs-5/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interpreting nonverbal cues to deception in real time</title>
      <link>https://josiahpjking.github.io/publication/interpreting-nonverbal-cues-to-deception-in-real-time/</link>
      <pubDate>Mon, 09 Mar 2020 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/interpreting-nonverbal-cues-to-deception-in-real-time/</guid>
      <description></description>
    </item>
    
    <item>
      <title>&#39;Sometimes a scream is better than a thesis&#39;</title>
      <link>https://josiahpjking.github.io/publication/thesis-metadata/</link>
      <pubDate>Wed, 16 Oct 2019 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/thesis-metadata/</guid>
      <description>&lt;br /&gt;
Back in the middle of the second year of my PhD (by which point I’d written a small amount already), I thought it would be fun to track my wordcount over the course of writing up (this was really just a means of procrastinating one morning instead of writing). Having finally finished it all, I figured that I should make a few quick plots, and take some time to look back on the process.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;font size=&#34;2&#34;,style=&#34;margin:5px&#34;&gt; &lt;strong&gt;DISCLAIMER&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;There’s a point which can’t be made strongly enough about a thesis: &lt;strong&gt;quality &amp;gt; quantity&lt;/strong&gt;. If you’re starting out/in the midst of your PhD, I would encourage you not to get too fixated on the wordcount of your thesis. The number of words you write can be a pretty useless metric of progress. For that purpose, I have omitted any specific numbers of words and timescales from this blogpost, to avoid anyone from drawing comparisons between their own progress and mine. All PhDs are different - don’t compare yourself too much to others.&lt;br /&gt;
By the end of it, I’m not sure that my thesis had either quality or quantity, and instead I would probably offer up different benchmarks of PhD success: 1) Learning things, and 2) Having fun. Provided you come out of the other end feeling that you’ve done those two things at least occasionally during your PhD, then you’ve probably done okay.&lt;br /&gt;
&lt;/font&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;With that out of the way, let’s push on and see what happens…&lt;br /&gt;
I set up the word counting using crontab to execute a bash script every day which saved the date and output of texcount into a .txt file. This meant I ended up with daily records of the words in each chapter, so I could work out thing such as how many words were added on each day.&lt;/p&gt;
&lt;p&gt;First though, let’s just take a look at how the total word count of the thesis grew.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/post/2019-09-16-thesis-metadata_files/figure-html/plot1-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The first thing to note (not a huge surprise to me, or anyone) is that writing is fairly slow-going. There are some gaps where I was doing an internship (I had high hopes of being motivated and continuing to work on the thesis during this period, but that just didn’t happen), and a smaller one for Christmas, but other than that it’s fairly steady, and not that steep (although you won’t be able to tell that from the absence of axis labels!). I can retrofit certain memorable feelings that I had, for instance the panic writing which resulted from being offered a job. You can see all this in the figure above. For context, I’ve added some of the key life events for me (that was a pretty big year!), as well as the various jobs I was doing along the bottom.&lt;/p&gt;
&lt;p&gt;I also recorded the wordcounts split up by the chapters which I was working on. At the start I imagined that there I would devote definite periods to different chapters, but in reality the process was quite skittish (see below - what a mess!). I seemed to switch between working on different chapters pretty frequently (46% of the days on which I actually did &lt;em&gt;some&lt;/em&gt; writing/editing, I did so in more than one chapter). I think this probably reflects various attempts to avoid dealing with problems by working on something else!&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/post/2019-09-16-thesis-metadata_files/figure-html/plot2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I can also take a look at which days of the week I worked, and how many words were added/removed on each day. Some of this fits with how it felt when I was writing. I remember noting that I’d spend more time editing and deleting stuff on the Monday, and that Tuesday was a day for adding new content. The figure below shows the addition of content for each day of the week, excluding days that I did not do any work (the vertical dashed line is zero).&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/post/2019-09-16-thesis-metadata_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;so-what&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;So what?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Take home message&lt;/strong&gt;: Don’t count your words. You’ll get some nice plots, but they won’t really mean anything. PhD’s can be a long long process, and a thesis will be finished (to quote my mother when asked at what time dinner would be) “whenever it’s ready”.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What&#39;s driving Scotland&#39;s falling reconviction rate?</title>
      <link>https://josiahpjking.github.io/publication/reconvictions-blog/</link>
      <pubDate>Mon, 05 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/reconvictions-blog/</guid>
      <description></description>
    </item>
    
    <item>
      <title>DasGuptR - R package for implementation of Prithwis Das Gupta&#39;s 1993 standardisation and decomposition of rates</title>
      <link>https://josiahpjking.github.io/publication/dasguptr/</link>
      <pubDate>Thu, 01 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/dasguptr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contextual effects on online pragmatic inferences of deception</title>
      <link>https://josiahpjking.github.io/publication/contextual-effects-on-online-pragmatic-inferences-to-deception/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/contextual-effects-on-online-pragmatic-inferences-to-deception/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Scottish Crime and Justice Survey Shiny App</title>
      <link>https://josiahpjking.github.io/publication/scottish-crime-justice-survey-shiny/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/scottish-crime-justice-survey-shiny/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
