<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>model | Josiah King</title>
    <link>https://josiahpjking.github.io/tags/model/</link>
      <atom:link href="https://josiahpjking.github.io/tags/model/index.xml" rel="self" type="application/rss+xml" />
    <description>model</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Fri, 21 May 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://josiahpjking.github.io/img/icon-192.png</url>
      <title>model</title>
      <link>https://josiahpjking.github.io/tags/model/</link>
    </image>
    
    <item>
      <title>Centering Predictors</title>
      <link>https://josiahpjking.github.io/publication/2020-05-21-centering-predictors/</link>
      <pubDate>Fri, 21 May 2021 00:00:00 +0000</pubDate>
      <guid>https://josiahpjking.github.io/publication/2020-05-21-centering-predictors/</guid>
      <description>
&lt;script src=&#34;https://josiahpjking.github.io/rmarkdown-libs/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;!-- # Centering predictors in standard linear regression --&gt;
&lt;!-- It makes little difference whether you mean-center or standardise a predictor in your basic regression model. These are simple linear transformations of a predictor $x$, and it does nothing to the significance of our coefficients.   --&gt;
&lt;!-- It will, however, change the meaning, and significance, of the intercept term. Why? Because the intercept provides an estimated mean $y$ where $x = 0$, and by centering we are changing what being &#34;zero&#34; on $x$ means. Scaling (or &#34;standardising&#34;) a predictor does just the same as mean-centering, but also multiples the estimate of the coefficient for $x$ by the standard deviation of $x$ $(s_x)$, and this makes no difference to the statistical inferences made.   --&gt;
&lt;!-- Let&#39;s look at it in a nice little thought example.  --&gt;
&lt;div id=&#34;early-birds-introducing-a-silly-toy-example&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Early birds: Introducing a silly toy example&lt;/h2&gt;
&lt;p&gt;Suppose we are interested in evaluating the veracity of the idiom “the early bird catches the worm”. We observe 120 birds, noting down the time at which each one arrives in the garden, and then how many worms they have caught by the end of the day:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;!-- Our question can easily be thought about in terms of the linear model:  --&gt;
&lt;!-- $$ --&gt;
&lt;!-- \text{worms eaten} \sim \beta_0 + \beta_1 \cdot \text{arrival time} + \epsilon --&gt;
&lt;!-- $$ --&gt;
&lt;!-- Which can be added to our visualisation as in the below. Our estimate $\hat{\beta}_0$ is represented by the larger black point - where the line intersects the y-axis. Our estimate $\hat{\beta}_1$ is the increase in the height of the blue line associated with an increase of 1 on the x-axis.  --&gt;
&lt;!-- i.e.  --&gt;
&lt;!-- - $\hat{\beta}_0$: estimated number of worms caught by a bird that arrives at midnight.   --&gt;
&lt;!-- - $\hat{\beta}_1$: estimated number of additional worms caught for every hour later that a bird arrives (the slope of the line).  --&gt;
&lt;!-- We can mean-center, standardise, minimum-center, _anything_-center our predictor variable, without making any changes to our inferences about $\hat{\beta}_1$ or the overall fit of our model. When applying a linear transformation of this sort to an explanatory variable, we are simply changing &#34;what zero means&#34; on our x-axis. The model stays just the same (the slope of the line remains identical) as we essentially simply change the location of the y-axis relative to the bulk of the data (and so change the meaning of our intercept term $\hat{\beta}_0$.  --&gt;
&lt;!-- Note that standardising the predictor (bottom right plot) also changes what moving from 0 to 1 on the x-axis represents - in this case it now represents 1 standard deviation. In doing so, our estimate $\hat{\beta}_1$ is multiplied by the standard deviation of the predictor.  --&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-predictors-in-standard-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering predictors in standard regression&lt;/h2&gt;
&lt;p&gt;In our model&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; $  _0 + _1  + $, linear transformations of our predictor (such as mean-centering/standardising etc) make no difference to the estimated slope. They change the intercept estimate, because they change where “zero” is.
One way to think about this is changing where the y-axis cuts the x-axis - we are simply shifting it right/left-wards, and thus moving the intercept estimate (see the plots below, in which the data and regression model are indentical, but the intercept (larger black dot) is shifted according to what zero represents on the x-axis).
&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;!-- ## centering with an interaction --&gt;
&lt;!-- When we have interactions in our model, the logic of centering a predictor stays the same - we are moving &#34;where zero is&#34; - but the implications of this may initially seem more pronounced in our model summary.  --&gt;
&lt;!-- In the model $y \sim \beta_0 + \beta_1 \cdot x + \beta_2 \cdot x_2 + \beta_3 \cdot x \cdot x_2 + \epsilon$, mean centering $x$ alters what the estimate is for the $x_2$ coefficient $\beta_2$, because this is the estimated effect of $x_2$ _conditional upon $x = 0$._ Mean centering makes &#34;zero&#34; on $x$ represent the mean, so we now have the effect of $x_2$ conditional upon $x = \bar{x}$. The significance of the conditional $\beta_2$ term may change after applying a linear transformation to $x$, but that is because _the meaning of these $\beta_2$ also changes._  --&gt;
&lt;!-- The interaction remains the same (and as above, scaling will multiple estimates by $s_x$).  --&gt;
&lt;p&gt;When you have an interaction, applying a linear transformation to a predictor again makes no difference to our estimate of the interaction term. It will change the intercept and the conditional effect of the interacting variable, again because it changes “what zero means”.&lt;br /&gt;
You can see this intuition in the visualisation below, in which we have a continuous (arrival_time) &lt;span class=&#34;math inline&#34;&gt;\(\times\)&lt;/span&gt; categorical (blackbird vs wren) interaction. The difference between blackbirds and wrens (distance between large black and large brown dots) “at zero” on x-axis is different depending on the transformation of x.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;centering-predictors-in-mlm&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Centering predictors in MLM&lt;/h2&gt;
&lt;p&gt;Suppose that we had birds clustered into different gardens. The average arrival time varies between gardens (if you want some context for the example, imagine that we’re on an island and all the island birds nest in the forest in the center of the island. Some gardens are further away than others, so the average arrival time for birds in these gardens is later than those closer to the forest).&lt;/p&gt;
&lt;p&gt;There are two different mechanisms going on here, generally known as between and within effects. Gardens to which birds on average arrive later seem to result in a greater yield of worms (maybe the worms are slow to wake up and there are more of them around later in the day?). However, &lt;em&gt;within&lt;/em&gt; a given garden it would seem that the later a bird arrives the fewer worms they catch.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;If we were &lt;em&gt;only&lt;/em&gt; interested in the between effects, we might be inclined to fit a linear regression with cluster robust variance estimates. If we are potentially interested in both, then we’ll likely want to use a mixed effects model.&lt;/p&gt;
&lt;p&gt;However, we have some options of how to fit our model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;random effect (re)&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(lme4)
mod_re &amp;lt;- lmer(nworms~arrival_time+(1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Within&lt;/strong&gt;&lt;br /&gt;
We can group mean center, which essentially provides our “within” estimate:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% 
  group_by(gardenid) %&amp;gt;%
  mutate(
    arrival_time_groupcentered = arrival_time - mean(arrival_time)
  )

mod_within &amp;lt;- lmer(nworms ~ arrival_time_groupcentered + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Mundlak&lt;/strong&gt;
We can also specify our between effect, by including the group means. One possibility here is the “Mundlak” approach, in which the raw (not group-mean centered) predictor is included along with the group means&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df &amp;lt;- df %&amp;gt;% group_by(gardenid) %&amp;gt;%
  mutate(
    garden_m = mean(arrival_time)
  )

mod_mundlak &amp;lt;- lmer(nworms ~ arrival_time + garden_m + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Within-between&lt;/strong&gt;&lt;br /&gt;
We also have the “within-between” approach. The within-between model uses the group-mean centered values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mod_withinbetween &amp;lt;- lmer(nworms ~ arrival_time_groupcentered + garden_m + (1|gardenid), data=df)&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;div id=&#34;model-estimates&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Model estimates&lt;/h3&gt;
&lt;p&gt;We’ve got similar estimates in all models for the within-group effect, but note that the between-group effect is quite different in the Mundlak and Within-between models. What exactly do they represent?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 6
##   name          intercept arrival_time garden_m sd_intercept sd_residual
##   &amp;lt;chr&amp;gt;             &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 re                31.3         -2.82    NA           8.90         2.33
## 2 within            11.9         -2.98    NA           2.66         2.33
## 3 mundlak            4.27        -2.98     4.09        0.983        2.33
## 4 withinbetween      4.27        -2.98     1.11        0.983        2.33&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;mundlak-vs-within-between&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Mundlak vs Within-between&lt;/h2&gt;
&lt;p&gt;To understand the difference in the estimates of the between effect for the Mundlak model and the Within-between model, let’s take a specific datapoint.
Bird number 21 arrived at her garden at 5am, but unfortunately caught zero worms:&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In the Mundlak model, the coefficient estimate for the group mean effect of 4.09 represents the answer to the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in the hypothetical world where Bird 21’s garden has an average arrival time of 4:10am, rather than the observed 3:10am, and Bird 21 continues to wake up at 5, how many more worms will she get?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;We can visualise this counterfactual scenario (in blue below), by increasing the mean arrival time for the garden by 1hr. The Mundlak between coefficient is the estimated difference between the actual predicted (red) and the counterfactual predicted (blue), assuming that Bird 21 &lt;strong&gt;doesn’t&lt;/strong&gt; change her arrival time.
&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The within-between model, on the other hand, provides the estimate for the group mean effect of 1.11, which assumes that an increase in the average arrival time for birds in the garden will also entail Bird 21’s arrival time increasing. So if Bird 21 continues to arrive at the same time relative to the other birds in that garden, and they all simply arrive an hour later, this is how many worms she gets.
It answers the question:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;In the hypothetical world where Bird 21’s garden has an average arrival time of 4:10am as opposed to the observed 3:10am (thereby Bird 21 would have an arrival time of 6am as opposed to the observed 5am), how many more worms will she get?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://josiahpjking.github.io/publication/2020-05-21-centering-predictors_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;blah blah blah.&lt;br /&gt;
I just wanted to makes some plots really.&lt;/p&gt;
&lt;p&gt;For a (much) better discussion, see:
Bell, A., Fairbrother, M. &amp;amp; Jones, K. &lt;em&gt;Fixed and random effects models: making an informed choice.&lt;/em&gt; Qual Quant 53, 1051–1074 (2019). &lt;a href=&#34;https://doi.org/10.1007/s11135-018-0802-x&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1007/s11135-018-0802-x&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Additionally, for a discussion on the limitations of using group means as a level-2 predictor, see Croon, M. A., &amp;amp; van Veldhoven, M. J. P. M. (2007). &lt;em&gt;Predicting group-level outcome variables from variables measured at the individual level: A latent variable multilevel model.&lt;/em&gt; Psychological Methods, 12(1), 45–57. &lt;a href=&#34;https://doi.org/10.1037/1082-989X.12.1.45&#34; class=&#34;uri&#34;&gt;https://doi.org/10.1037/1082-989X.12.1.45&lt;/a&gt; and the R package &lt;a href=&#34;https://cran.r-project.org/web/packages/MicroMacroMultilevel/MicroMacroMultilevel.pdf&#34;&gt;MicroMacroMultilevel&lt;/a&gt; which provides the functionality to calculate adjusted group means to include as predictors of group-level outcomes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Let’s just ignore the fact that we should possibly be fitting a poisson regression here.. &lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
