

	####### B099078 R script #######

install.packages("psych")
[1] 1
install.packages("car")
[1] 2
install.packages("lm.beta")
[1] 3
install.packages("MASS")
[1] 4
install.packages("Hmsc")
[1] 5
install.packages("jtools")
[1] 6
install.packages("ggplot2")
[1] 7
install.packages("interactions")
[1] 8
install.packages("stats")
[1] 9
library(psych, quietly = T)
[1] 10
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 11
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(lm.beta, quietly = T)
[1] 12
 [1] "lm.beta"   "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"    
[10] "datasets"  "methods"   "base"     
library(Hmsc, quietly = T)
[1] 13
 [1] "Hmsc"      "coda"      "lm.beta"   "car"       "carData"   "psych"     "readr"     "stats"     "graphics" 
[10] "grDevices" "utils"     "datasets"  "methods"   "base"     
library(jtools, quietly = T)
[1] 14
 [1] "jtools"    "Hmsc"      "coda"      "lm.beta"   "car"       "carData"   "psych"     "readr"     "stats"    
[10] "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(ggplot2, quietly = T)
[1] 15
 [1] "ggplot2"   "jtools"    "Hmsc"      "coda"      "lm.beta"   "car"       "carData"   "psych"     "readr"    
[10] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 16
 [1] "interactions" "ggplot2"      "jtools"       "Hmsc"         "coda"         "lm.beta"      "car"         
 [8] "carData"      "psych"        "readr"        "stats"        "graphics"     "grDevices"    "utils"       
[15] "datasets"     "methods"      "base"        
library(stats, quietly = T)
[1] 17
 [1] "interactions" "ggplot2"      "jtools"       "Hmsc"         "coda"         "lm.beta"      "car"         
 [8] "carData"      "psych"        "readr"        "stats"        "graphics"     "grDevices"    "utils"       
[15] "datasets"     "methods"      "base"        
df <- read.csv("../RMS2_report_1920.csv")
[1] 18
df <- read.csv("../RMS2_report_1920.csv")
[1] 19
View(df)
[1] 20
df$training[df$training < 0 | df$training > 2]
[1] 21
integer(0)
df$feedback[df$feedback < 0 | df$feedback > 2]
[1] 22
integer(0)
df$incidents[df$incidents < 0 | df$incidents > 1]
[1] 23
numeric(0)
df$empathy[df$empathy <= 1 | df$incidents >= 20]
[1] 24
integer(0)
df$years[df$years <= 0 | df$years >= 30]
[1] 25
integer(0)
any(is.na(df))
[1] 26
[1] FALSE
str(df)
[1] 27
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
sapply(df, class)
[1] 28
  subject incidents  training  feedback   empathy     years 
"integer" "numeric" "integer" "integer" "integer" "integer" 
df$training <- as.factor(df$training)
[1] 29
df$feedback <- as.factor(df$feedback)
[1] 30
sapply(df, class)
[1] 31
  subject incidents  training  feedback   empathy     years 
"integer" "numeric"  "factor"  "factor" "integer" "integer" 
df$training <- factor(df$training, labels = c("No", "Yes"))
[1] 32
str(df$training)
[1] 33
 Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
NULL
df$feedback <- factor(df$feedback, labels = c("No", "Yes"))
[1] 34
str(df$feedback)
[1] 35
 Factor w/ 2 levels "No","Yes": 2 1 2 1 2 1 2 1 2 1 ...
NULL
summary(df$training)
[1] 36
 No Yes 
100 100 
summary(df$feedback)
[1] 37
 No Yes 
100 100 
str(df)
[1] 38
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "No","Yes": 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "No","Yes": 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
describe(df)
[1] 39
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training*    3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
summary(df)
[1] 40
    subject         incidents       training  feedback     empathy          years      
 Min.   :  1.00   Min.   :0.08333   No :100   No :100   Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 50.75   1st Qu.:0.33333   Yes:100   Yes:100   1st Qu.: 9.00   1st Qu.: 6.00  
 Median :100.50   Median :0.41667                       Median :10.00   Median : 8.00  
 Mean   :100.50   Mean   :0.47500                       Mean   :10.18   Mean   : 8.13  
 3rd Qu.:150.25   3rd Qu.:0.58333                       3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :200.00   Max.   :0.91667                       Max.   :16.00   Max.   :19.00  
png("~/Desktop/RMS/Coursework/Histogram Years.png")
[1] 41
hist(df$years, col = "lavenderblush4", xlab = "Years of Experience", 
    main = "Histogram Years of Experience")
[1] 42
dev.off()
[1] 43
png("~/Desktop/RMS/Coursework/Histogam Empathy.png")
[1] 44
hist(df$empathy, col = "lavenderblush4", xlab = "Empathy Score", 
    main = "Histogram Empathy Score")
[1] 45
dev.off()
[1] 46
png("~/Desktop/RMS/Coursework/Feedback boxplot.png")
[1] 47
plot(df$feedback, df$incidents, xlab = "Feedback", ylab = "Incidents", 
    main = "Histogram Feedback")
[1] 48
dev.off()
[1] 49
png("~/Desktop/RMS/Coursework/Training boxplot.png")
[1] 50
plot(df$training, df$incidents, xlab = "Training", ylab = "Incidents", 
    main = "Histogram Training")
[1] 51
dev.off()
[1] 52
m <- lm(scale(empathy) ~ scale(years), data = df)
[1] 53
summary(m)
[1] 54

Call:
lm(formula = scale(empathy) ~ scale(years), data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.419e-16  6.837e-02   0.000 1.000000    
scale(years)  2.640e-01  6.854e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

png("~/Desktop/RMS/Coursework/Q1 Model.png")
[1] 55
scatterplot(df$empathy ~ df$years)
[1] 56
dev.off()
[1] 57
cooksm <- cooks.distance(m)
[1] 58
which(cooksm > (4/(200 - 1 - 1)))
[1] 59
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
png("~/Desktop/RMS/Coursework/Q1 Cooks.png")
[1] 60
plot(m, 4)
[1] 61
dev.off()
[1] 62
ma <- lm(empathy ~ years, data = df[-c(88, 137, 154), ])
[1] 63
summary(lm.beta(ma))
[1] 64

Call:
lm(formula = empathy ~ years, data = df[-c(88, 137, 154), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-6.2211 -1.6555  0.0411  1.4756  5.7583 

Coefficients:
            Estimate Standardized Std. Error t value Pr(>|t|)    
(Intercept)  7.97944      0.00000    0.49438  16.140  < 2e-16 ***
years        0.28278      0.33072    0.05778   4.894 2.07e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.325 on 195 degrees of freedom
Multiple R-squared:  0.1094,	Adjusted R-squared:  0.1048 
F-statistic: 23.95 on 1 and 195 DF,  p-value: 2.068e-06

m_coef <- summary(lm.beta(m))
[1] 65
ma_coef <- summary(lm.beta(ma))
[1] 66
compare <- data.frame(round(m_coef$coefficients[, 2], 3), round(m_coef$coefficients[, 
    5], 4), round(ma_coef$coefficients[, 2], 3), round(ma_coef$coefficients[, 
    5], 4))
[1] 67
colnames(compare) <- c("M Coef", "M p-value", "Ma Coef", "Ma p-value")
[1] 68
print(compare)
[1] 69
             M Coef M p-value Ma Coef Ma p-value
(Intercept)   0.000     1e+00   0.000          0
scale(years)  0.264     2e-04   0.331          0
             M Coef M p-value Ma Coef Ma p-value
(Intercept)   0.000     1e+00   0.000          0
scale(years)  0.264     2e-04   0.331          0
png("~/Desktop/RMS/Coursework/Q1 Linearity.png")
[1] 70
crPlots(m)
[1] 71
dev.off()
[1] 72
png("~/Desktop/RMS/Coursework/Q1 Normality.png")
[1] 73
qqPlot(m, main = "QQ-plot", col.lines = "firebrick3")
[1] 74
png("~/Desktop/RMS/Coursework/Q1 Homoscedasticity.png")
[1] 75
residualPlots(m)
[1] 76
dev.off()
[1] 77
ncvTest(m)
[1] 78
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
durbinWatsonTest(m)
[1] 79
 lag Autocorrelation D-W Statistic p-value
   1       0.1017162      1.769879   0.118
 Alternative hypothesis: rho != 0
df$spoly <- (scale(df$years))^2
[1] 80
m1 <- lm(scale(df$empathy) ~ scale(df$years) + df$spoly)
[1] 81
summary(m1)
[1] 82

Call:
lm(formula = scale(df$empathy) ~ scale(df$years) + df$spoly)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)      0.38537    0.06599   5.840 2.13e-08 ***
scale(df$years)  0.46511    0.05824   7.986 1.13e-13 ***
df$spoly        -0.38731    0.03685 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

cooksm1 <- cooks.distance(m1)
[1] 83
which(cooksm1 > (4/(200 - 1 - 1)))
[1] 84
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
png("~/Desktop/RMS/Coursework/Q1 PolyCooks.png")
[1] 85
plot(m1, 4)
[1] 86
dev.off()
[1] 87
png("~/Desktop/RMS/Coursework/Q1 PolyLinearity.png")
[1] 88
crPlots(m1)
[1] 89
dev.off()
[1] 90
png("~/Desktop/RMS/Coursework/Q1 PolyNormality.png")
[1] 91
qqPlot(m1, main = "QQ-plot", col.lines = "firebrick3")
[1] 92
dev.off()
[1] 93
png("~/Desktop/RMS/Coursework/Q1 PolyHomoscedasticity.png")
[1] 94
residualPlots(m1)
[1] 95
dev.off()
[1] 96
ncvTest(m1)
[1] 97
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(m1)
[1] 98
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.864
 Alternative hypothesis: rho != 0
m1a <- lm(scale(df$empathy) ~ scale(df$years) + df$spoly, data = df[-c(89, 
    154, 175), ])
[1] 99
summary(lm.beta(m1a))
[1] 100

Call:
lm(formula = scale(df$empathy) ~ scale(df$years) + df$spoly, 
    data = df[-c(89, 154, 175), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
                Estimate Standardized Std. Error t value Pr(>|t|)    
(Intercept)      0.38537      0.00000    0.06599   5.840 2.13e-08 ***
scale(df$years)  0.46511      0.46511    0.05824   7.986 1.13e-13 ***
df$spoly        -0.38731     -0.61210    0.03685 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

m1_coef <- summary(lm.beta(m1))
[1] 101
m1a_coef <- summary(lm.beta(m1a))
[1] 102
compare1 <- data.frame(round(m1_coef$coefficients[, 2], 3), round(m1_coef$coefficients[, 
    5], 4), round(m1a_coef$coefficients[, 2], 3), round(m1a_coef$coefficients[, 
    5], 4))
[1] 103
colnames(compare1) <- c("M1 Coef", "M1 p-value", "M1a Coef", 
    "M1a p-value")
[1] 104
print(compare1)
[1] 105
                M1 Coef M1 p-value M1a Coef M1a p-value
(Intercept)       0.000          0    0.000           0
scale(df$years)   0.465          0    0.465           0
df$spoly         -0.612          0   -0.612           0
                M1 Coef M1 p-value M1a Coef M1a p-value
(Intercept)       0.000          0    0.000           0
scale(df$years)   0.465          0    0.465           0
df$spoly         -0.612          0   -0.612           0
stdz1 <- MASS::studres(m1)
[1] 106
which(abs(stdz1) > 2)
[1] 107
 30  68  69  70  74  76 122 142 162 175 
 30  68  69  70  74  76 122 142 162 175 
hats1 <- hatvalues(m1)
[1] 108
which(hats1 > 2 * mean(hats1))
[1] 109
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
CVR1 <- covratio(m1)
[1] 110
which(CVR1 > (1 + 3 * (1 + 1)/200) | CVR1 < (1 - 3 * (1 + 1)/200))
[1] 111
 16  30  37  44  50  59  61  68  69  70  74  76  87  88  89  92  94 108 109 116 122 131 134 136 137 140 141 142 146 
 16  30  37  44  50  59  61  68  69  70  74  76  87  88  89  92  94 108 109 116 122 131 134 136 137 140 141 142 146 
154 155 162 169 171 175 190 200 
154 155 162 169 171 175 190 200 
m2 <- lm(incidents ~ training + years + empathy, data = df)
[1] 112
summary(m2)
[1] 113

Call:
lm(formula = incidents ~ training + years + empathy, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.407320   0.051814   7.861 2.48e-13 ***
trainingYes -0.152427   0.023166  -6.580 4.20e-10 ***
years       -0.014085   0.003889  -3.622 0.000372 ***
empathy      0.025396   0.004735   5.363 2.29e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

png("~/Desktop/RMS/Coursework/Q2 Plot.png")
[1] 114
effect_plot(m2, pred = training, interval = TRUE, plot.points = TRUE, 
    jutter = 0.2, partial.residuals = TRUE, cat.geom = "line", 
    main.title = "Training Model Controlling for Empathy & Years")
[1] 115
dev.off()
[1] 116
cooksm2 <- cooks.distance(m2)
[1] 117
which(cooksm2 > (4/(200 - 3 - 1)))
[1] 118
 13  35  74 137 165 
 13  35  74 137 165 
par(mfrow = c(1, 1))
[1] 119
$mfrow
[1] 1 2

plot(m2, 4)
[1] 120
m2a <- lm(incidents ~ training + years + empathy, data = df[-c(13, 
    74, 137), ])
[1] 121
summary(lm.beta(m2a))
[1] 122

Call:
lm(formula = incidents ~ training + years + empathy, data = df[-c(13, 
    74, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29350 -0.11585 -0.00812  0.10001  0.40267 

Coefficients:
             Estimate Standardized Std. Error t value Pr(>|t|)    
(Intercept)  0.386104     0.000000   0.049898   7.738 5.50e-13 ***
trainingYes -0.153719    -0.419006   0.022279  -6.900 7.28e-11 ***
years       -0.016244    -0.266756   0.003864  -4.204 4.01e-05 ***
empathy      0.029033     0.396908   0.004656   6.236 2.77e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1552 on 193 degrees of freedom
Multiple R-squared:  0.2988,	Adjusted R-squared:  0.2879 
F-statistic: 27.41 on 3 and 193 DF,  p-value: 8.212e-15

m2_coef <- summary(lm.beta(m2))
[1] 123
m2a_coef <- summary(lm.beta(m2a))
[1] 124
compare2 <- data.frame(round(m2_coef$coefficients[, 2], 3), round(m2_coef$coefficients[, 
    5], 4), round(m2a_coef$coefficients[, 2], 3), round(m2a_coef$coefficients[, 
    5], 4))
[1] 125
colnames(compare2) <- c("M2 Coef", "M2 p-value", "M2a Coef", 
    "M2a p-value")
[1] 126
compare2

            M2 Coef M2 p-value M2a Coef M2a p-value
(Intercept)   0.000      0e+00    0.000           0
trainingYes  -0.409      0e+00   -0.419           0
years        -0.232      4e-04   -0.267           0
empathy       0.345      0e+00    0.397           0


png("~/Desktop/RMS/Coursework/Q2 Normality.png")
[1] 128
qqPlot(m2, main = "QQ-plot", col.lines = "firebrick3")
[1] 129
dev.off()
[1] 130
png("~/Desktop/RMS/Coursework/Q2 Homoscedasticity.png")
[1] 131
residualPlots(m2)
[1] 132
dev.off()
[1] 133
ncvTest(m2)
[1] 134
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
png("~/Desktop/RMS/Coursework/Q2 Linearity.png")
[1] 135
crPlots(m2)
[1] 136
dev.off()
[1] 137
plot(m2, 1)
[1] 138
durbinWatsonTest(m2)
[1] 139
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.184
 Alternative hypothesis: rho != 0
vif(m2)
[1] 140
training    years  empathy 
1.020633 1.085089 1.092467 
stdz2 <- MASS::studres(m2)
[1] 141
which(abs(stdz2) > 2)
[1] 142
  7  13  35  74 159 165 176 181 
  7  13  35  74 159 165 176 181 
hats2 <- hatvalues(m2)
[1] 143
which(hats2 > 2 * mean(hats2))
[1] 144
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
CVR2 <- covratio(m2)
[1] 145
which(CVR2 > (1 + 3 * (3 + 1)/200) | CVR2 < (1 - 3 * (3 + 1)/200))
[1] 146
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
m3 <- lm(incidents ~ feedback + years + empathy, data = df)
[1] 147
summary(m3)
[1] 148

Call:
lm(formula = incidents ~ feedback + years + empathy, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.276161   0.054108   5.104 7.84e-07 ***
feedbackYes  0.132132   0.023585   5.602 7.09e-08 ***
years       -0.012689   0.003975  -3.192  0.00165 ** 
empathy      0.023187   0.004829   4.802 3.11e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

png("~/Desktop/RMS/Coursework/Q3 Plot.png")
[1] 149
effect_plot(m3, pred = feedback, interval = TRUE, plot.points = TRUE, 
    jutter = 0.2, partial.residuals = TRUE, cat.geom = "line", 
    main.title = "Feedback Model Controlling for Empathy & Years")
[1] 150
dev.off()
[1] 151
cooksm3 <- cooks.distance(m3)
[1] 152
which(cooksm3 > (4/(200 - 3 - 1)))
[1] 153
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
png("~/Desktop/RMS/Coursework/Q3 Cooks.png")
[1] 154
plot(m3, 4)
[1] 155
dev.off()
[1] 156
m3a <- lm(incidents ~ feedback + years + empathy, data = df[-c(74, 
    89, 137), ])
[1] 157
summary(lm.beta(m3a))
[1] 158

Call:
lm(formula = incidents ~ feedback + years + empathy, data = df[-c(74, 
    89, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.34740 -0.11326 -0.01073  0.11335  0.53413 

Coefficients:
             Estimate Standardized Std. Error t value Pr(>|t|)    
(Intercept)  0.269488     0.000000   0.053306   5.055 9.94e-07 ***
feedbackYes  0.128900     0.350295   0.023282   5.537 9.99e-08 ***
years       -0.013583    -0.219447   0.004147  -3.276  0.00125 ** 
empathy      0.024888     0.336995   0.004950   5.028 1.13e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1633 on 193 degrees of freedom
Multiple R-squared:  0.2282,	Adjusted R-squared:  0.2162 
F-statistic: 19.02 on 3 and 193 DF,  p-value: 7.541e-11

m3_coef <- summary(lm.beta(m3))
[1] 159
m3a_coef <- summary(lm.beta(m3a))
[1] 160
compare3 <- data.frame(round(m3_coef$coefficients[, 2], 3), round(m3_coef$coefficients[, 
    5], 4), round(m3a_coef$coefficients[, 2], 3), round(m3a_coef$coefficients[, 
    5], 4))
[1] 161
colnames(compare3) <- c("M3 Coef", "M3 p-value", "M3a Coef", 
    "M3a p-value")
[1] 162
compare3

            M3 Coef M3 p-value M3a Coef M3a p-value
(Intercept)   0.000     0.0000    0.000      0.0000
feedbackYes   0.355     0.0000    0.350      0.0000
years        -0.209     0.0016   -0.219      0.0013
empathy       0.315     0.0000    0.337      0.0000


png("~/Desktop/RMS/Coursework/Q3 Normality.png")
[1] 164
qqPlot(m3, main = "QQ-plot", col.lines = "firebrick3")
[1] 165
dev.off()
[1] 166
png("~/Desktop/RMS/Coursework/Q3 Homoescedasticity.png")
[1] 167
residualPlots(m3)
[1] 168
dev.off()
[1] 169
ncvTest(m3)
[1] 170
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
png("~/Desktop/RMS/Coursework/Q3 Linearity.png")
[1] 171
crPlots(m3)
[1] 172
dev.off()
[1] 173
durbinWatsonTest(m3)
[1] 174
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(m3)
[1] 175
feedback    years  empathy 
1.005211 1.077467 1.079397 
stdz3 <- MASS::studres(m3)
[1] 176
which(abs(stdz3) > 2)
[1] 177
 13  21  73  74 150 156 159 160 165 176 181 
 13  21  73  74 150 156 159 160 165 176 181 
hats3 <- hatvalues(m3)
[1] 178
which(hats3 > 2 * mean(hats3))
[1] 179
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
CVR3 <- covratio(m3)
[1] 180
which(CVR3 > (1 + 3 * (3 + 1)/200) | CVR3 < (1 - 3 * (3 + 1)/200))
[1] 181
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
summary(lm(incidents ~ training + years + empathy, data = df))$adj.r.squared
[1] 182
[1] 0.2450747
summ(m2)
[1] 183
MODEL INFO:
Observations: 200
Dependent Variable: incidents
Type: OLS linear regression 

MODEL FIT:
F(3,196) = 22.53, p = 0.00
R² = 0.26
Adj. R² = 0.25 

Standard errors: OLS
------------------------------------------------
                     Est.   S.E.   t val.      p
----------------- ------- ------ -------- ------
(Intercept)          0.41   0.05     7.86   0.00
trainingYes         -0.15   0.02    -6.58   0.00
years               -0.01   0.00    -3.62   0.00
empathy              0.03   0.00     5.36   0.00
------------------------------------------------
summary(lm(incidents ~ feedback + years + empathy, data = df))$adj.r.squared
[1] 184
[1] 0.2055499
summ(m3)
[1] 185
MODEL INFO:
Observations: 200
Dependent Variable: incidents
Type: OLS linear regression 

MODEL FIT:
F(3,196) = 18.16, p = 0.00
R² = 0.22
Adj. R² = 0.21 

Standard errors: OLS
------------------------------------------------
                     Est.   S.E.   t val.      p
----------------- ------- ------ -------- ------
(Intercept)          0.28   0.05     5.10   0.00
feedbackYes          0.13   0.02     5.60   0.00
years               -0.01   0.00    -3.19   0.00
empathy              0.02   0.00     4.80   0.00
------------------------------------------------
AIC(m2, m3)
[1] 186
   df       AIC
m2  5 -154.1654
m3  5 -143.9591
BIC(m2, m3)
[1] 187
   df       BIC
m2  5 -137.6738
m3  5 -127.4675
interaction1 <- lm(incidents ~ training + feedback + training * 
    feedback, data = df)
[1] 188
summary(interaction1)
[1] 189

Call:
lm(formula = incidents ~ training + feedback + training * feedback, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)              0.49333    0.02314  21.323  < 2e-16 ***
trainingYes             -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackYes              0.09667    0.03272   2.954  0.00352 ** 
trainingYes:feedbackYes  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

m5 <- lm(incidents ~ training + feedback + empathy + years + 
    training * feedback, data = df)
[1] 190
summary(m5)
[1] 191

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training * feedback, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                         Estimate Std. Error t value Pr(>|t|)    
(Intercept)              0.345467   0.048515   7.121 2.04e-11 ***
trainingYes             -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackYes              0.085558   0.029299   2.920  0.00391 ** 
empathy                  0.028695   0.004328   6.630 3.25e-10 ***
years                   -0.015720   0.003518  -4.468 1.34e-05 ***
trainingYes:feedbackYes  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

anova(interaction1, m5)
[1] 192
Analysis of Variance Table

Model 1: incidents ~ training + feedback + training * feedback
Model 2: incidents ~ training + feedback + empathy + years + training * 
    feedback
  Res.Df    RSS Df Sum of Sq     F    Pr(>F)    
1    196 5.2456                                 
2    194 4.1482  2    1.0974 25.66 1.296e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
describeBy(df$incidents, group = list(df$training, df$feedback), 
    mat = TRUE, digits = 2)
[1] 193
    item group1 group2 vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X11    1     No     No    1 50 0.49 0.17   0.42    0.48 0.12 0.25 0.92  0.67 0.82    -0.07 0.02
X12    2    Yes     No    1 50 0.33 0.14   0.33    0.33 0.12 0.08 0.58  0.50 0.15    -0.96 0.02
X13    3     No    Yes    1 50 0.59 0.17   0.58    0.59 0.12 0.25 0.92  0.67 0.05    -0.81 0.02
 [ reached 'max' / getOption("max.print") -- omitted 1 rows ]
aggregate(df$incidents, list(training = df$training, feedback = df$feedback), 
    mean, data = df)
[1] 194
  training feedback         x
1       No       No 0.4933333
2      Yes       No 0.3333333
3       No      Yes 0.5900000
4      Yes      Yes 0.4833333
tapply(df$incidents, df$training, mean)
[1] 195
       No       Yes 
0.5416667 0.4083333 
tapply(df$incidents, df$feedback, mean)
[1] 196
       No       Yes 
0.4133333 0.5366667 
mean(df$incidents)
[1] 197
[1] 0.475
png("~/Desktop/RMS/Coursework/Q5 Interactionplot.png")
[1] 198
cat_plot(m5, pred = training, modx = feedback, geom = "line", 
    point.shape = TRUE, main.title = "Interaction Plot Feedback & Training")
[1] 199
dev.off()
[1] 200
png("~/Desktop/RMS/Coursework/Q5 Normality.png")
[1] 201
qqPlot(m5, main = "QQ-plot", col.lines = "firebrick3")
[1] 202
dev.off()
[1] 203
png("~/Desktop/RMS/Coursework/Q5 Homoscedasticity.png")
[1] 204
residualPlots(m5)
[1] 205
dev.off()
[1] 206
ncvTest(m5)
[1] 207
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
durbinWatsonTest(m5)
[1] 208
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.182
 Alternative hypothesis: rho != 0
vif(m5)
[1] 209
         training          feedback           empathy             years training:feedback 
         2.086826          2.007327          1.122147          1.092150          3.070068 
stdz5 <- MASS::studres(m5)
[1] 210
which(abs(stdz5) > 2)
[1] 211
 13  73 117 150 156 159 160 176 181 
 13  73 117 150 156 159 160 176 181 
cooksm5 <- cooks.distance(m5)
[1] 212
which(cooksm5 > (4/(200 - 4 - 1)))
[1] 213
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
png("~/Desktop/RMS/Coursework/Q5 Cooks.png")
[1] 214
plot(m5, 4)
[1] 215
dev.off()
[1] 216
m5a <- lm(incidents ~ training + feedback + empathy + years + 
    training * feedback, data = df[-c(13, 137, 176), ])
[1] 217
summary(lm.beta(m5a))
[1] 218

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training * feedback, data = df[-c(13, 137, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29641 -0.09999 -0.00384  0.09683  0.33452 

Coefficients:
                         Estimate Standardized Std. Error t value Pr(>|t|)    
(Intercept)              0.334974     0.000000   0.046041   7.276 8.69e-12 ***
trainingYes             -0.197969    -0.543938   0.028484  -6.950 5.60e-11 ***
feedbackYes              0.087979     0.241729   0.028093   3.132  0.00201 ** 
empathy                  0.030659     0.426408   0.004183   7.330 6.34e-12 ***
years                   -0.017844    -0.295074   0.003468  -5.146 6.58e-07 ***
trainingYes:feedbackYes  0.088478     0.210176   0.040074   2.208  0.02845 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1386 on 191 degrees of freedom
Multiple R-squared:  0.4376,	Adjusted R-squared:  0.4228 
F-statistic: 29.72 on 5 and 191 DF,  p-value: < 2.2e-16

m5_coef <- summary(lm.beta(m5))
[1] 219
m5a_coef <- summary(lm.beta(m5a))
[1] 220
compare5 <- data.frame(round(m5_coef$coefficients[, 2], 3), round(m5_coef$coefficients[, 
    5], 4), round(m5a_coef$coefficients[, 2], 3), round(m5a_coef$coefficients[, 
    5], 4))
[1] 221
colnames(compare5) <- c("M5 Coef", "M5 p-value", "M5a Coef", 
    "M5a p-value")
[1] 222
print(compare5)
[1] 223
                        M5 Coef M5 p-value M5a Coef M5a p-value
(Intercept)               0.000     0.0000    0.000      0.0000
trainingYes              -0.547     0.0000   -0.544      0.0000
feedbackYes               0.230     0.0039    0.242      0.0020
empathy                   0.390     0.0000    0.426      0.0000
years                    -0.259     0.0000   -0.295      0.0000
trainingYes:feedbackYes   0.226     0.0210    0.210      0.0284
                        M5 Coef M5 p-value M5a Coef M5a p-value
(Intercept)               0.000     0.0000    0.000      0.0000
trainingYes              -0.547     0.0000   -0.544      0.0000
feedbackYes               0.230     0.0039    0.242      0.0020
empathy                   0.390     0.0000    0.426      0.0000
years                    -0.259     0.0000   -0.295      0.0000
trainingYes:feedbackYes   0.226     0.0210    0.210      0.0284
hats5 <- hatvalues(m5)
[1] 224
which(hats5 > 2 * mean(hats5))
[1] 225
 61  88  89 137 141 154 200 
 61  88  89 137 141 154 200 
CVR5 <- covratio(m5)
[1] 226
which(CVR5 > (1 + 3 * (4 + 1)/200) | CVR5 < (1 - 3 * (4 + 1)/200))
[1] 227
 13  16  61  88  92  94 108 150 154 155 159 160 163 176 181 200 
 13  16  61  88  92  94 108 150 154 155 159 160 163 176 181 200 
