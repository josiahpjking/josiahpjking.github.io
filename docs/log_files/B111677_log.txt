

	####### B111677 R script #######

setwd("~/Documents/RMS /RMS 2/Coursework")
[1] 1
RMS2_report_1920 <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 2
View(RMS2_report_1920)
[1] 3
data <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 4
install.packages("psych")
[1] 5
library(psych, quietly = T)
[1] 6
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
install.packages("car")
[1] 7
library(car, quietly = T)
[1] 8
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
install.packages("carData")
[1] 9
library(carData, quietly = T)
[1] 10
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
install.packages("MASS")
[1] 11
install.packages("interactions")
[1] 12
library(interactions, quietly = T)
[1] 13
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"     "grDevices"   
 [9] "utils"        "datasets"     "methods"      "base"        
ftraining <- factor(data$training)
[1] 14
is.factor(ftraining)
[1] 15
[1] TRUE
levels(ftraining)
[1] 16
[1] "1" "2"
ftraining <- factor(ftraining, labels = c("No Training", "Training"))
[1] 17
levels(ftraining)
[1] 18
[1] "No Training" "Training"   
ffeedback <- factor(data$feedback)
[1] 19
is.factor(ffeedback)
[1] 20
[1] TRUE
levels(ffeedback)
[1] 21
[1] "1" "2"
ffeedback <- factor(ffeedback, labels = c("No Feedback", "Feedback"))
[1] 22
levels(ffeedback)
[1] 23
[1] "No Feedback" "Feedback"   
describe(data$empathy)
[1] 24
   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
X1    1 200 10.18 2.54     10   10.24 2.97   3  16    13 -0.37     0.23 0.18
describe(data$years)
[1] 25
   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 200 8.13 3.08      8    7.97 2.97   1  19    18 0.52     0.48 0.22
m0 <- lm(data$empathy ~ data$years)
[1] 26
m0


Call:
lm(formula = data$empathy ~ data$years)

Coefficients:
(Intercept)   data$years  
     8.4063       0.2176  



stdz0 <- MASS::studres(m0)
[1] 28
which(abs(stdz0) > 2)
[1] 29
 61  68  70  88  89 137 141 142 154 175 200 
 61  68  70  88  89 137 141 142 154 175 200 
which(abs(stdz0) > 3)
[1] 30
154 
154 
hats0 <- hatvalues(m0)
[1] 31
hats0

          1           2           3           4           5           6           7           8           9          10 
0.006853526 0.005676819 0.010192832 0.005676819 0.012938483 0.006853526 0.005008958 0.006853526 0.005676819 0.005401194 
         11          12          13          14          15          16          17          18          19          20 
0.007404777 0.009365956 0.005676819 0.005676819 0.005676819 0.018949232 0.017571106 0.005676819 0.010192832 0.012938483 
         21          22          23          24          25          26          27          28          29          30 
0.009365956 0.014040983 0.005008958 0.005676819 0.005676819 0.007404777 0.005676819 0.005676819 0.007404777 0.010192832 
         31          32          33          34          35          36          37          38          39          40 
0.005676819 0.005008958 0.010192832 0.005401194 0.017571106 0.010192832 0.014040983 0.010192832 0.009365956 0.010192832 
         41          42          43          44          45          46          47          48          49          50 
0.010192832 0.005401194 0.012938483 0.014040983 0.010192832 0.005008958 0.007404777 0.007404777 0.007404777 0.014040983 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats0 > 2 * mean(hats0))
[1] 33
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
plot(hats0, main = "High Leverage Cases")
[1] 34
cooks0 <- cooks.distance(m0)
[1] 35
d = 4/(200 - 3 - 1)
[1] 36
d

[1] 0.02040816


which(cooks0 > d)
[1] 38
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
plot(m0, which = 4)
[1] 39
posCVR <- 1 + (3 * 2)/200
[1] 40
posCVR

[1] 1.03


negCVR <- 1 - (3 * 2)/200
[1] 42
negCVR

[1] 0.97


CVRs <- covratio(m0)
[1] 44
which(CVRs > posCVR | CVRs < negCVR)
[1] 45
 68 109 142 175 190 
 68 109 142 175 190 
hist(m0$residuals, main = "Histogram of M0")
[1] 46
shapiro.test(m0$residuals)
[1] 47

	Shapiro-Wilk normality test

data:  m0$residuals
W = 0.98911, p-value = 0.1321

qqPlot(m0$residuals, main = "QQ plot")
[1] 48
ncvTest(m0)
[1] 49
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
durbinWatsonTest(m0)
[1] 50
 lag Autocorrelation D-W Statistic p-value
   1       0.1017162      1.769879   0.122
 Alternative hypothesis: rho != 0
crPlots(m0, main = "Component Residual Plot", xlab = "Years", 
    ylab = "Empathy")
[1] 51
m0 <- lm(data$empathy ~ data$years + I(data$years^2), data = data)
[1] 52
summary(m0)
[1] 53

Call:
lm(formula = data$empathy ~ data$years + I(data$years^2), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      1.186356   0.791848   1.498    0.136    
data$years       2.068508   0.181845  11.375   <2e-16 ***
I(data$years^2) -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

par(mfrow = c(2, 2))
[1] 54
$mfrow
[1] 1 1

hist(m0$residuals)
[1] 55
shapiro.test(m0$residuals)
[1] 56

	Shapiro-Wilk normality test

data:  m0$residuals
W = 0.9941, p-value = 0.6155

qqPlot(m0$residuals)
[1] 57
ncvTest(m0)
[1] 58
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
crPlots(m0, main = "Component Residual Plot", xlab = "Years", 
    ylab = "Empathy")
[1] 59
durbinWatsonTest(m0)
[1] 60
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.856
 Alternative hypothesis: rho != 0
m1 <- lm(incidents ~ training + empathy + years, data = data)
[1] 61
summary(m1)
[1] 62

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.559747   0.060141   9.307  < 2e-16 ***
training    -0.152427   0.023166  -6.580 4.20e-10 ***
empathy      0.025396   0.004735   5.363 2.29e-07 ***
years       -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

stdz <- MASS::studres(m1)
[1] 63
which(abs(stdz) > 2)
[1] 64
  7  13  35  74 159 165 176 181 
  7  13  35  74 159 165 176 181 
which(abs(stdz) > 3)
[1] 65
13 
13 
hats <- hatvalues(m1)
[1] 66
hats

         1          2          3          4          5          6          7          8          9         10         11 
0.01228875 0.01050612 0.01460984 0.01175403 0.01917551 0.01228875 0.01552392 0.02045647 0.01312775 0.01209596 0.01282306 
        12         13         14         15         16         17         18         19         20         21         22 
0.01887947 0.01175403 0.01312775 0.01175403 0.03896604 0.02934399 0.01175403 0.01460984 0.02037708 0.01610229 0.01838715 
        23         24         25         26         27         28         29         30         31         32         33 
0.01017972 0.01312775 0.01096403 0.01536910 0.01096403 0.01312775 0.01198283 0.03408432 0.01470775 0.01552392 0.01509311 
        34         35         36         37         38         39         40         41         42         43         44 
0.01209596 0.02541158 0.01460984 0.02029486 0.01876074 0.02205168 0.02117709 0.02117709 0.01209596 0.01892339 0.02380744 
        45         46         47         48         49         50 
0.02117709 0.01017972 0.01282306 0.01536910 0.01284842 0.02380744 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats > 2 * mean(hats))
[1] 68
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
plot(hats)
[1] 69
cooks1 <- cooks.distance(m1)
[1] 70
d2 = 4/(200 - 3 - 1)
[1] 71
d2

[1] 0.02040816


which(cooks1 > d2)
[1] 73
 13  35  74 137 165 
 13  35  74 137 165 
plot(m1, which = 4)
[1] 74
posCVR <- 1 + (3 * 4)/200
[1] 75
posCVR

[1] 1.06


negCVR <- 1 - (3 * 4)/200
[1] 77
negCVR

[1] 0.94


CVRs2 <- covratio(m1)
[1] 79
which(CVRs2 > posCVR | CVRs2 < negCVR)
[1] 80
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
residualPlots(m1)
[1] 81
ncvTest(m1)
[1] 82
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(m1)
[1] 83
durbinWatsonTest(m1)
[1] 84
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.172
 Alternative hypothesis: rho != 0
vif(m1)
[1] 85
training  empathy    years 
1.020633 1.092467 1.085089 
par(mfrow = c(2, 2))
[1] 86
$mfrow
[1] 2 2

qqPlot(m1$residuals)
[1] 87
shapiro.test(m1$residuals)
[1] 88

	Shapiro-Wilk normality test

data:  m1$residuals
W = 0.97994, p-value = 0.005838

hist(m1$residuals)
[1] 89
data$logincidents1 <- log(data$incidents + 1)
[1] 90
data$logincidents1
[1] 91
 [1] 0.51082562 0.28768207 0.28768207 0.34830669 0.40546511 0.22314355 0.60613580 0.34830669 0.40546511 0.15415068
[11] 0.55961579 0.28768207 0.65058757 0.40546511 0.45953233 0.15415068 0.15415068 0.28768207 0.55961579 0.34830669
[21] 0.15415068 0.34830669 0.34830669 0.45953233 0.34830669 0.22314355 0.40546511 0.28768207 0.34830669 0.08004271
[31] 0.28768207 0.40546511 0.28768207 0.34830669 0.55961579 0.34830669 0.40546511 0.45953233 0.45953233 0.15415068
[41] 0.51082562 0.34830669 0.28768207 0.22314355 0.34830669 0.22314355 0.45953233 0.45953233 0.40546511 0.15415068
 [ reached getOption("max.print") -- omitted 150 entries ]
describe(data$logincidents1)
[1] 92
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 200 0.38 0.13   0.35    0.38 0.09 0.08 0.65  0.57 0.02    -0.37 0.01
m2 <- lm(logincidents1 ~ training + empathy + years, data = data)
[1] 93
summary(m2)
[1] 94

Call:
lm(formula = logincidents1 ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.25974 -0.08206 -0.00301  0.07026  0.33183 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.438928   0.040385  10.869  < 2e-16 ***
training    -0.104810   0.015556  -6.737 1.75e-10 ***
empathy      0.017470   0.003180   5.494 1.21e-07 ***
years       -0.009683   0.002611  -3.708 0.000272 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1089 on 196 degrees of freedom
Multiple R-squared:  0.2657,	Adjusted R-squared:  0.2544 
F-statistic: 23.63 on 3 and 196 DF,  p-value: 4.229e-13

par(mfrow = c(2, 2))
[1] 95
$mfrow
[1] 2 2

residualPlots(m2)
[1] 96
ncvTest(m2)
[1] 97
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.8932792, Df = 1, p = 0.34459
crPlots(m2)
[1] 98
durbinWatsonTest(m2)
[1] 99
 lag Autocorrelation D-W Statistic p-value
   1      -0.1160146      2.216759   0.126
 Alternative hypothesis: rho != 0
vif(m2)
[1] 100
training  empathy    years 
1.020633 1.092467 1.085089 
qqPlot(m2$residuals)
[1] 101
shapiro.test(m2$residuals)
[1] 102

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.9901, p-value = 0.1845

hist(m2$residuals)
[1] 103
m3 <- lm(incidents ~ ffeedback + empathy + years, data = data)
[1] 104
summary(m3)
[1] 105

Call:
lm(formula = incidents ~ ffeedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)        0.276161   0.054108   5.104 7.84e-07 ***
ffeedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy            0.023187   0.004829   4.802 3.11e-06 ***
years             -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

stdz1 <- MASS::studres(m3)
[1] 106
which(abs(stdz1) > 2)
[1] 107
 13  21  73  74 150 156 159 160 165 176 181 
 13  21  73  74 150 156 159 160 165 176 181 
which(abs(stdz1) > 3)
[1] 108
176 
176 
hats1 <- hatvalues(m3)
[1] 109
hats1

         1          2          3          4          5          6          7          8          9         10         11 
0.01193805 0.01056890 0.01591194 0.01155352 0.01862431 0.01211540 0.01766517 0.02100490 0.01499209 0.01233851 0.01440768 
        12         13         14         15         16         17         18         19         20         21         22 
0.01792139 0.01130286 0.01365588 0.01130286 0.03834202 0.02573877 0.01155352 0.01591194 0.01953690 0.01442435 0.01889473 
        23         24         25         26         27         28         29         30         31         32         33 
0.01002816 0.01365588 0.01207695 0.01602790 0.01207695 0.01365588 0.01280846 0.03305959 0.01344393 0.01612821 0.01562865 
        34         35         36         37         38         39         40         41         42         43         44 
0.01233851 0.02516110 0.01497723 0.02053750 0.01954213 0.02354412 0.02077043 0.02011827 0.01233851 0.01755655 0.02357949 
        45         46         47         48         49         50 
0.02011827 0.01007806 0.01440768 0.01602790 0.01289465 0.02357949 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats1 > 2 * mean(hats1))
[1] 111
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
plot(hats1)
[1] 112
cooks2 <- cooks.distance(m3)
[1] 113
d3 = 4/(200 - 3 - 1)
[1] 114
d3

[1] 0.02040816


which(cooks1 > d2)
[1] 116
 13  35  74 137 165 
 13  35  74 137 165 
plot(m3, which = 4)
[1] 117
posCVR <- 1 + (3 * 4)/200
[1] 118
posCVR

[1] 1.06


negCVR <- 1 - (3 * 4)/200
[1] 120
negCVR

[1] 0.94


CVRs3 <- covratio(m1)
[1] 122
which(CVRs3 > posCVR | CVRs3 < negCVR)
[1] 123
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
residualPlots(m3)
[1] 124
ncvTest(m3)
[1] 125
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(m3)
[1] 126
durbinWatsonTest(m3)
[1] 127
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081   0.002
 Alternative hypothesis: rho != 0
vif(m3)
[1] 128
ffeedback   empathy     years 
 1.005211  1.079397  1.077467 
par(mfrow = c(2, 2))
[1] 129
$mfrow
[1] 2 2

qqPlot(m3$residuals)
[1] 130
shapiro.test(m3$residuals)
[1] 131

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.98772, p-value = 0.08174

hist(m3$residuals)
[1] 132
AIC(m2, m3)
[1] 133
   df       AIC
m2  5 -313.4627
m3  5 -143.9591
BIC(m2, m3)
[1] 134
   df       BIC
m2  5 -296.9711
m3  5 -127.4675
m4 <- lm(incidents ~ ftraining + ffeedback + ftraining * ffeedback, 
    data = data)
[1] 135
summary(m4)
[1] 136

Call:
lm(formula = incidents ~ ftraining + ffeedback + ftraining * 
    ffeedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)                          0.49333    0.02314  21.323  < 2e-16 ***
ftrainingTraining                   -0.16000    0.03272  -4.890 2.09e-06 ***
ffeedbackFeedback                    0.09667    0.03272   2.954  0.00352 ** 
ftrainingTraining:ffeedbackFeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

cat_plot((m4), pred = ftraining, modx = ffeedback)
[1] 137
