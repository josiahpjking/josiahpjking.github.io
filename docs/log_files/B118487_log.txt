

	####### B118487 R script #######

RMS2_report_1920 <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 1
data = RMS2_report_1920
[1] 2
install.packages("psych")
[1] 3
library(psych, quietly = T)
[1] 4
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
install.packages("car")
[1] 5
library(car, quietly = T)
[1] 6
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
install.packages("emmeans")
[1] 7
library(emmeans, quietly = T)
[1] 8
 [1] "emmeans"   "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[11] "methods"   "base"     
str(data)
[1] 9
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
describeBy(data)
[1] 10
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
data$training <- factor(x = data$training, label = c("No training", 
    "Training"))
[1] 11
data$feedback <- factor(x = data$feedback, label = c("No feedback", 
    "Feedback"))
[1] 12
empathy_m <- data$empathy - mean(data$empathy)
[1] 13
years_m <- data$years - mean(data$years)
[1] 14
plot(x = data$years, y = data$empathy, xlab = "Experience (Years)", 
    ylab = "Empathy (Score)", main = "Relationship between Experience and Empathy", 
    col = "purple")
[1] 15
M1 <- lm(empathy ~ years, data = data)
[1] 16
summary(M1)
[1] 17

Call:
lm(formula = empathy ~ years, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.40625    0.49085  17.126  < 2e-16 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

crPlots(model = M1)
[1] 18
M1H <- lm(empathy ~ years + I(years^2), data = data)
[1] 19
summary(M1H)
[1] 20

Call:
lm(formula = empathy ~ years + I(years^2), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.186356   0.791848   1.498    0.136    
years        2.068508   0.181845  11.375   <2e-16 ***
I(years^2)  -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

crPlots(model = M1H, main = "Component + Residual Plot (Model M1H)")
[1] 21
plot(M1H, which = 4, main = "Model M1H Cook's Distance Plot")
[1] 22
which((cooks.distance(M1H) > (4/(200 - 1 - 1))))
[1] 23
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
M1C <- lm(empathy ~ years + I(years^2), data = data[-c(89, 154, 
    175), ])
[1] 24
summary(M1C)
[1] 25

Call:
lm(formula = empathy ~ years + I(years^2), data = data[-c(89, 
    154, 175), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5295 -1.2903  0.1354  1.3148  4.8900 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.8127     0.8215   0.989    0.324    
years         2.1491     0.1961  10.957   <2e-16 ***
I(years^2)   -0.1077     0.0111  -9.710   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.918 on 194 degrees of freedom
Multiple R-squared:  0.4117,	Adjusted R-squared:  0.4056 
F-statistic: 67.87 on 2 and 194 DF,  p-value: < 2.2e-16

summary(M1H)
[1] 26

Call:
lm(formula = empathy ~ years + I(years^2), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.186356   0.791848   1.498    0.136    
years        2.068508   0.181845  11.375   <2e-16 ***
I(years^2)  -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

qqPlot(M1H, xlab = "Theoretical Quantiles", main = "M1H Quantile-Comparison Plot", 
    col = "red")
[1] 27
hist(M1H$residuals)
[1] 28
shapiro.test(M1H$residuals)
[1] 29

	Shapiro-Wilk normality test

data:  M1H$residuals
W = 0.9941, p-value = 0.6155

residualPlots(M1H, col = "Red", main = "Model M1H Residual Plot")
[1] 30
ncvTest(M1H)
[1] 31
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(M1H)
[1] 32
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.846
 Alternative hypothesis: rho != 0
M2 <- lm(incidents ~ training + empathy + years, data = data)
[1] 33
summary(M2)
[1] 34

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

qqPlot(M2, col.lines = "blue", col = "red", main = "M2 Quantile-Comparison Plot", 
    xlab = "Theoretical Quantiles")
[1] 35
hist(M2$residuals)
[1] 36
shapiro.test(M2$residuals)
[1] 37

	Shapiro-Wilk normality test

data:  M2$residuals
W = 0.97994, p-value = 0.005838

log_incidents <- log(data$incidents + (-1 * min(data$incidents) + 
    1))
[1] 38
M2log <- lm(log_incidents ~ training + empathy_m + years_m, data = data)
[1] 39
summary(M2log)
[1] 40

Call:
lm(formula = log_incidents ~ training + empathy_m + years_m, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.377249   0.011606  32.504  < 2e-16 ***
trainingTraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy_m         0.018550   0.003372   5.501 1.17e-07 ***
years_m          -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

M2logbeta1 = (exp(-0.111288) - 1) * 100
[1] 41
M2logbeta1

[1] -10.5319


plot(M2log, which = 4, main = "Cook's distance plot on M2log")
[1] 43
which((cooks.distance(M2log) > (4/(200 - 3 - 1))))
[1] 44
 13  30  35  60  74  88  94 137 
 13  30  35  60  74  88  94 137 
empathy_m2C <- empathy_m[-c(35, 74, 137)]
[1] 45
years_m2C <- years_m[-c(35, 74, 137)]
[1] 46
log_incidentsm2C <- log_incidents[-c(35, 74, 137)]
[1] 47
M2C <- lm(log_incidentsm2C ~ training + empathy_m2C + years_m2C, 
    data = data[-c(35, 74, 137), ])
[1] 48
summary(M2C)
[1] 49

Call:
lm(formula = log_incidentsm2C ~ training + empathy_m2C + years_m2C, 
    data = data[-c(35, 74, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.22780 -0.08427 -0.00031  0.07489  0.35074 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.375861   0.011298  33.268  < 2e-16 ***
trainingTraining -0.110542   0.016088  -6.871 8.55e-11 ***
empathy_m2C       0.020603   0.003363   6.127 4.93e-09 ***
years_m2C        -0.012642   0.002805  -4.507 1.14e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1121 on 193 degrees of freedom
Multiple R-squared:  0.2994,	Adjusted R-squared:  0.2885 
F-statistic:  27.5 on 3 and 193 DF,  p-value: 7.516e-15

summary(M2log)
[1] 50

Call:
lm(formula = log_incidents ~ training + empathy_m + years_m, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.377249   0.011606  32.504  < 2e-16 ***
trainingTraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy_m         0.018550   0.003372   5.501 1.17e-07 ***
years_m          -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

plot(data$training, data$incidents, ylab = "Incidents", xlab = "Training Group", 
    col = "violet", main = "Boxplot of Training Group and Incidents")
[1] 51
qqPlot(M2log, col = "Red", xlab = "Theoretical Quantiles", main = "Model M2log Quantile-Comparison Plot")
[1] 52
hist(M2log$residuals)
[1] 53
shapiro.test(M2log$residuals)
[1] 54

	Shapiro-Wilk normality test

data:  M2log$residuals
W = 0.9905, p-value = 0.2109

residualPlots(M2log, col = "Red", main = "Model M2log Residual Plot")
[1] 55
ncvTest(M2log)
[1] 56
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.036059, Df = 1, p = 0.30874
crPlots(model = M2log)
[1] 57
durbinWatsonTest(M2log)
[1] 58
 lag Autocorrelation D-W Statistic p-value
   1       -0.116516      2.217742   0.142
 Alternative hypothesis: rho != 0
vif(M2log)
[1] 59
 training empathy_m   years_m 
 1.020633  1.092467  1.085089 
M3M <- lm(incidents ~ feedback + empathy_m + years_m, data = data)
[1] 60
summary(M3M)
[1] 61

Call:
lm(formula = incidents ~ feedback + empathy_m + years_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

plot(data$feedback, data$incidents, ylab = "Incidents", xlab = "Feedback Group", 
    col = "pink", main = "Boxplot of Feedback Group and Incidents")
[1] 62
plot(M3M, which = 4, main = "Cook's distance plot on M3M")
[1] 63
which((cooks.distance(M3M) > (4/(200 - 3 - 1))))
[1] 64
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
empathy_m3C <- empathy_m[-c(74, 89, 137)]
[1] 65
years_m3C <- years_m[-c(74, 89, 137)]
[1] 66
log_incidentsm3C <- log_incidents[-c(74, 89, 137)]
[1] 67
M3C <- lm(log_incidentsm3C ~ feedback + empathy_m3C + years_m3C, 
    data = data[-c(74, 89, 137), ])
[1] 68
summary(M3C)
[1] 69

Call:
lm(formula = log_incidentsm3C ~ feedback + empathy_m3C + years_m3C, 
    data = data[-c(74, 89, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.25856 -0.07688 -0.00253  0.08184  0.35114 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276439   0.011657  23.714  < 2e-16 ***
feedbackFeedback  0.093377   0.016521   5.652 5.64e-08 ***
empathy_m3C       0.018078   0.003512   5.147 6.50e-07 ***
years_m3C        -0.009774   0.002943  -3.321  0.00107 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1159 on 193 degrees of freedom
Multiple R-squared:  0.2357,	Adjusted R-squared:  0.2238 
F-statistic: 19.84 on 3 and 193 DF,  p-value: 2.998e-11

summary(M3M)
[1] 70

Call:
lm(formula = incidents ~ feedback + empathy_m + years_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

qqPlot(M3M, col = "red", xlab = "Theoretical Quantiles", main = "Model M3M Quantile-Comparison Plot")
[1] 71
hist(M3M$residuals)
[1] 72
shapiro.test(M3M$residuals)
[1] 73

	Shapiro-Wilk normality test

data:  M3M$residuals
W = 0.98772, p-value = 0.08174

residualPlots(M3M, col = "Red", main = "Model M3M Residual Plot")
[1] 74
ncvTest(M3M)
[1] 75
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(model = M3M)
[1] 76
durbinWatsonTest(M3M)
[1] 77
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(M3M)
[1] 78
 feedback empathy_m   years_m 
 1.005211  1.079397  1.077467 
summary(M2log)
[1] 79

Call:
lm(formula = log_incidents ~ training + empathy_m + years_m, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.377249   0.011606  32.504  < 2e-16 ***
trainingTraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy_m         0.018550   0.003372   5.501 1.17e-07 ***
years_m          -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

summary(M3M)
[1] 80

Call:
lm(formula = incidents ~ feedback + empathy_m + years_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

M4 <- lm(incidents ~ feedback + training + empathy_m + years_m + 
    feedback * training, data = data)
[1] 81
summary(M4)
[1] 82

Call:
lm(formula = incidents ~ feedback + training + empathy_m + years_m + 
    feedback * training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
empathy_m                          0.028695   0.004328   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
feedbackFeedback:trainingTraining  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

residualPlots(M4, col = "Red", main = "Model M4 Residual Plot")
[1] 83
ncvTest(M4)
[1] 84
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
M4log <- lm(log_incidents ~ empathy_m + years_m + feedback * 
    training, data = data)
[1] 85
summary(M4log)
[1] 86

Call:
lm(formula = log_incidents ~ empathy_m + years_m + feedback * 
    training, data = data)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.226383 -0.071808 -0.000811  0.069089  0.284822 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.348968   0.014712  23.720  < 2e-16 ***
empathy_m                          0.021048   0.003060   6.878 8.14e-11 ***
years_m                           -0.011505   0.002488  -4.625 6.84e-06 ***
feedbackFeedback                   0.058376   0.020716   2.818  0.00533 ** 
trainingTraining                  -0.151903   0.021123  -7.191 1.36e-11 ***
feedbackFeedback:trainingTraining  0.077604   0.029583   2.623  0.00940 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1034 on 194 degrees of freedom
Multiple R-squared:  0.4176,	Adjusted R-squared:  0.4026 
F-statistic: 27.82 on 5 and 194 DF,  p-value: < 2.2e-16

M4logbeta5 = (exp(0.077604) - 1) * 100
[1] 87
M4logbeta5

[1] 8.069462


plot(M4log, which = 4, main = "Cook's distance plot on M4log")
[1] 89
which((cooks.distance(M4log) > (4/(200 - 5 - 1))))
[1] 90
 13  73  74  89 117 137 176 
 13  73  74  89 117 137 176 
empathy_m4C <- empathy_m[-c(73, 89, 137)]
[1] 91
years_m4C <- years_m[-c(73, 89, 137)]
[1] 92
log_incidentsm4c <- log_incidents[-c(73, 89, 137)]
[1] 93
M4C <- lm(log_incidentsm4c ~ feedback + training + empathy_m4C + 
    years_m4C, data = data[-c(73, 89, 137), ])
[1] 94
summary(M4C)
[1] 95

Call:
lm(formula = log_incidentsm4c ~ feedback + training + empathy_m4C + 
    years_m4C, data = data[-c(73, 89, 137), ])

Residuals:
      Min        1Q    Median        3Q       Max 
-0.239838 -0.071498 -0.000466  0.065078  0.303960 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.326757   0.012699  25.732  < 2e-16 ***
feedbackFeedback  0.098874   0.014743   6.706 2.17e-10 ***
trainingTraining -0.107280   0.014884  -7.208 1.27e-11 ***
empathy_m4C       0.020507   0.003140   6.531 5.72e-10 ***
years_m4C        -0.011226   0.002638  -4.256 3.26e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1033 on 192 degrees of freedom
Multiple R-squared:  0.4008,	Adjusted R-squared:  0.3883 
F-statistic: 32.11 on 4 and 192 DF,  p-value: < 2.2e-16

summary(M4log)
[1] 96

Call:
lm(formula = log_incidents ~ empathy_m + years_m + feedback * 
    training, data = data)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.226383 -0.071808 -0.000811  0.069089  0.284822 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.348968   0.014712  23.720  < 2e-16 ***
empathy_m                          0.021048   0.003060   6.878 8.14e-11 ***
years_m                           -0.011505   0.002488  -4.625 6.84e-06 ***
feedbackFeedback                   0.058376   0.020716   2.818  0.00533 ** 
trainingTraining                  -0.151903   0.021123  -7.191 1.36e-11 ***
feedbackFeedback:trainingTraining  0.077604   0.029583   2.623  0.00940 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1034 on 194 degrees of freedom
Multiple R-squared:  0.4176,	Adjusted R-squared:  0.4026 
F-statistic: 27.82 on 5 and 194 DF,  p-value: < 2.2e-16

qqPlot(M4log, col = "red", xlab = "Theoretical Quantiles", main = "Model M4log Quantile-Comparison Plot")
[1] 97
hist(M4log$residuals)
[1] 98
shapiro.test(M4log$residuals)
[1] 99

	Shapiro-Wilk normality test

data:  M4log$residuals
W = 0.99434, p-value = 0.6515

residualPlots(M4log, col = "Red", main = "Model M4log Residual Plot")
[1] 100
ncvTest(M4log)
[1] 101
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.577295, Df = 1, p = 0.44737
durbinWatsonTest(M4log)
[1] 102
 lag Autocorrelation D-W Statistic p-value
   1      0.09726586      1.794988    0.13
 Alternative hypothesis: rho != 0
vif(M4log)
[1] 103
        empathy_m           years_m          feedback          training feedback:training 
         1.122147          1.092150          2.007327          2.086826          3.070068 
emmip(object = M4log, training ~ feedback, CIs = TRUE, ylab = "Incidents (log)", 
    xlab = "Feedback group", main = "Feedback*Training Interaction Plot")
[1] 104
