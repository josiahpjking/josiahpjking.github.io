

	####### B112234 R script #######

setwd("~/Desktop/Year 3/Assessments/RMS2")
[1] 1
library(psych, quietly = T)
[1] 2
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 3
 [1] "interactions" "psych"        "readr"        "stats"        "graphics"     "grDevices"    "utils"        "datasets"    
 [9] "methods"      "base"        
library(car, quietly = T)
[1] 4
 [1] "car"          "carData"      "interactions" "psych"        "readr"        "stats"        "graphics"     "grDevices"   
 [9] "utils"        "datasets"     "methods"      "base"        
data <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 5
any(data$incidents > 1)
[1] 6
[1] FALSE
any(data$incidents < 0)
[1] 7
[1] FALSE
any(is.na(data$incidents))
[1] 8
[1] FALSE
is.factor(data$training)
[1] 9
[1] FALSE
data$training <- factor(data$training, labels = c("No Training", 
    "Training"))
[1] 10
any(is.na(data$training))
[1] 11
[1] FALSE
is.factor(data$feedback)
[1] 12
[1] FALSE
data$feedback <- factor(data$feedback, labels = c("No Feedback", 
    "Feedback"))
[1] 13
any(is.na(data$feedback))
[1] 14
[1] FALSE
any(data$empathy < 1)
[1] 15
[1] FALSE
any(data$empathy > 20)
[1] 16
[1] FALSE
any(is.na(data$empathy))
[1] 17
[1] FALSE
any(data$years < 0)
[1] 18
[1] FALSE
any(data$years > 30)
[1] 19
[1] FALSE
any(is.na(data$years))
[1] 20
[1] FALSE
describe(data)[, c(2:4, 8:12)]
[1] 21
            n   mean    sd  min    max  range  skew kurtosis
subject   200 100.50 57.88 1.00 200.00 199.00  0.00    -1.22
incidents 200   0.48  0.19 0.08   0.92   0.83  0.32    -0.31
training* 200   1.50  0.50 1.00   2.00   1.00  0.00    -2.01
feedback* 200   1.50  0.50 1.00   2.00   1.00  0.00    -2.01
empathy   200  10.18  2.54 3.00  16.00  13.00 -0.37     0.23
years     200   8.13  3.08 1.00  19.00  18.00  0.52     0.48
describeBy(data$incidents, group = data$training)
[1] 22

 Descriptive statistics by group 
group: No Training
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.54 0.18    0.5    0.53 0.25 0.25 0.92  0.67 0.39    -0.73 0.02
--------------------------------------------------------------------------------------------- 
group: Training
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.41 0.17   0.42     0.4 0.12 0.08 0.92  0.83 0.38    -0.05 0.02
describeBy(data$incidents, group = data$feedback)
[1] 23

 Descriptive statistics by group 
group: No Feedback
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.41 0.17   0.42     0.4 0.12 0.08 0.92  0.83  0.6     0.36 0.02
--------------------------------------------------------------------------------------------- 
group: Feedback
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.54 0.18    0.5    0.53 0.25 0.08 0.92  0.83 0.11    -0.44 0.02
data$years <- data$years - mean(data$years)
[1] 24
model1 <- lm(scale(empathy) ~ years, data = data)
[1] 25
summary(model1)
[1] 26

Call:
lm(formula = scale(empathy) ~ years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept) -3.544e-16  6.837e-02   0.000 1.000000    
years        8.575e-02  2.226e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

crPlots(model1)
[1] 27
model1a <- lm(scale(empathy) ~ years + I(years^2), data = data)
[1] 28
summary(model1a)
[1] 29

Call:
lm(formula = scale(empathy) ~ years + I(years^2), data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.385369   0.065991   5.840 2.13e-08 ***
years        0.151057   0.018914   7.986 1.13e-13 ***
I(years^2)  -0.040853   0.003887 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

crPlots(model1a, main = "crPlot Model 1a")
[1] 30
hist(model1a$residuals, main = "Histogram of Model 1a Residuals", 
    xlab = "Residuals", col = "light grey")
[1] 31
shapiro.test(model1a$residuals)
[1] 32

	Shapiro-Wilk normality test

data:  model1a$residuals
W = 0.9941, p-value = 0.6155

residualPlots(model1a, main = "Residual Plot Model 1a")
[1] 33
ncvTest(model1a)
[1] 34
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(model1a)
[1] 35
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.816
 Alternative hypothesis: rho != 0
plot(model1a, which = 4, main = "Cook's Distance for Model 1a")
[1] 36
model1b <- lm(scale(empathy) ~ years + I(years^2), data = data[-c(89, 
    154, 175), ])
[1] 37
summary(model1b)
[1] 38

Call:
lm(formula = scale(empathy) ~ years + I(years^2), data = data[-c(89, 
    154, 175), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-1.82053 -0.51860  0.05442  0.52846  1.96544 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.38805    0.06741   5.757 3.31e-08 ***
years        0.15966    0.01908   8.366 1.15e-14 ***
I(years^2)  -0.04330    0.00446  -9.710  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.771 on 194 degrees of freedom
Multiple R-squared:  0.4117,	Adjusted R-squared:  0.4056 
F-statistic: 67.87 on 2 and 194 DF,  p-value: < 2.2e-16

model1a$coefficients
[1] 39
(Intercept)       years  I(years^2) 
 0.38536918  0.15105660 -0.04085287 
model1b$coefficients
[1] 40
(Intercept)       years  I(years^2) 
 0.38804684  0.15965592 -0.04330353 
data$empathy <- data$empathy - mean(data$empathy)
[1] 41
model2 <- lm(incidents ~ training + empathy + years, data = data)
[1] 42
summary(model2)
[1] 43

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

plot(model2, which = 4, main = "Cook's Distance for Model 2")
[1] 44
model2a <- lm(incidents ~ training + empathy + years, data = data[-c(13, 
    74, 137), ])
[1] 45
summary(model2a)
[1] 46

Call:
lm(formula = incidents ~ training + empathy + years, data = data[-c(13, 
    74, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29350 -0.11585 -0.00812  0.10001  0.40267 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.549455   0.015645  35.119  < 2e-16 ***
trainingTraining -0.153719   0.022279  -6.900 7.28e-11 ***
empathy           0.029033   0.004656   6.236 2.77e-09 ***
years            -0.016244   0.003864  -4.204 4.01e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1552 on 193 degrees of freedom
Multiple R-squared:  0.2988,	Adjusted R-squared:  0.2879 
F-statistic: 27.41 on 3 and 193 DF,  p-value: 8.212e-15

model2$coefficients
[1] 47
     (Intercept) trainingTraining          empathy            years 
      0.55121342      -0.15242684       0.02539564      -0.01408454 
model2a$coefficients
[1] 48
     (Intercept) trainingTraining          empathy            years 
      0.54945508      -0.15371857       0.02903331      -0.01624391 
hist(model2$residuals, main = "Histogram of Model 2 Residuals", 
    xlab = "Residuals", col = "light grey")
[1] 49
shapiro.test(model2$residuals)
[1] 50

	Shapiro-Wilk normality test

data:  model2$residuals
W = 0.97994, p-value = 0.005838

residualPlots(model2, main = "Residual Plot Model 2")
[1] 51
ncvTest(model2)
[1] 52
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(model2, main = "crPlot Model 2")
[1] 53
durbinWatsonTest(model2)
[1] 54
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.184
 Alternative hypothesis: rho != 0
vif(model2)
[1] 55
training  empathy    years 
1.020633 1.092467 1.085089 
model3 <- lm(incidents ~ feedback + training + empathy + years, 
    data = data)
[1] 56
summary(model3)
[1] 57

Call:
lm(formula = incidents ~ feedback + training + empathy + years, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.485055   0.018126  26.760  < 2e-16 ***
feedbackFeedback  0.133715   0.020968   6.377 1.28e-09 ***
trainingTraining -0.153824   0.021128  -7.281 7.98e-12 ***
empathy           0.027191   0.004328   6.283 2.12e-09 ***
years            -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

plot(model3, which = 4, main = "Cook's Distance for Model 3")
[1] 58
model3a <- lm(incidents ~ feedback + training + empathy + years, 
    data = data[-c(13, 137, 176), ])
[1] 59
summary(model3a)
[1] 60

Call:
lm(formula = incidents ~ feedback + training + empathy + years, 
    data = data[-c(13, 137, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31479 -0.10102 -0.00300  0.09041  0.35676 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.479439   0.017312  27.693  < 2e-16 ***
feedbackFeedback  0.132020   0.019981   6.607 3.76e-10 ***
trainingTraining -0.153003   0.020113  -7.607 1.22e-12 ***
empathy           0.029143   0.004167   6.993 4.34e-11 ***
years            -0.017169   0.003489  -4.921 1.85e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.14 on 192 degrees of freedom
Multiple R-squared:  0.4232,	Adjusted R-squared:  0.4112 
F-statistic: 35.22 on 4 and 192 DF,  p-value: < 2.2e-16

model3$coefficients
[1] 61
     (Intercept) feedbackFeedback trainingTraining          empathy            years 
      0.48505468       0.13371460      -0.15382397       0.02719087      -0.01519867 
model3a$coefficients
[1] 62
     (Intercept) feedbackFeedback trainingTraining          empathy            years 
      0.47943925       0.13201951      -0.15300290       0.02914329      -0.01716858 
hist(model3$residuals, main = "Histogram of Model 3 Residuals", 
    xlab = "Residuals", col = "light grey")
[1] 63
shapiro.test(model3$residuals)
[1] 64

	Shapiro-Wilk normality test

data:  model3$residuals
W = 0.98734, p-value = 0.07172

residualPlots(model3, main = "Residual Plot Model 3")
[1] 65
ncvTest(model3)
[1] 66
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 3.684027, Df = 1, p = 0.054936
crPlots(model3, main = "crPlot Model 3")
[1] 67
durbinWatsonTest(model3)
[1] 68
 lag Autocorrelation D-W Statistic p-value
   1      0.07303546      1.841386   0.256
 Alternative hypothesis: rho != 0
vif(model3)
[1] 69
feedback training  empathy    years 
1.005320 1.020743 1.097109 1.087722 
AIC(model2, model3)
[1] 70
       df       AIC
model2  5 -154.1654
model3  6 -190.0499
BIC(model2, model3)
[1] 71
       df       BIC
model2  5 -137.6738
model3  6 -170.2600
anova(model2, model3)
[1] 72
Analysis of Variance Table

Model 1: incidents ~ training + empathy + years
Model 2: incidents ~ feedback + training + empathy + years
  Res.Df    RSS Df Sum of Sq      F    Pr(>F)    
1    196 5.1532                                  
2    195 4.2639  1   0.88925 40.668 1.279e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
model4 <- lm(incidents ~ training + feedback + empathy + years + 
    training:feedback, data = data)
[1] 73
summary(model4)
[1] 74

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training:feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
empathy                            0.028695   0.004328   6.630 3.25e-10 ***
years                             -0.015720   0.003518  -4.468 1.34e-05 ***
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

plot(model4, which = 4, main = "Cook's Distance for Model 4")
[1] 75
model4a <- lm(incidents ~ training + feedback + empathy + years + 
    training:feedback, data = data[-c(13, 137, 176), ])
[1] 76
summary(model4a)
[1] 77

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training:feedback, data = data[-c(13, 137, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29641 -0.09999 -0.00384  0.09683  0.33452 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.501859   0.019923  25.190  < 2e-16 ***
trainingTraining                  -0.197969   0.028484  -6.950 5.60e-11 ***
feedbackFeedback                   0.087979   0.028093   3.132  0.00201 ** 
empathy                            0.030659   0.004183   7.330 6.34e-12 ***
years                             -0.017844   0.003468  -5.146 6.58e-07 ***
trainingTraining:feedbackFeedback  0.088478   0.040074   2.208  0.02845 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1386 on 191 degrees of freedom
Multiple R-squared:  0.4376,	Adjusted R-squared:  0.4228 
F-statistic: 29.72 on 5 and 191 DF,  p-value: < 2.2e-16

model4$coefficients
[1] 78
                      (Intercept)                  trainingTraining                  feedbackFeedback 
                       0.50963577                       -0.20349646                        0.08555800 
                          empathy                             years trainingTraining:feedbackFeedback 
                       0.02869488                       -0.01571982                        0.09733382 
model4a$coefficients
[1] 79
                      (Intercept)                  trainingTraining                  feedbackFeedback 
                       0.50185920                       -0.19796944                        0.08797882 
                          empathy                             years trainingTraining:feedbackFeedback 
                       0.03065934                       -0.01784422                        0.08847755 
hist(model4$residuals, main = "Histogram of Model 4 Residuals", 
    xlab = "Residuals", col = "light grey")
[1] 80
shapiro.test(model4$residuals)
[1] 81

	Shapiro-Wilk normality test

data:  model4$residuals
W = 0.98794, p-value = 0.08817

residualPlots(model4, main = "Residual Plot Model 4")
[1] 82
ncvTest(model4)
[1] 83
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
log.dv <- log(data$incidents + (-1 * min(data$incidents) + 1))
[1] 84
model4b <- lm(log.dv ~ training + feedback + empathy + years + 
    training:feedback, data = data)
[1] 85
summary(model4b)
[1] 86

Call:
lm(formula = log.dv ~ training + feedback + empathy + years + 
    training:feedback, data = data)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.226383 -0.071808 -0.000811  0.069089  0.284822 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.348968   0.014712  23.720  < 2e-16 ***
trainingTraining                  -0.151903   0.021123  -7.191 1.36e-11 ***
feedbackFeedback                   0.058376   0.020716   2.818  0.00533 ** 
empathy                            0.021048   0.003060   6.878 8.14e-11 ***
years                             -0.011505   0.002488  -4.625 6.84e-06 ***
trainingTraining:feedbackFeedback  0.077604   0.029583   2.623  0.00940 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1034 on 194 degrees of freedom
Multiple R-squared:  0.4176,	Adjusted R-squared:  0.4026 
F-statistic: 27.82 on 5 and 194 DF,  p-value: < 2.2e-16

residualPlots(model4b, main = "Residual Plot Model 4b (Log Transformed DV)")
[1] 87
ncvTest(model4b)
[1] 88
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.577295, Df = 1, p = 0.44737
durbinWatsonTest(model4)
[1] 89
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.168
 Alternative hypothesis: rho != 0
vif(model4)
[1] 90
         training          feedback           empathy             years training:feedback 
         2.086826          2.007327          1.122147          1.092150          3.070068 
cat_plot(model4, pred = training, modx = feedback, data = data, 
    main = "Interaction Plot for Training and Feedback on Intervention", 
    ylab = "Percentage of Incidents Intervened", geom = "line")
[1] 91
