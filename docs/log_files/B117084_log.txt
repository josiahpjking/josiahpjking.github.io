

	####### B117084 R script #######

setwd("~/R/my_uni_stuff_RMS2/Coursework")
[1] 1
data <- read.csv("../RMS2_report_1920.csv")
[1] 2
library(psych, quietly = T)
[1] 3
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(carData, quietly = T)
[1] 4
 [1] "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[10] "base"     
library(car, quietly = T)
[1] 5
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(interactions, quietly = T)
[1] 6
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [8] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(jtools, quietly = T)
[1] 7
 [1] "jtools"       "interactions" "car"          "carData"      "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(lm.beta, quietly = T)
[1] 8
 [1] "lm.beta"      "jtools"       "interactions" "car"          "carData"      "psych"        "readr"       
 [8] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(sandwich, quietly = T)
[1] 9
 [1] "sandwich"     "lm.beta"      "jtools"       "interactions" "car"          "carData"      "psych"       
 [8] "readr"        "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"     
[15] "base"        
summary(data)
[1] 10
    subject         incidents          training      feedback      empathy          years      
 Min.   :  1.00   Min.   :0.08333   Min.   :1.0   Min.   :1.0   Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 50.75   1st Qu.:0.33333   1st Qu.:1.0   1st Qu.:1.0   1st Qu.: 9.00   1st Qu.: 6.00  
 Median :100.50   Median :0.41667   Median :1.5   Median :1.5   Median :10.00   Median : 8.00  
 Mean   :100.50   Mean   :0.47500   Mean   :1.5   Mean   :1.5   Mean   :10.18   Mean   : 8.13  
 3rd Qu.:150.25   3rd Qu.:0.58333   3rd Qu.:2.0   3rd Qu.:2.0   3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :200.00   Max.   :0.91667   Max.   :2.0   Max.   :2.0   Max.   :16.00   Max.   :19.00  
describe(data)
[1] 11
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
str(data)
[1] 12
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
data$training <- factor(x = data$training, levels = c(1, 2), 
    labels = c("no training", "training"))
[1] 13
summary(data$training)
[1] 14
no training    training 
        100         100 
data$feedback <- factor(x = data$feedback, levels = c(1, 2), 
    labels = c("no feedback", "feedback"))
[1] 15
summary(data$feedback)
[1] 16
no feedback    feedback 
        100         100 
data$empathy_z <- (data$empathy - mean(data$empathy))/sd(data$empathy)
[1] 17
data$years_m <- data$years - mean(data$years)
[1] 18
describe(data)[c(2, 5, 6, 7, 8), c(2:4, 8:10)]
[1] 19
            n  mean   sd   min   max range
incidents 200  0.48 0.19  0.08  0.92  0.83
empathy   200 10.18 2.54  3.00 16.00 13.00
years     200  8.13 3.08  1.00 19.00 18.00
empathy_z 200  0.00 1.00 -2.83  2.30  5.12
years_m   200  0.00 3.08 -7.13 10.87 18.00
contrasts(data$training)
[1] 20
            training
no training        0
training           1
contrasts(data$feedback)
[1] 21
            feedback
no feedback        0
feedback           1
describeBy(x = data, group = list(data$training, data$feedback))
[1] 22

 Descriptive statistics by group 
: no training
: no feedback
          vars  n   mean    sd median trimmed   mad    min    max range skew kurtosis   se
subject      1 50 151.00 29.15 151.00  151.00 37.06 102.00 200.00 98.00 0.00    -1.27 4.12
incidents    2 50   0.49  0.17   0.42    0.48  0.12   0.25   0.92  0.67 0.82    -0.07 0.02
training*    3 50   1.00  0.00   1.00    1.00  0.00   1.00   1.00  0.00  NaN      NaN 0.00
 [ reached 'max' / getOption("max.print") -- omitted 5 rows ]
--------------------------------------------------------------------------------------- 
: training
: no feedback
          vars  n  mean    sd median trimmed   mad  min    max range skew kurtosis   se
subject      1 50 51.00 29.15  51.00   51.00 37.06 2.00 100.00  98.0 0.00    -1.27 4.12
incidents    2 50  0.33  0.14   0.33    0.33  0.12 0.08   0.58   0.5 0.15    -0.96 0.02
training*    3 50  2.00  0.00   2.00    2.00  0.00 2.00   2.00   0.0  NaN      NaN 0.00
 [ reached 'max' / getOption("max.print") -- omitted 5 rows ]
--------------------------------------------------------------------------------------- 
: no training
: feedback
          vars  n   mean    sd median trimmed   mad    min    max range skew kurtosis   se
subject      1 50 150.00 29.15 150.00  150.00 37.06 101.00 199.00 98.00 0.00    -1.27 4.12
incidents    2 50   0.59  0.17   0.58    0.59  0.12   0.25   0.92  0.67 0.05    -0.81 0.02
training*    3 50   1.00  0.00   1.00    1.00  0.00   1.00   1.00  0.00  NaN      NaN 0.00
 [ reached 'max' / getOption("max.print") -- omitted 5 rows ]
--------------------------------------------------------------------------------------- 
: training
: feedback
          vars  n  mean    sd median trimmed   mad  min   max range skew kurtosis   se
subject      1 50 50.00 29.15   50.0   50.00 37.06 1.00 99.00 98.00 0.00    -1.27 4.12
incidents    2 50  0.48  0.17    0.5    0.48  0.12 0.08  0.92  0.83 0.23    -0.07 0.02
training*    3 50  2.00  0.00    2.0    2.00  0.00 2.00  2.00  0.00  NaN      NaN 0.00
 [ reached 'max' / getOption("max.print") -- omitted 5 rows ]
sum(is.na(data))
[1] 23
[1] 0
table(is.na(data))
[1] 24

FALSE 
 1600 
par(mfrow = c(2, 3))
[1] 25
$mfrow
[1] 2 2

hist(data$incidents, main = "Histogram of the Incidents\n     Intervened", 
    xlab = "Incidents", col = "pink")
[1] 26
hist(data$empathy_z, main = "Histogram of Empathy", col = "pink", 
    xlab = "Empathy (Z-scores")
[1] 27
hist(data$years_m, main = "Histogram of Years of Experience", 
    xlab = "Years of Experience (mean centred)", col = "pink")
[1] 28
plot(data$incidents ~ data$training, ylab = "Incidents Intervened", 
    xlab = "Training", main = "Incidents Intervened by Training", 
    col = "lightblue")
[1] 29
plot(data$incidents ~ data$feedback, ylab = "Incidents Intervened", 
    xlab = "Feedback", main = "Incidents Intervened by Feedback", 
    col = "lightblue")
[1] 30
par(mfrow = c(1, 1))
[1] 31
$mfrow
[1] 2 3

plot(data$empathy_z ~ data$years_m, main = "Empathy by Years of\n     Experience", 
    ylab = "Empathy (Z-scores)", xlab = "Years of Experience (mean centred)", 
    pch = 16, col = "red")
[1] 32
par(mfrow = c(1, 2))
[1] 33
$mfrow
[1] 1 1

hist(data$empathy_z, main = "Histogram of Empathy", col = "pink", 
    xlab = "Empathy (Z-scores)")
[1] 34
hist(data$years_m, main = "Histogram of Years of Experience", 
    xlab = "Years of Experience (Mean centred)", col = "pink")
[1] 35
skew(data$years)
[1] 36
[1] 0.516562
skew(data$empathy)
[1] 37
[1] -0.371876
par(mfrow = c(1, 1))
[1] 38
$mfrow
[1] 1 2

plot(data$empathy_z ~ data$years_m, main = "Empathy by Years of\n     Experience", 
    ylab = "Empathy (Z-scores)", xlab = "Years of Experience", 
    pch = 16, col = "red")
[1] 39
abline(lm(data$empathy_z ~ data$years_m), lwd = 3, col = "black")
[1] 40
lines(lowess(data$empathy_z ~ data$years_m), col = "darkgrey", 
    lwd = 3)
[1] 41
data$years_log <- log(data$years)
[1] 42
data$empathy_log <- log(data$empathy)
[1] 43
hist(data$years_log)
[1] 44
hist(data$empathy_log)
[1] 45
skew(data$years_log)
[1] 46
[1] -1.284774
skew(data$empathy_log)
[1] 47
[1] -1.520138
plot(data$empathy_log ~ data$years_log, xlab = "Years of Experience", 
    ylab = "Empathy", col = "red", pch = 16)
[1] 48
data <- data[, -c(9, 10)]
[1] 49
Model1 <- lm(data$empathy_z ~ data$years_m)
[1] 50
summary(Model1)
[1] 51

Call:
lm(formula = data$empathy_z ~ data$years_m)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.544e-16  6.837e-02   0.000 1.000000    
data$years_m  8.575e-02  2.226e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(Model1, which = 4)
[1] 52
abline(h = 4/198, col = "red")
[1] 53
cooks_M1 <- cooks.distance(Model1)
[1] 54
which(cooks_M1 > 4/(200 - 1 - 1))
[1] 55
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
data[which(cooks_M1 > 4/(200 - 1 - 1)), ]
[1] 56
    subject  incidents    training    feedback empathy years  empathy_z years_m
16       16 0.16666667    training no feedback       5     3 -2.0397809   -5.13
61       61 0.41666667    training    feedback       3     2 -2.8281020   -6.13
88       88 0.16666667    training no feedback       3     1 -2.8281020   -7.13
89       89 0.08333333    training    feedback       6    15 -1.6456203    6.87
94       94 0.08333333    training no feedback       8    14 -0.8572992    5.87
108     108 0.33333333 no training no feedback       8    14 -0.8572992    5.87
 [ reached 'max' / getOption("max.print") -- omitted 8 rows ]
Model1_sub <- lm(empathy ~ years, data = data[-c(which(cooks_M1 > 
    4/(200 - 1 - 1))), ])
[1] 57
summary(Model1_sub)
[1] 58

Call:
lm(formula = empathy ~ years, data = data[-c(which(cooks_M1 > 
    4/(200 - 1 - 1))), ])

Residuals:
   Min     1Q Median     3Q    Max 
-4.681 -1.378  0.008  1.307  5.532 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.36973    0.49518  16.902  < 2e-16 ***
years        0.26223    0.05804   4.518 1.11e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.064 on 184 degrees of freedom
Multiple R-squared:  0.09986,	Adjusted R-squared:  0.09497 
F-statistic: 20.41 on 1 and 184 DF,  p-value: 1.114e-05

summary(Model1)
[1] 59

Call:
lm(formula = data$empathy_z ~ data$years_m)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.544e-16  6.837e-02   0.000 1.000000    
data$years_m  8.575e-02  2.226e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

Model1_poly <- lm(empathy_z ~ poly(years_m, 2, raw = TRUE), data = data)
[1] 60
summary(Model1_poly)
[1] 61

Call:
lm(formula = empathy_z ~ poly(years_m, 2, raw = TRUE), data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
                               Estimate Std. Error t value Pr(>|t|)    
(Intercept)                    0.385369   0.065991   5.840 2.13e-08 ***
poly(years_m, 2, raw = TRUE)1  0.151057   0.018914   7.986 1.13e-13 ***
poly(years_m, 2, raw = TRUE)2 -0.040853   0.003887 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

BIC(Model1, Model1_poly)
[1] 62
            df      BIC
Model1       3 568.0149
Model1_poly  4 484.2796
Model1_poly$coefficients
[1] 63
                  (Intercept) poly(years_m, 2, raw = TRUE)1 poly(years_m, 2, raw = TRUE)2 
                   0.38536918                    0.15105660                   -0.04085287 
(-Model1_poly$coefficients[2])/(2 * Model1_poly$coefficients[3])
[1] 64
poly(years_m, 2, raw = TRUE)1 
                     1.848788 
mean(data$years) + (-Model1_poly$coefficients[2])/(2 * Model1_poly$coefficients[3])
[1] 65
poly(years_m, 2, raw = TRUE)1 
                     9.978788 
Model1_poly$coefficients[1] + Model1_poly$coefficients[2] * ((-Model1_poly$coefficients[2])/(2 * 
    Model1_poly$coefficients[3])) + Model1_poly$coefficients[3] * 
    ((-Model1_poly$coefficients[2])/(2 * Model1_poly$coefficients[3]))^2
[1] 66
(Intercept) 
   0.525005 
plot(data$empathy_z ~ data$years_m, xlab = "Years of Experience (mean centred)", 
    ylab = "Empathy (Z-scores)")
[1] 67
points(data$years_m, fitted(Model1_poly), col = "red", pch = 20)
[1] 68
NULL
lines(sort(data$years_m), fitted(Model1_poly)[order(data$years_m)], 
    col = "red", type = "b")
[1] 69
cooks_M1poly <- cooks.distance(Model1_poly)
[1] 70
which(cooks_M1poly > 4/(200 - 1 - 1))
[1] 71
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(Model1_poly, which = 4)
[1] 72
abline(h = 4/198, col = "red")
[1] 73
data[which(cooks_M1poly > 4/(200 - 1 - 1)), ]
[1] 74
    subject  incidents    training    feedback empathy years empathy_z years_m
61       61 0.41666667    training    feedback       3     2 -2.828102   -6.13
89       89 0.08333333    training    feedback       6    15 -1.645620    6.87
137     137 0.58333333 no training    feedback       6    18 -1.645620    9.87
141     141 0.33333333 no training    feedback       3     2 -2.828102   -6.13
154     154 0.25000000 no training no feedback       5    19 -2.039781   10.87
163     163 0.41666667 no training    feedback       7    14 -1.251460    5.87
 [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
qqPlot(Model1_poly, main = "Figure 1: QQ-Plot, Model 1")
[1] 75
hist(Model1_poly$residuals, main = "Figure 2: Histogram of Residuals,\n     Model 1", 
    col = "lightblue")
[1] 76
shapiro.test(Model1_poly$residuals)
[1] 77

	Shapiro-Wilk normality test

data:  Model1_poly$residuals
W = 0.9941, p-value = 0.6155

residualPlots(Model1_poly, main = "Figure 3: Residual Plots, Model 1")
[1] 78
ncvTest(Model1_poly)
[1] 79
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(Model1_poly)
[1] 80
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.832
 Alternative hypothesis: rho != 0
crPlots(Model1_poly)
[1] 81
plot(data$incidents ~ data$training, ylab = "Percentage of Incidents Intervened", 
    xlab = "Training", main = "Incidents by Training", col = "lightblue")
[1] 82
describeBy(x = data$incidents, group = data$training)
[1] 83

 Descriptive statistics by group 
group: no training
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.54 0.18    0.5    0.53 0.25 0.25 0.92  0.67 0.39    -0.73 0.02
--------------------------------------------------------------------------------------- 
group: training
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.41 0.17   0.42     0.4 0.12 0.08 0.92  0.83 0.38    -0.05 0.02
Model2 <- lm(incidents ~ empathy_z + years_m + training, data = data)
[1] 84
contrasts(data$training)
[1] 85
            training
no training        0
training           1
summary(Model2)
[1] 86

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
empathy_z         0.064430   0.012014   5.363 2.29e-07 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

plot(Model2, which = 4)
[1] 87
abline(h = 4/(200 - 3 - 1), col = "red")
[1] 88
cooks_M2 <- cooks.distance(Model2)
[1] 89
which(cooks_M2 > 4/(200 - 3 - 1))
[1] 90
 13  35  74 137 165 
 13  35  74 137 165 
data[which(cooks_M2 > 4/(200 - 3 - 1)), ]
[1] 91
    subject incidents    training    feedback empathy years  empathy_z years_m
13       13 0.9166667    training    feedback       9     7 -0.4631387   -1.13
35       35 0.7500000    training    feedback      13    13  1.1135036    4.87
74       74 0.1666667    training no feedback      15     8  1.9018247   -0.13
137     137 0.5833333 no training    feedback       6    18 -1.6456203    9.87
165     165 0.9166667 no training    feedback       9     3 -0.4631387   -5.13
Model2_sub <- lm(incidents ~ empathy_z + years_m + training, 
    data = data[-which(cooks_M2 > 4/(200 - 3 - 1)), ])
[1] 92
summary(Model2_sub)
[1] 93

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data[-which(cooks_M2 > 
    4/(200 - 3 - 1)), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28818 -0.11426 -0.00621  0.09990  0.40582 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.546086   0.015423  35.408  < 2e-16 ***
empathy_z         0.072319   0.011590   6.240 2.76e-09 ***
years_m          -0.016177   0.003838  -4.215 3.84e-05 ***
trainingtraining -0.153846   0.021969  -7.003 4.16e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1521 on 191 degrees of freedom
Multiple R-squared:  0.3042,	Adjusted R-squared:  0.2932 
F-statistic: 27.83 on 3 and 191 DF,  p-value: 5.621e-15

summary(Model2)
[1] 94

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
empathy_z         0.064430   0.012014   5.363 2.29e-07 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

qqPlot(Model2, main = "Figure 4: QQ-plot, Model 2")
[1] 95
hist(Model2$residuals, col = "lightblue", main = "Figure 5: Histogram \n     of Residuals, Model 2")
[1] 96
which(abs(Model2$residuals) > 0.4)
[1] 97
13 
13 
data[13, ]
[1] 98
   subject incidents training feedback empathy years  empathy_z years_m
13      13 0.9166667 training feedback       9     7 -0.4631387   -1.13
shapiro.test(Model2$residuals)
[1] 99

	Shapiro-Wilk normality test

data:  Model2$residuals
W = 0.97994, p-value = 0.005838

residualPlots(Model2, main = "Figure 6: Residual Plots, Model 2")
[1] 100
ncvTest(Model2)
[1] 101
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(Model2, main = "Figure 7: Component Residual Plots, Model 2")
[1] 102
durbinWatsonTest(Model2)
[1] 103
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.164
 Alternative hypothesis: rho != 0
vif(Model2)
[1] 104
empathy_z   years_m  training 
 1.092467  1.085089  1.020633 
plot(data$incidents ~ data$feedback, ylab = "Percentage of Incidents Intervened", 
    xlab = "Feedback", main = "Incidents by Feedback", col = "lightblue")
[1] 105
describeBy(x = data$incidents, group = data$feedback)
[1] 106

 Descriptive statistics by group 
group: no feedback
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.41 0.17   0.42     0.4 0.12 0.08 0.92  0.83  0.6     0.36 0.02
--------------------------------------------------------------------------------------- 
group: feedback
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 100 0.54 0.18    0.5    0.53 0.25 0.08 0.92  0.83 0.11    -0.44 0.02
Model3 <- lm(incidents ~ empathy_z + years_m + feedback, data = data)
[1] 107
contrasts(data$feedback)
[1] 108
            feedback
no feedback        0
feedback           1
summary(Model3)
[1] 109

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
empathy_z         0.058827   0.012251   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

plot(Model3, which = 4)
[1] 110
abline(h = 4/(200 - 3 - 1), col = "red")
[1] 111
cooks_M3 <- cooks.distance(Model3)
[1] 112
which(cooks_M3 > 4/(200 - 3 - 1))
[1] 113
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
data[which(cooks_M3 > 4/(200 - 3 - 1)), ]
[1] 114
    subject  incidents    training    feedback empathy years empathy_z years_m
73       73 0.25000000    training    feedback      14    11  1.507664    2.87
74       74 0.16666667    training no feedback      15     8  1.901825   -0.13
89       89 0.08333333    training    feedback       6    15 -1.645620    6.87
137     137 0.58333333 no training    feedback       6    18 -1.645620    9.87
156     156 0.75000000 no training no feedback       7     6 -1.251460   -2.13
160     160 0.91666667 no training no feedback      12     6  0.719343   -2.13
 [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
Model3_sub <- lm(incidents ~ empathy_z + years_m + training, 
    data = data[-which(cooks_M3 > 4/(200 - 3 - 1)), ])
[1] 115
summary(Model3_sub)
[1] 116

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data[-which(cooks_M3 > 
    4/(200 - 3 - 1)), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30596 -0.11408 -0.00224  0.09663  0.52888 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.535697   0.015844  33.811  < 2e-16 ***
empathy_z         0.071948   0.012032   5.980 1.10e-08 ***
years_m          -0.014240   0.003979  -3.579 0.000439 ***
trainingtraining -0.130676   0.022442  -5.823 2.46e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1538 on 188 degrees of freedom
Multiple R-squared:  0.2532,	Adjusted R-squared:  0.2413 
F-statistic: 21.25 on 3 and 188 DF,  p-value: 6.764e-12

summary(Model3)
[1] 117

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
empathy_z         0.058827   0.012251   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

qqPlot(Model3, main = "Figure 8: QQ-Plot, Model 3")
[1] 118
hist(Model3$residuals, col = "lightblue", main = "Figure 9: Histogram of Residuals, Model 3")
[1] 119
shapiro.test(Model3$residuals)
[1] 120

	Shapiro-Wilk normality test

data:  Model3$residuals
W = 0.98772, p-value = 0.08174

residualPlots(Model3, main = "Figure 10: Residual Plots, Model 3")
[1] 121
ncvTest(Model3)
[1] 122
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(Model3, main = "Figure 11: Component Residual Plots, Model 3")
[1] 123
vif(Model3)
[1] 124
empathy_z   years_m  feedback 
 1.079397  1.077467  1.005211 
durbinWatsonTest(Model3)
[1] 125
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
AIC(Model2, Model3)
[1] 126
       df       AIC
Model2  5 -154.1654
Model3  5 -143.9591
BIC(Model2, Model3)
[1] 127
       df       BIC
Model2  5 -137.6738
Model3  5 -127.4675
abs(BIC(Model2, Model3)[1, 2]) - abs(BIC(Model2, Model3)[2, 2])
[1] 128
[1] 10.20629
summary(Model2)
[1] 129

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
empathy_z         0.064430   0.012014   5.363 2.29e-07 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

summary(Model3)
[1] 130

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
empathy_z         0.058827   0.012251   4.802 3.11e-06 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

lm.beta(Model2)
[1] 131

Call:
lm(formula = incidents ~ empathy_z + years_m + training, data = data)

Standardized Coefficients::
     (Intercept)        empathy_z          years_m trainingtraining 
       0.0000000        0.3452459       -0.2323812       -0.4094138 

lm.beta(Model3)
[1] 132

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback, data = data)

Standardized Coefficients::
     (Intercept)        empathy_z          years_m feedbackfeedback 
       0.0000000        0.3152254       -0.2093496        0.3549015 

describeBy(x = data$incidents, group = list(data$training, data$feedback))
[1] 133

 Descriptive statistics by group 
: no training
: no feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.49 0.17   0.42    0.48 0.12 0.25 0.92  0.67 0.82    -0.07 0.02
--------------------------------------------------------------------------------------- 
: training
: no feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.33 0.14   0.33    0.33 0.12 0.08 0.58   0.5 0.15    -0.96 0.02
--------------------------------------------------------------------------------------- 
: no training
: feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.59 0.17   0.58    0.59 0.12 0.25 0.92  0.67 0.05    -0.81 0.02
--------------------------------------------------------------------------------------- 
: training
: feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.48 0.17    0.5    0.48 0.12 0.08 0.92  0.83 0.23    -0.07 0.02
Model4 <- lm(incidents ~ empathy_z + years_m + feedback + training + 
    feedback:training, data = data)
[1] 134
summary(Model4)
[1] 135

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback + training + 
    feedback:training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
empathy_z                          0.072800   0.010981   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
feedbackfeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingtraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackfeedback:trainingtraining  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

contrasts(data$feedback)
[1] 136
            feedback
no feedback        0
feedback           1
contrasts(data$training)
[1] 137
            training
no training        0
training           1
cat_plot(model = Model4, pred = training, modx = feedback, geom = "line", 
    point.shape = TRUE, pred.labels = c("No Training", "Training"), 
    modx.labels = c("No Feedback", "Feedback"), y.label = "Incidents Intevened")
[1] 138
summary(Model4)
[1] 139

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback + training + 
    feedback:training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
empathy_z                          0.072800   0.010981   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
feedbackfeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingtraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackfeedback:trainingtraining  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

plot(Model4, which = 4)
[1] 140
cooks_M4 <- cooks.distance(Model4)
[1] 141
abline(h = 4/(200 - 4 - 1), col = "red")
[1] 142
which(cooks_M4 > 4/(200 - 4 - 1))
[1] 143
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
data[which(cooks_M4 > 4/(200 - 4 - 1)), ]
[1] 144
    subject  incidents    training    feedback empathy years  empathy_z years_m
13       13 0.91666667    training    feedback       9     7 -0.4631387   -1.13
73       73 0.25000000    training    feedback      14    11  1.5076641    2.87
74       74 0.16666667    training no feedback      15     8  1.9018247   -0.13
89       89 0.08333333    training    feedback       6    15 -1.6456203    6.87
117     117 0.33333333 no training    feedback       9     4 -0.4631387   -4.13
137     137 0.58333333 no training    feedback       6    18 -1.6456203    9.87
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
Model4_sub <- lm(incidents ~ empathy_z + years_m + feedback + 
    training + feedback:training, data = data[-which(cooks_M4 > 
    4/(200 - 4 - 1)), ])
[1] 145
summary(Model4_sub)
[1] 146

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback + training + 
    feedback:training, data = data[-which(cooks_M4 > 4/(200 - 
    4 - 1)), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28269 -0.09632  0.00081  0.09067  0.34167 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.494958   0.019144  25.855  < 2e-16 ***
empathy_z                          0.078239   0.010409   7.516 2.35e-12 ***
years_m                           -0.016135   0.003427  -4.708 4.89e-06 ***
feedbackfeedback                   0.094956   0.027103   3.504 0.000576 ***
trainingtraining                  -0.184679   0.027340  -6.755 1.80e-10 ***
feedbackfeedback:trainingtraining  0.084936   0.038572   2.202 0.028899 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1315 on 185 degrees of freedom
Multiple R-squared:  0.4496,	Adjusted R-squared:  0.4348 
F-statistic: 30.23 on 5 and 185 DF,  p-value: < 2.2e-16

summary(Model4)
[1] 147

Call:
lm(formula = incidents ~ empathy_z + years_m + feedback + training + 
    feedback:training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
empathy_z                          0.072800   0.010981   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
feedbackfeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingtraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackfeedback:trainingtraining  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

qqPlot(Model4, main = "Figure 12: QQ-plot, Model 4")
[1] 148
hist(Model4$residuals, col = "lightblue", main = "Figure 13: Histogram of Residuals, Model 4")
[1] 149
shapiro.test(Model4$residuals)
[1] 150

	Shapiro-Wilk normality test

data:  Model4$residuals
W = 0.98794, p-value = 0.08817

residualPlots(Model4, main = "Figure 14: Residual Plots, Model 4")
[1] 151
ncvTest(Model4)
[1] 152
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
durbinWatsonTest(Model4)
[1] 153
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.148
 Alternative hypothesis: rho != 0
vif(Model4)
[1] 154
        empathy_z           years_m          feedback          training feedback:training 
         1.122147          1.092150          2.007327          2.086826          3.070068 
