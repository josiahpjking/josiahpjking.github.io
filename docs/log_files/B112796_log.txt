

	####### B112796 R script #######

rm(list = ls())
[1] 1
data <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 2
install.packages("psych")
[1] 3
install.packages("car")
[1] 4
install.packages("carData")
[1] 5
install.packages("MASS")
[1] 6
install.packages("interactions")
[1] 7
install.packages("sandwich")
[1] 8
library("psych", quietly = T)
[1] 9
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library("car", quietly = T)
[1] 10
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library("carData", quietly = T)
[1] 11
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library("interactions", quietly = T)
[1] 12
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"     "grDevices"   
 [9] "utils"        "datasets"     "methods"      "base"        
library("sandwich", quietly = T)
[1] 13
 [1] "sandwich"     "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [9] "grDevices"    "utils"        "datasets"     "methods"      "base"        
str(data)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
describe(data)
[1] 15
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
f.feedback <- factor(data$feedback)
[1] 16
is.factor(f.feedback)
[1] 17
[1] TRUE
levels(f.feedback)
[1] 18
[1] "1" "2"
f.training <- factor(data$training)
[1] 19
is.factor(f.training)
[1] 20
[1] TRUE
levels(f.training)
[1] 21
[1] "1" "2"
f.training <- factor(f.training, labels = c("No Training", "Training"))
[1] 22
levels(f.training)
[1] 23
[1] "No Training" "Training"   
f.feedback <- factor(f.feedback, labels = c("No Feedback", "Feedback"))
[1] 24
levels(f.feedback)
[1] 25
[1] "No Feedback" "Feedback"   
m0 <- lm(empathy ~ years, data = data)
[1] 26
summary(m0)
[1] 27

Call:
lm(formula = empathy ~ years, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.40625    0.49085  17.126  < 2e-16 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

strsd0 <- MASS::studres(m0)
[1] 28
which(abs(strsd0) > 2)
[1] 29
 61  68  70  88  89 137 141 142 154 175 200 
 61  68  70  88  89 137 141 142 154 175 200 
hats0 <- hatvalues(m0)
[1] 30
hats0

          1           2           3           4           5           6           7           8           9          10 
0.006853526 0.005676819 0.010192832 0.005676819 0.012938483 0.006853526 0.005008958 0.006853526 0.005676819 0.005401194 
         11          12          13          14          15          16          17          18          19          20 
0.007404777 0.009365956 0.005676819 0.005676819 0.005676819 0.018949232 0.017571106 0.005676819 0.010192832 0.012938483 
         21          22          23          24          25          26          27          28          29          30 
0.009365956 0.014040983 0.005008958 0.005676819 0.005676819 0.007404777 0.005676819 0.005676819 0.007404777 0.010192832 
         31          32          33          34          35          36          37          38          39          40 
0.005676819 0.005008958 0.010192832 0.005401194 0.017571106 0.010192832 0.014040983 0.010192832 0.009365956 0.010192832 
         41          42          43          44          45          46          47          48          49          50 
0.010192832 0.005401194 0.012938483 0.014040983 0.010192832 0.005008958 0.007404777 0.007404777 0.007404777 0.014040983 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats0 > 2 * mean(hats0))
[1] 32
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
plot(hats0)
[1] 33
cooks0 <- cooks.distance(m0)
[1] 34
plot(cooks0, ylim = c(0, 0.1))
[1] 35
plot(m0, which = 4)
[1] 36
d.0 <- 4/(200 - 3 - 1)
[1] 37
d.0

[1] 0.02040816


which(cooks0 > d.0)
[1] 39
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
posCVR.0 <- 1 + (3 * 2)/200
[1] 40
posCVR.0

[1] 1.03


negCVR.0 <- 1 - (3 * 2)/200
[1] 42
negCVR.0

[1] 0.97


CVRs.0 <- covratio(m0)
[1] 44
which(CVRs.0 > posCVR.0 | CVRs.0 < negCVR.0)
[1] 45
 68 109 142 175 190 
 68 109 142 175 190 
plot(data$empathy, data$years, xlab = "Empathy Score", ylab = "Years of Experience", 
    main = "Relationship between Empathy and Years")
[1] 46
crPlots(m0)
[1] 47
m0a <- lm(empathy ~ years + I(years^2), data = data)
[1] 48
summary(m0a)
[1] 49

Call:
lm(formula = empathy ~ years + I(years^2), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.186356   0.791848   1.498    0.136    
years        2.068508   0.181845  11.375   <2e-16 ***
I(years^2)  -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

crPlots(m0a)
[1] 50
hist(m0a$residuals, main = "Histogram of m0a Normally Distributed Error")
[1] 51
qqPlot(m0a$residuals, main = "QQ-plot of m0a Normally Distributed Error")
[1] 52
describe(m0a$residuals)
[1] 53
   vars   n mean   sd median trimmed mad   min  max range skew kurtosis   se
X1    1 200    0 1.96  -0.08       0 1.9 -4.51 6.06 10.57 0.09    -0.12 0.14
shapiro.test(m0a$residuals)
[1] 54

	Shapiro-Wilk normality test

data:  m0a$residuals
W = 0.9941, p-value = 0.6155

residualPlots(m0a, main = "Residual Plots for Homoscedasticity")
[1] 55
ncvTest(m0a)
[1] 56
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(m0a)
[1] 57
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.884
 Alternative hypothesis: rho != 0
summary(m0a)
[1] 58

Call:
lm(formula = empathy ~ years + I(years^2), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.186356   0.791848   1.498    0.136    
years        2.068508   0.181845  11.375   <2e-16 ***
I(years^2)  -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

m1 <- lm(incidents ~ empathy + years + f.training, data = data)
[1] 59
summary(m1)
[1] 60

Call:
lm(formula = incidents ~ empathy + years + f.training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.407320   0.051814   7.861 2.48e-13 ***
empathy             0.025396   0.004735   5.363 2.29e-07 ***
years              -0.014085   0.003889  -3.622 0.000372 ***
f.trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

strsd.1 <- MASS::studres(m1)
[1] 61
which(abs(strsd.1) > 2)
[1] 62
  7  13  35  74 159 165 176 181 
  7  13  35  74 159 165 176 181 
hats.1 <- hatvalues(m1)
[1] 63
hats.1

         1          2          3          4          5          6          7          8          9         10         11 
0.01228875 0.01050612 0.01460984 0.01175403 0.01917551 0.01228875 0.01552392 0.02045647 0.01312775 0.01209596 0.01282306 
        12         13         14         15         16         17         18         19         20         21         22 
0.01887947 0.01175403 0.01312775 0.01175403 0.03896604 0.02934399 0.01175403 0.01460984 0.02037708 0.01610229 0.01838715 
        23         24         25         26         27         28         29         30         31         32         33 
0.01017972 0.01312775 0.01096403 0.01536910 0.01096403 0.01312775 0.01198283 0.03408432 0.01470775 0.01552392 0.01509311 
        34         35         36         37         38         39         40         41         42         43         44 
0.01209596 0.02541158 0.01460984 0.02029486 0.01876074 0.02205168 0.02117709 0.02117709 0.01209596 0.01892339 0.02380744 
        45         46         47         48         49         50 
0.02117709 0.01017972 0.01282306 0.01536910 0.01284842 0.02380744 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats.1 > 2 * mean(hats.1))
[1] 65
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
plot(hats.1)
[1] 66
cooks1 <- cooks.distance(m1)
[1] 67
plot(cooks1, ylim = c(0, 0.1))
[1] 68
plot(m1, which = 4)
[1] 69
d.1 <- 4/(200 - 3 - 1)
[1] 70
d.1

[1] 0.02040816


which(cooks1 > d.1)
[1] 72
 13  35  74 137 165 
 13  35  74 137 165 
posCVR.1 <- 1 + (3 * 4)/200
[1] 73
posCVR.1

[1] 1.06


negCVR.1 <- 1 - (3 * 4)/200
[1] 75
negCVR.1

[1] 0.94


CVRs.1 <- covratio(m1)
[1] 77
which(CVRs.1 > posCVR.1 | CVRs.1 < negCVR.1)
[1] 78
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
qqPlot(m1$residuals, main = "QQ-plot of m1 residuals")
[1] 79
hist(m1$residuals, main = "Histogram of m1 residuals")
[1] 80
describe(m1$residuals)
[1] 81
   vars   n mean   sd median trimmed  mad   min  max range skew kurtosis   se
X1    1 200    0 0.16  -0.01   -0.01 0.16 -0.36 0.53  0.89 0.47     -0.1 0.01
shapiro.test(m1$residuals)
[1] 82

	Shapiro-Wilk normality test

data:  m1$residuals
W = 0.97994, p-value = 0.005838

data$logincidents <- log(data$incidents + 1)
[1] 83
data$logincidents
[1] 84
 [1] 0.51082562 0.28768207 0.28768207 0.34830669 0.40546511 0.22314355 0.60613580 0.34830669 0.40546511 0.15415068
[11] 0.55961579 0.28768207 0.65058757 0.40546511 0.45953233 0.15415068 0.15415068 0.28768207 0.55961579 0.34830669
[21] 0.15415068 0.34830669 0.34830669 0.45953233 0.34830669 0.22314355 0.40546511 0.28768207 0.34830669 0.08004271
[31] 0.28768207 0.40546511 0.28768207 0.34830669 0.55961579 0.34830669 0.40546511 0.45953233 0.45953233 0.15415068
[41] 0.51082562 0.34830669 0.28768207 0.22314355 0.34830669 0.22314355 0.45953233 0.45953233 0.40546511 0.15415068
 [ reached getOption("max.print") -- omitted 150 entries ]
describe(data$logincidents)
[1] 85
   vars   n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 200 0.38 0.13   0.35    0.38 0.09 0.08 0.65  0.57 0.02    -0.37 0.01
m2 <- lm(data$logincidents ~ empathy + years + f.training, data = data)
[1] 86
summary(m2)
[1] 87

Call:
lm(formula = data$logincidents ~ empathy + years + f.training, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.25974 -0.08206 -0.00301  0.07026  0.33183 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.334118   0.034793   9.603  < 2e-16 ***
empathy             0.017470   0.003180   5.494 1.21e-07 ***
years              -0.009683   0.002611  -3.708 0.000272 ***
f.trainingTraining -0.104810   0.015556  -6.737 1.75e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1089 on 196 degrees of freedom
Multiple R-squared:  0.2657,	Adjusted R-squared:  0.2544 
F-statistic: 23.63 on 3 and 196 DF,  p-value: 4.229e-13

qqPlot(m2$residuals, main = "QQ-plot of m2 residuals ")
[1] 88
hist(m2$residuals, main = "Histogram of m2 residuals")
[1] 89
describe(m2$residuals)
[1] 90
   vars   n mean   sd median trimmed  mad   min  max range skew kurtosis   se
X1    1 200    0 0.11      0       0 0.11 -0.26 0.33  0.59 0.23    -0.34 0.01
shapiro.test(m2$residuals)
[1] 91

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.9901, p-value = 0.1845

residualPlots(m2, main = "Residual Plots for m2")
[1] 92
ncvTest(m2)
[1] 93
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.8932792, Df = 1, p = 0.34459
crPlots(m2, main = "Component Residuals Plots for m2")
[1] 94
plot(m2, which = 1, main = "Residual vs Fitted Values of m2")
[1] 95
durbinWatsonTest(m2)
[1] 96
 lag Autocorrelation D-W Statistic p-value
   1      -0.1160146      2.216759   0.158
 Alternative hypothesis: rho != 0
vif(m2)
[1] 97
   empathy      years f.training 
  1.092467   1.085089   1.020633 
summary(m2)
[1] 98

Call:
lm(formula = data$logincidents ~ empathy + years + f.training, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.25974 -0.08206 -0.00301  0.07026  0.33183 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.334118   0.034793   9.603  < 2e-16 ***
empathy             0.017470   0.003180   5.494 1.21e-07 ***
years              -0.009683   0.002611  -3.708 0.000272 ***
f.trainingTraining -0.104810   0.015556  -6.737 1.75e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1089 on 196 degrees of freedom
Multiple R-squared:  0.2657,	Adjusted R-squared:  0.2544 
F-statistic: 23.63 on 3 and 196 DF,  p-value: 4.229e-13

m3 <- lm(incidents ~ empathy + years + f.feedback, data = data)
[1] 99
summary(m3)
[1] 100

Call:
lm(formula = incidents ~ empathy + years + f.feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.276161   0.054108   5.104 7.84e-07 ***
empathy             0.023187   0.004829   4.802 3.11e-06 ***
years              -0.012689   0.003975  -3.192  0.00165 ** 
f.feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

strsd2 <- MASS::studres(m3)
[1] 101
strsd2

          1           2           3           4           5           6           7           8           9          10 
 0.78668687 -0.51808660 -1.47947681  0.12449141 -0.20751190 -0.93321229  1.36850378 -0.34695885 -0.59095552 -1.66218321 
         11          12          13          14          15          16          17          18          19          20 
 0.98565350 -0.07224569  2.37666165  0.20779062  0.33283507 -1.14959283 -1.74713875 -0.37827327  1.05038041  0.36890741 
         21          22          23          24          25          26          27          28          29          30 
-2.03835911 -0.24591225 -0.73623624  0.71184711 -0.95464175 -1.38676214 -0.44989793 -0.79985404 -0.89121794 -1.50466822 
         31          32          33          34          35          36          37          38          39          40 
-1.03908276  0.14456629 -1.33697404 -0.14207678  1.25139850 -0.16873342 -0.26081004  0.55982042 -0.06073259 -1.26782458 
         41          42          43          44          45          46          47          48          49          50 
 0.96856634 -0.14207678 -1.07860769 -0.83724085 -0.54861653 -0.94553477 -0.02348923  0.63573364 -0.24657473 -1.34767952 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(abs(strsd2) > 2)
[1] 103
 13  21  73  74 150 156 159 160 165 176 181 
 13  21  73  74 150 156 159 160 165 176 181 
hats.2 <- hatvalues(m3)
[1] 104
hats.2

         1          2          3          4          5          6          7          8          9         10         11 
0.01193805 0.01056890 0.01591194 0.01155352 0.01862431 0.01211540 0.01766517 0.02100490 0.01499209 0.01233851 0.01440768 
        12         13         14         15         16         17         18         19         20         21         22 
0.01792139 0.01130286 0.01365588 0.01130286 0.03834202 0.02573877 0.01155352 0.01591194 0.01953690 0.01442435 0.01889473 
        23         24         25         26         27         28         29         30         31         32         33 
0.01002816 0.01365588 0.01207695 0.01602790 0.01207695 0.01365588 0.01280846 0.03305959 0.01344393 0.01612821 0.01562865 
        34         35         36         37         38         39         40         41         42         43         44 
0.01233851 0.02516110 0.01497723 0.02053750 0.01954213 0.02354412 0.02077043 0.02011827 0.01233851 0.01755655 0.02357949 
        45         46         47         48         49         50 
0.02011827 0.01007806 0.01440768 0.01602790 0.01289465 0.02357949 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats.2 > 2 * mean(hats.2))
[1] 106
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
plot(hats.2)
[1] 107
cooks2 <- cooks.distance(m3)
[1] 108
plot(cooks2, ylim = c(0, 0.1))
[1] 109
plot(m3, which = 4)
[1] 110
d.2 <- 4/(200 - 3 - 1)
[1] 111
d.2

[1] 0.02040816


which(cooks2 > d.2, )
[1] 113
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
posCVR.2 <- 1 + (3 * 4)/200
[1] 114
posCVR.2

[1] 1.06


negCVR.2 <- 1 - (3 * 4)/200
[1] 116
negCVR.2

[1] 0.94


CVRs.2 <- covratio(m3)
[1] 118
which(CVRs.2 > posCVR.2 | CVRs.2 < negCVR.2)
[1] 119
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
qqPlot(m3$residuals, main = "QQ-plot of m3 Residuals")
[1] 120
hist(m3$residuals, main = "Histogram of m3 Residuals")
[1] 121
shapiro.test(m3$residuals)
[1] 122

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.98772, p-value = 0.08174

describe(m3$residuals)
[1] 123
   vars   n mean   sd median trimmed  mad   min  max range skew kurtosis   se
X1    1 200    0 0.17  -0.01   -0.01 0.17 -0.36 0.54  0.89 0.41      0.1 0.01
residualPlots(m3, main = "Residual Plots of m3")
[1] 124
ncvTest(m3)
[1] 125
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(m3, main = "Component-Residual Plots for m3")
[1] 126
vif(m3)
[1] 127
   empathy      years f.feedback 
  1.079397   1.077467   1.005211 
durbinWatsonTest(m3)
[1] 128
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
summary(m3)
[1] 129

Call:
lm(formula = incidents ~ empathy + years + f.feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                    Estimate Std. Error t value Pr(>|t|)    
(Intercept)         0.276161   0.054108   5.104 7.84e-07 ***
empathy             0.023187   0.004829   4.802 3.11e-06 ***
years              -0.012689   0.003975  -3.192  0.00165 ** 
f.feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

comparison <- AIC(m2, m3)
[1] 130
comparison

   df       AIC
m2  5 -313.4627
m3  5 -143.9591


comparison2 <- BIC(m2, m3)
[1] 132
comparison2

   df       BIC
m2  5 -296.9711
m3  5 -127.4675


m4 <- lm(incidents ~ f.training + f.feedback + f.training * f.feedback, 
    data = data)
[1] 134
summary(m4)
[1] 135

Call:
lm(formula = incidents ~ f.training + f.feedback + f.training * 
    f.feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)                            0.49333    0.02314  21.323  < 2e-16 ***
f.trainingTraining                    -0.16000    0.03272  -4.890 2.09e-06 ***
f.feedbackFeedback                     0.09667    0.03272   2.954  0.00352 ** 
f.trainingTraining:f.feedbackFeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

cat_plot((m4), pred = f.training, modx = f.feedback, main = "Plot of the Interaction between Training and Feedback")
[1] 136
