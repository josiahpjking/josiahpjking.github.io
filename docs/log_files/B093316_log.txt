

	####### B093316 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 2
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(interactions, quietly = T)
[1] 3
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [8] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(sandwich, quietly = T)
[1] 4
 [1] "sandwich"     "interactions" "car"          "carData"      "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
df <- read.csv("../RMS2_report_1920.csv")
[1] 5
des <- describe(df)
[1] 6
des[, c(3, 4, 5, 8, 9, 10)]
[1] 7
            mean    sd median  min    max  range
subject   100.50 57.88 100.50 1.00 200.00 199.00
incidents   0.48  0.19   0.42 0.08   0.92   0.83
training    1.50  0.50   1.50 1.00   2.00   1.00
feedback    1.50  0.50   1.50 1.00   2.00   1.00
empathy    10.18  2.54  10.00 3.00  16.00  13.00
years       8.13  3.08   8.00 1.00  19.00  18.00
str(df)
[1] 8
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
par(mfrow = c(1, 1))
[1] 9
$mfrow
[1] 2 2

df$training
[1] 10
 [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [ reached getOption("max.print") -- omitted 150 entries ]
df$training <- as.factor(df$training)
[1] 11
df$training
[1] 12
 [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: 1 2
df$training <- factor(df$training, levels = c(1, 2), labels = c("No Training", 
    "Training"))
[1] 13
df$training
[1] 14
 [1] Training Training Training Training Training Training Training Training Training Training Training Training
[13] Training Training Training Training Training Training Training Training Training Training Training Training
[25] Training Training Training Training Training Training Training Training Training Training Training Training
[37] Training Training Training Training Training Training Training Training Training Training Training Training
[49] Training Training
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: No Training Training
df$feedback
[1] 15
 [1] 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1
 [ reached getOption("max.print") -- omitted 150 entries ]
df$feedback <- as.factor(df$feedback)
[1] 16
df$feedback
[1] 17
 [1] 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: 1 2
df$feedback <- factor(df$feedback, levels = c(1, 2), labels = c("No Feedback", 
    "Feedback"))
[1] 18
df$feedback
[1] 19
 [1] Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback   
[10] No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback
[19] Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback   
[28] No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback
[37] Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback    No Feedback Feedback   
[46] No Feedback Feedback    No Feedback Feedback    No Feedback
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: No Feedback Feedback
years_m <- df$years - mean(df$years)
[1] 20
emp_m <- df$empathy - mean(df$empathy)
[1] 21
plot(df$years, df$empathy, xlab = "Years of Experience", ylab = "Empathy Score", 
    main = "Empathy Score plotted against Years of Teaching Experience", 
    pch = 16)
[1] 22
abline(lm(df$empathy ~ df$years), col = "red")
[1] 23
m1 <- lm(empathy ~ years, data = df)
[1] 24
summary(m1)
[1] 25

Call:
lm(formula = empathy ~ years, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.40625    0.49085  17.126  < 2e-16 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

shapiro.test(m1$residuals)
[1] 26

	Shapiro-Wilk normality test

data:  m1$residuals
W = 0.98911, p-value = 0.1321

qqPlot(m1, main = "Model 1: Quantile-Quantile Plot")
[1] 27
hist(m1$residuals, main = "Model 1: Histogram of Residuals", 
    ylab = "Frequency", xlab = "Residuals")
[1] 28
residualPlots(m1, main = "Model 1: Residuals vs Fitted Values")
[1] 29
ncvTest(m1)
[1] 30
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
crPlots(m1, main = "Model 1: Component-Residuals Plot")
[1] 31
durbinWatsonTest(m1)
[1] 32
 lag Autocorrelation D-W Statistic p-value
   1       0.1017162      1.769879   0.114
 Alternative hypothesis: rho != 0
p_years <- poly(years_m, 2, raw = TRUE)
[1] 33
m1_tr <- lm(df$empathy ~ p_years)
[1] 34
summary(m1_tr)
[1] 35

Call:
lm(formula = df$empathy ~ p_years)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.152696   0.167423  66.614  < 2e-16 ***
p_years1     0.383236   0.047986   7.986 1.13e-13 ***
p_years2    -0.103645   0.009861 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

shapiro.test(m1_tr$residuals)
[1] 36

	Shapiro-Wilk normality test

data:  m1_tr$residuals
W = 0.9941, p-value = 0.6155

qqPlot(m1_tr, main = "Model 1a: Quantile-Quantile Plot")
[1] 37
hist(m1_tr$residuals, main = "Model 1a: Histogram of Residuals", 
    xlab = "Residuals")
[1] 38
residualPlots(m1_tr)
[1] 39
ncvTest(m1_tr)
[1] 40
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
crPlots(m1_tr, main = "Model 1a: Components-Residual Plot")
[1] 41
durbinWatsonTest(m1_tr)
[1] 42
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.866
 Alternative hypothesis: rho != 0
cook <- cooks.distance(m1_tr)
[1] 43
plot(cook, main = "Model 1a: Cook's Distance")
[1] 44
abline(a = (4/(200 - 2 - 1)), b = 0, col = "red")
[1] 45
dfa1 <- df[which(cook < 4/(200 - 2 - 1)), ]
[1] 46
years_m_a <- scale(dfa1$years, scale = FALSE)
[1] 47
pa1_years <- poly(years_m_a, 2, raw = TRUE)
[1] 48
m1a_tr <- lm(empathy ~ pa1_years, data = dfa1)
[1] 49
summary(m1a_tr)
[1] 50

Call:
lm(formula = empathy ~ pa1_years, data = dfa1)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5344 -1.1205  0.1144  1.2235  4.8795 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.14647    0.17286  64.484  < 2e-16 ***
pa1_years1   0.40894    0.05089   8.036 9.80e-14 ***
pa1_years2  -0.10772    0.01353  -7.962 1.54e-13 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.912 on 189 degrees of freedom
Multiple R-squared:  0.3587,	Adjusted R-squared:  0.3519 
F-statistic: 52.86 on 2 and 189 DF,  p-value: < 2.2e-16

summary(m1_tr)
[1] 51

Call:
lm(formula = df$empathy ~ p_years)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) 11.152696   0.167423  66.614  < 2e-16 ***
p_years1     0.383236   0.047986   7.986 1.13e-13 ***
p_years2    -0.103645   0.009861 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

par(mfrow = c(1, 2))
[1] 52
$mfrow
[1] 1 1

boxplot(df$incidents ~ df$training, xlab = "Training or No Training", 
    ylab = "Percentage of Interventions", col = c("red", "blue"))
[1] 53
boxplot(df$incidents ~ df$feedback, xlab = "Feedback or No Feedback", 
    ylab = "Percentage of Feedback", col = c("orange", "light blue"))
[1] 54
dev.copy(png, "Q3 Distribution.png")
[1] 55
dev.off()
[1] 56
m2 <- lm(incidents ~ training + years_m + emp_m, data = df)
[1] 57
summary(m2)
[1] 58

Call:
lm(formula = incidents ~ training + years_m + emp_m, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
emp_m             0.025396   0.004735   5.363 2.29e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

par(mfrow = c(1, 1))
[1] 59
$mfrow
[1] 1 2

shapiro.test(m2$residuals)
[1] 60

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.97994, p-value = 0.005838

qqPlot(m2, main = "Model 2: Quantile-Quantile Plot")
[1] 61
hist(m2$residuals, main = "Model 2: Histogram of Residuals", 
    xlab = "Residuals")
[1] 62
residualPlots(m2)
[1] 63
ncvTest(m2)
[1] 64
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(m2)
[1] 65
durbinWatsonTest(m2)
[1] 66
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.172
 Alternative hypothesis: rho != 0
vif(m2)
[1] 67
training  years_m    emp_m 
1.020633 1.085089 1.092467 
cook2 <- cooks.distance(m2)
[1] 68
plot(cook2, main = "Model 2: Cook's Distance")
[1] 69
abline(a = (4/(200 - 3 - 1)), b = 0, col = "red")
[1] 70
which(cook2 > 4/(200 - 3 - 1))
[1] 71
 13  35  74 137 165 
 13  35  74 137 165 
dfa2 <- df[which(cook2 < 4/(200 - 3 - 1)), ]
[1] 72
years_ma2 <- scale(dfa2$years, scale = FALSE)
[1] 73
emp_ma2 <- scale(dfa2$empathy, scale = FALSE)
[1] 74
m2a <- lm(incidents ~ training + years_ma2 + emp_ma2, data = dfa2)
[1] 75
summary(m2a)
[1] 76

Call:
lm(formula = incidents ~ training + years_ma2 + emp_ma2, data = dfa2)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28818 -0.11426 -0.00621  0.09990  0.40582 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.546614   0.015431  35.423  < 2e-16 ***
trainingTraining -0.153846   0.021969  -7.003 4.16e-11 ***
years_ma2        -0.016177   0.003838  -4.215 3.84e-05 ***
emp_ma2           0.028505   0.004568   6.240 2.76e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1521 on 191 degrees of freedom
Multiple R-squared:  0.3042,	Adjusted R-squared:  0.2932 
F-statistic: 27.83 on 3 and 191 DF,  p-value: 5.621e-15

summary(m2)
[1] 77

Call:
lm(formula = incidents ~ training + years_m + emp_m, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
emp_m             0.025396   0.004735   5.363 2.29e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

contrasts(df$feedback)
[1] 78
            Feedback
No Feedback        0
Feedback           1
contrasts(df$training)
[1] 79
            Training
No Training        0
Training           1
contrasts(df$feedback)
[1] 80
            Feedback
No Feedback        0
Feedback           1
m3 <- lm(incidents ~ feedback + training + emp_m + years_m, data = df)
[1] 81
summary(m3)
[1] 82

Call:
lm(formula = incidents ~ feedback + training + emp_m + years_m, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.485055   0.018126  26.760  < 2e-16 ***
feedbackFeedback  0.133715   0.020968   6.377 1.28e-09 ***
trainingTraining -0.153824   0.021128  -7.281 7.98e-12 ***
emp_m             0.027191   0.004328   6.283 2.12e-09 ***
years_m          -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

shapiro.test(m3$residuals)
[1] 83

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.98734, p-value = 0.07172

qqPlot(m3, main = "Model 3:Quantile-Quantile Plot")
[1] 84
hist(m3$residuals, main = "Model 3: Histogram of Residuals", 
    xlab = "Residuals")
[1] 85
residualPlots(m3)
[1] 86
ncvTest(m3)
[1] 87
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 3.684027, Df = 1, p = 0.054936
crPlots(m3)
[1] 88
durbinWatsonTest(m3)
[1] 89
 lag Autocorrelation D-W Statistic p-value
   1      0.07303546      1.841386   0.262
 Alternative hypothesis: rho != 0
vif(m3)
[1] 90
feedback training    emp_m  years_m 
1.005320 1.020743 1.097109 1.087722 
cook3 <- cooks.distance(m3)
[1] 91
plot(cook3, main = "Model 3: Cook's Distance")
[1] 92
abline(a = (4/(200 - 4 - 1)), b = 0, col = "red")
[1] 93
dfa3 <- df[which(cook3 < 4/(200 - 4 - 1)), ]
[1] 94
which(cook3 > 4/(200 - 4 - 1))
[1] 95
 13  35  74 117 131 137 141 156 160 176 
 13  35  74 117 131 137 141 156 160 176 
years_ma3 <- scale(dfa3$years, scale = FALSE)
[1] 96
emp_ma3 <- scale(dfa3$empathy, scale = FALSE)
[1] 97
m3a <- lm(incidents ~ feedback + training + emp_ma3 + years_ma3, 
    data = dfa3)
[1] 98
summary(m3a)
[1] 99

Call:
lm(formula = incidents ~ feedback + training + emp_ma3 + years_ma3, 
    data = dfa3)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30197 -0.09301 -0.00430  0.09141  0.36025 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.477738   0.016536  28.890  < 2e-16 ***
feedbackFeedback  0.140371   0.019014   7.383 5.12e-12 ***
trainingTraining -0.153419   0.019134  -8.018 1.19e-13 ***
emp_ma3           0.028642   0.004022   7.121 2.30e-11 ***
years_ma3        -0.017718   0.003365  -5.266 3.85e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.131 on 185 degrees of freedom
Multiple R-squared:  0.4702,	Adjusted R-squared:  0.4588 
F-statistic: 41.05 on 4 and 185 DF,  p-value: < 2.2e-16

summary(m3)
[1] 100

Call:
lm(formula = incidents ~ feedback + training + emp_m + years_m, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.485055   0.018126  26.760  < 2e-16 ***
feedbackFeedback  0.133715   0.020968   6.377 1.28e-09 ***
trainingTraining -0.153824   0.021128  -7.281 7.98e-12 ***
emp_m             0.027191   0.004328   6.283 2.12e-09 ***
years_m          -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

m5 <- lm(incidents ~ emp_m + years_m + training + feedback + 
    training:feedback, data = df)
[1] 101
summary(m5)
[1] 102

Call:
lm(formula = incidents ~ emp_m + years_m + training + feedback + 
    training:feedback, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
emp_m                              0.028695   0.004328   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

shapiro.test(m5$residuals)
[1] 103

	Shapiro-Wilk normality test

data:  m5$residuals
W = 0.98794, p-value = 0.08817

qqPlot(m5, main = "Model 4: Quantile-Quantile Plot")
[1] 104
hist(m5$residuals, main = "Model 4: Histogram of Residuals", 
    xlab = "Residuals")
[1] 105
residualPlots(m5)
[1] 106
ncvTest(m5)
[1] 107
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
durbinWatsonTest(m5)
[1] 108
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.188
 Alternative hypothesis: rho != 0
vif(m5)
[1] 109
            emp_m           years_m          training          feedback training:feedback 
         1.122147          1.092150          2.086826          2.007327          3.070068 
cook5 <- cooks.distance(m5)
[1] 110
plot(cook5, main = "Model 4: Cook's Distance")
[1] 111
abline(a = (4/(200 - 5 - 1)), b = 0, col = "red")
[1] 112
which(cook5 > 4/(200 - 5 - 1))
[1] 113
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
dfa5 <- df[which(cook5 < 4/(200 - 5 - 1)), ]
[1] 114
years_ma5 <- scale(dfa5$years, scale = FALSE)
[1] 115
emp_ma5 <- scale(dfa5$empathy, scale = FALSE)
[1] 116
m5a <- lm(incidents ~ emp_ma5 + years_ma5 + training + feedback + 
    training:feedback, data = dfa5)
[1] 117
summary(m5a)
[1] 118

Call:
lm(formula = incidents ~ emp_ma5 + years_ma5 + training + feedback + 
    training:feedback, data = dfa5)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28269 -0.09632  0.00081  0.09067  0.34167 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.495958   0.019160  25.885  < 2e-16 ***
emp_ma5                            0.030839   0.004103   7.516 2.35e-12 ***
years_ma5                         -0.016135   0.003427  -4.708 4.89e-06 ***
trainingTraining                  -0.184679   0.027340  -6.755 1.80e-10 ***
feedbackFeedback                   0.094956   0.027103   3.504 0.000576 ***
trainingTraining:feedbackFeedback  0.084936   0.038572   2.202 0.028899 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1315 on 185 degrees of freedom
Multiple R-squared:  0.4496,	Adjusted R-squared:  0.4348 
F-statistic: 30.23 on 5 and 185 DF,  p-value: < 2.2e-16

summary(m5)
[1] 119

Call:
lm(formula = incidents ~ emp_m + years_m + training + feedback + 
    training:feedback, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
emp_m                              0.028695   0.004328   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

library(ggplot2, quietly = T)
[1] 120
 [1] "ggplot2"      "sandwich"     "interactions" "car"          "carData"      "psych"        "readr"       
 [8] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
ggplot(m5, aes(x = training, y = incidents, group = feedback, 
    colour = feedback)) + geom_line(stat = "summary", fun.y = "mean") + 
    geom_point(stat = "summary", fun.y = "mean")
[1] 121
df[c(13, 35, 74, 137, 165), ]
[1] 122
    subject incidents    training    feedback empathy years
13       13 0.9166667    Training    Feedback       9     7
35       35 0.7500000    Training    Feedback      13    13
74       74 0.1666667    Training No Feedback      15     8
137     137 0.5833333 No Training    Feedback       6    18
165     165 0.9166667 No Training    Feedback       9     3
hist(df$empathy)
[1] 123
hist(df$incidents)
[1] 124
