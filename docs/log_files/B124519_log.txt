

	####### B124519 R script #######

library(car, quietly = T)
[1] 1
 [1] "car"       "carData"   "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[10] "base"     
library(psych, quietly = T)
[1] 2
 [1] "psych"     "car"       "carData"   "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(lm.beta, quietly = T)
[1] 3
 [1] "lm.beta"   "psych"     "car"       "carData"   "readr"     "stats"     "graphics"  "grDevices" "utils"    
[10] "datasets"  "methods"   "base"     
rm(list = ls())
[1] 4
rms2 = read.csv("../RMS2_report_1920.csv", header = TRUE)
[1] 5
str(rms2)
[1] 6
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
str(rms2$training)
[1] 7
 int [1:200] 2 2 2 2 2 2 2 2 2 2 ...
NULL
is.factor(rms2$training)
[1] 8
[1] FALSE
rms2$training <- factor(rms2$training)
[1] 9
is.factor(rms2$training)
[1] 10
[1] TRUE
is.factor(rms2$feedback)
[1] 11
[1] FALSE
rms2$feedback <- factor(rms2$feedback)
[1] 12
is.factor(rms2$feedback)
[1] 13
[1] TRUE
levels(rms2$training)
[1] 14
[1] "1" "2"
table(rms2$training)
[1] 15

  1   2 
100 100 
rms2$training <- factor(rms2$training, labels = c("no training", 
    "training"))
[1] 16
levels(rms2$training)
[1] 17
[1] "no training" "training"   
table(rms2$training)
[1] 18

no training    training 
        100         100 
levels(rms2$feedback)
[1] 19
[1] "1" "2"
table(rms2$feedback)
[1] 20

  1   2 
100 100 
rms2$feedback <- factor(rms2$feedback, labels = c("no feedback", 
    "feedback"))
[1] 21
levels(rms2$feedback)
[1] 22
[1] "no feedback" "feedback"   
table(rms2$feedback)
[1] 23

no feedback    feedback 
        100         100 
summary(rms2)
[1] 24
    subject         incidents              training          feedback      empathy          years      
 Min.   :  1.00   Min.   :0.08333   no training:100   no feedback:100   Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 50.75   1st Qu.:0.33333   training   :100   feedback   :100   1st Qu.: 9.00   1st Qu.: 6.00  
 Median :100.50   Median :0.41667                                       Median :10.00   Median : 8.00  
 Mean   :100.50   Mean   :0.47500                                       Mean   :10.18   Mean   : 8.13  
 3rd Qu.:150.25   3rd Qu.:0.58333                                       3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :200.00   Max.   :0.91667                                       Max.   :16.00   Max.   :19.00  
hist(rms2$empathy, main = "Distribution of the variable 'empathy'", 
    xlab = "Proportion of empathy", ylab = "Frequency", col = "grey")
[1] 25
describe(rms2$empathy)
[1] 26
   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
X1    1 200 10.18 2.54     10   10.24 2.97   3  16    13 -0.37     0.23 0.18
hist(rms2$years, main = "Distribution of the variable 'years'", 
    xlab = "number of years", ylab = "Frequency", col = "grey")
[1] 27
describe(rms2$years)
[1] 28
   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se
X1    1 200 8.13 3.08      8    7.97 2.97   1  19    18 0.52     0.48 0.22
pairs.panels(rms2[, 5:6])
[1] 29
NULL
plot(rms2$empathy, rms2$years, main = "Relationship between empathy and years", 
    ylab = "measures od empathy", xlab = "teaching years by teachers ", 
    col = "blue", pch = 10)
[1] 30
qqplot(rms2$empathy, rms2$years, main = "results for the affect of measures of empathy to the years taken", 
    ylab = "meaaures of empathy", xlab = "teaching years by teachers")
[1] 31
cov(rms2$empathy, rms2$years)
[1] 32
[1] 2.062563
cor.test(rms2$empathy, rms2$years, method = "spearman")
[1] 33

	Spearman's rank correlation rho

data:  rms2$empathy and rms2$years
S = 923838, p-value = 9.723e-06
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho 
0.3071045 

M1 <- lm(rms2$incidents ~ rms2$training + rms2$feedback + rms2$empathy + 
    rms2$years + rms2$training:rms2$feedback)
[1] 34
summary(M1)
[1] 35

Call:
lm(formula = rms2$incidents ~ rms2$training + rms2$feedback + 
    rms2$empathy + rms2$years + rms2$training:rms2$feedback)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                             Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                  0.345467   0.048515   7.121 2.04e-11 ***
rms2$trainingtraining                       -0.203496   0.029874  -6.812 1.18e-10 ***
rms2$feedbackfeedback                        0.085558   0.029299   2.920  0.00391 ** 
rms2$empathy                                 0.028695   0.004328   6.630 3.25e-10 ***
rms2$years                                  -0.015720   0.003518  -4.468 1.34e-05 ***
rms2$trainingtraining:rms2$feedbackfeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

interaction.plot(rms2$training, rms2$feedback, rms2$incidents, 
    main = "interaction plot of training and incidents")
[1] 36
shapiro.test(M1$residuals)
[1] 37

	Shapiro-Wilk normality test

data:  M1$residuals
W = 0.98794, p-value = 0.08817

hist(M1$residuals)
[1] 38
qqPlot(M1)
[1] 39
residualPlots(M1)
[1] 40
ncvTest(M1)
[1] 41
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
M2 <- lm(rms2$incidents ~ rms2$training + rms2$feedback + rms2$empathy + 
    rms2$years)
[1] 42
crPlots(M2)
[1] 43
durbinWatsonTest(M1)
[1] 44
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.176
 Alternative hypothesis: rho != 0
vif(M1)
[1] 45
              rms2$training               rms2$feedback                rms2$empathy                  rms2$years 
                   2.086826                    2.007327                    1.122147                    1.092150 
rms2$training:rms2$feedback 
                   3.070068 
stdz <- MASS::studres(M1)
[1] 46
head(stdz, 200)
[1] 47
          1           2           3           4           5           6           7           8           9 
 1.27011135  0.09962262 -1.38805826  0.87453844  0.13456568 -0.34799618  1.82279419  0.20877377 -0.40891846 
         10          11          12          13          14          15          16          17          18 
-1.23329350  1.41474395  0.73601713  3.13503334  0.85487326  0.76124851 -0.50220505 -1.48226606  0.29781614 
         19          20          21          22          23          24          25          26          27 
 1.50680387  1.22806472 -1.89781115  0.35028806 -0.47837595  1.43554494 -0.78621912 -0.98259083 -0.21018107 
         28          29          30          31          32          33          34          35          36 
-0.29617261 -0.69651048 -0.86539421 -0.76758425  0.76569919 -1.18694186  0.49562753  1.79655450  0.45835720 
         37          38          39          40          41          42          43          44          45 
 0.05857005  1.21886174  0.20591501 -0.67777658  1.52929778  0.49562753 -0.82158071 -0.20810557 -0.21094198 
         46          47          48          49          50 
-0.36658391  0.25656038  1.32682233  0.07728755 -0.78820486 
 [ reached getOption("max.print") -- omitted 150 entries ]
which(abs(stdz) > 2)
[1] 48
 13  73 117 150 156 159 160 176 181 
 13  73 117 150 156 159 160 176 181 
hats <- hatvalues(M1)
[1] 49
hats

         1          2          3          4          5          6          7          8          9         10 
0.02224625 0.02079595 0.02561420 0.02297973 0.02926555 0.02283851 0.02822387 0.02845329 0.02524477 0.02137580 
        11         12         13         14         15         16         17         18         19         20 
0.02437488 0.03179714 0.02108507 0.02168485 0.02108507 0.05253776 0.03658992 0.02297973 0.02561420 0.03271035 
        21         22         23         24         25         26         27         28         29         30 
0.02482345 0.02754072 0.02000879 0.02168485 0.02210604 0.02357605 0.02210604 0.02168485 0.02258795 0.04857153 
        31         32         33         34         35         36         37         38         39         40 
0.02320282 0.02362375 0.02517907 0.02137580 0.03603175 0.02413468 0.02987940 0.02662504 0.03447682 0.03354032 
        41         42         43         44         45         46         47         48         49         50 
0.02956526 0.02137580 0.02812864 0.03574527 0.02956526 0.02086326 0.02437488 0.02357605 0.02255318 0.03574527 
 [ reached getOption("max.print") -- omitted 150 entries ]


which(hats > 2 * mean(hats))
[1] 51
 61  88  89 137 141 154 200 
 61  88  89 137 141 154 200 
cooks <- cooks.distance(M1)
[1] 52
which(cooks > (4/(200 - 5 - 1)))
[1] 53
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
cooks <- cooks.distance(M1)
[1] 54
names(which(cooks > (4/(200 - 5 - 1))))
[1] 55
[1] "13"  "73"  "74"  "89"  "117" "137" "160" "165" "176"
plot(M1, which = 4)
[1] 56
plot(M1, which = 5)
[1] 57
M1b <- lm(rms2$incidents ~ rms2$training + rms2$feedback + rms2$empathy + 
    rms2$years + rms2$training * rms2$feedback, data = rms2[-c(13, 
    73, 74, 117, 137, 160, 165, 176), ])
[1] 58
summary(M1b)
[1] 59

Call:
lm(formula = rms2$incidents ~ rms2$training + rms2$feedback + 
    rms2$empathy + rms2$years + rms2$training * rms2$feedback, 
    data = rms2[-c(13, 73, 74, 117, 137, 160, 165, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                             Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                  0.345467   0.048515   7.121 2.04e-11 ***
rms2$trainingtraining                       -0.203496   0.029874  -6.812 1.18e-10 ***
rms2$feedbackfeedback                        0.085558   0.029299   2.920  0.00391 ** 
rms2$empathy                                 0.028695   0.004328   6.630 3.25e-10 ***
rms2$years                                  -0.015720   0.003518  -4.468 1.34e-05 ***
rms2$trainingtraining:rms2$feedbackfeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

CVRs <- covratio(M1)
[1] 60
which(CVRs > 1.09 | CVRs < 0.91)
[1] 61
 13  61  88  92 150 154 159 160 163 176 200 
 13  61  88  92 150 154 159 160 163 176 200 
M1c <- lm(rms2$incidents ~ rms2$training + rms2$feedback + rms2$empathy + 
    rms2$years + rms2$training * rms2$feedback, data = rms2[-c(13, 
    61, 88, 92, 150, 154, 159, 160, 163, 176, 200), ])
[1] 62
summary(M1c)
[1] 63

Call:
lm(formula = rms2$incidents ~ rms2$training + rms2$feedback + 
    rms2$empathy + rms2$years + rms2$training * rms2$feedback, 
    data = rms2[-c(13, 61, 88, 92, 150, 154, 159, 160, 163, 176, 
        200), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                             Estimate Std. Error t value Pr(>|t|)    
(Intercept)                                  0.345467   0.048515   7.121 2.04e-11 ***
rms2$trainingtraining                       -0.203496   0.029874  -6.812 1.18e-10 ***
rms2$feedbackfeedback                        0.085558   0.029299   2.920  0.00391 ** 
rms2$empathy                                 0.028695   0.004328   6.630 3.25e-10 ***
rms2$years                                  -0.015720   0.003518  -4.468 1.34e-05 ***
rms2$trainingtraining:rms2$feedbackfeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

