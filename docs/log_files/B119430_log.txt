

	####### B119430 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 2
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(interactions, quietly = T)
[1] 3
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [8] "grDevices"    "utils"        "datasets"     "methods"      "base"        
data <- read.csv("../RMS2_report_1920.csv")
[1] 4
describe(data)
[1] 5
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
is.na(data)
[1] 6
       subject incidents training feedback empathy years
  [1,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [2,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [3,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [4,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [5,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [6,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [7,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
  [8,]   FALSE     FALSE    FALSE    FALSE   FALSE FALSE
 [ reached getOption("max.print") -- omitted 192 rows ]
str(data)
[1] 7
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
data$training <- factor(data$training, labels = c("no training", 
    "training"))
[1] 8
levels(data$training)
[1] 9
[1] "no training" "training"   
data$feedback <- factor(data$feedback, labels = c("no feedback", 
    "feedback"))
[1] 10
levels(data$feedback)
[1] 11
[1] "no feedback" "feedback"   
is.factor(data$training)
[1] 12
[1] TRUE
is.factor(data$feedback)
[1] 13
[1] TRUE
str(data)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "no training",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "no feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
describe(data)
[1] 15
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training*    3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
describe(data)[, c(2:5, 8, 9)]
[1] 16
            n   mean    sd median  min    max
subject   200 100.50 57.88 100.50 1.00 200.00
incidents 200   0.48  0.19   0.42 0.08   0.92
training* 200   1.50  0.50   1.50 1.00   2.00
feedback* 200   1.50  0.50   1.50 1.00   2.00
empathy   200  10.18  2.54  10.00 3.00  16.00
years     200   8.13  3.08   8.00 1.00  19.00
describe(data)[c(2, 5:6), c(2:5, 8, 9)]
[1] 17
            n  mean   sd median  min   max
incidents 200  0.48 0.19   0.42 0.08  0.92
empathy   200 10.18 2.54  10.00 3.00 16.00
years     200  8.13 3.08   8.00 1.00 19.00
boxplot(data$incidents ~ data$training, main = "Relationship between percentage of interventions and training", 
    ylab = "% incidents that teachers intervened in", xlab = "Training")
[1] 18
boxplot(data$incidents ~ data$feedback, main = "Relationship between percentage of interventions and feedback", 
    ylab = "% incidents that teachers intervened in", xlab = "Feedback")
[1] 19
data$empathy_mean <- data$empathy - mean(data$empathy)
[1] 20
data$years_min <- data$years - min(data$years)
[1] 21
Q1a <- lm(empathy_mean ~ years_min, data = data)
[1] 22
summary(Q1a)
[1] 23

Call:
lm(formula = empathy_mean ~ years_min, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.55119    0.43847  -3.538 0.000503 ***
years_min    0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(empathy_mean ~ years_min, main = "Relationship between empathy and experience", 
    xlab = "Experience in years of teaching (centred to the min)", 
    ylab = "Mean-centred empathy score (scale from 1-20)", data = data)
[1] 24
abline(Q1a)
[1] 25
lines(lowess(data$empathy_mean ~ data$years_min), col = "red")
[1] 26
crPlots(Q1a)
[1] 27
Q1b <- lm(empathy_mean ~ poly(years_min, 2, raw = TRUE), data = data)
[1] 28
summary(Q1b)
[1] 29

Call:
lm(formula = empathy_mean ~ poly(years_min, 2, raw = TRUE), data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)                     -7.023781   0.628424  -11.18   <2e-16 ***
poly(years_min, 2, raw = TRUE)1  1.861217   0.162820   11.43   <2e-16 ***
poly(years_min, 2, raw = TRUE)2 -0.103645   0.009861  -10.51   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

plot(empathy_mean ~ years_min, main = "Relationship between empathy and experience", 
    xlab = "Experience in years of teaching (centred to the min)", 
    ylab = "Mean-centred empathy score (scale from 1-20)", data = data)
[1] 30
points(data$years_min, fitted(Q1b), col = "red", pch = 20)
[1] 31
NULL
lines(sort(data$years_min), fitted(Q1b)[order(data$years_min)], 
    col = "red", type = "b")
[1] 32
(-1.861217)/(2 * (-0.103645))
[1] 33
[1] 8.978807
shapiro.test(Q1b$residuals)
[1] 34

	Shapiro-Wilk normality test

data:  Q1b$residuals
W = 0.9941, p-value = 0.6155

qqPlot(Q1b, main = "Question 1 QQ plot testing for the normality of distributed errors")
[1] 35
hist(Q1b$residuals, main = "Question 1 Histogram of the Residuals")
[1] 36
residualPlot(Q1b, main = "Question 1 Residual Plot")
[1] 37
ncvTest(Q1b)
[1] 38
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(Q1b)
[1] 39
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.834
 Alternative hypothesis: rho != 0
studentised_res_Q1 <- MASS::studres(Q1b)
[1] 40
which(abs(studentised_res_Q1) > 2)
[1] 41
 30  68  69  70  74  76 122 142 162 175 
 30  68  69  70  74  76 122 142 162 175 
hats_Q1 <- hatvalues(Q1b)
[1] 42
which(hats_Q1 > 2 * mean(hats_Q1))
[1] 43
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
plot(Q1b, which = 5, main = "Question 1 Plot of Residuals against Leverages")
[1] 44
cooks_Q1 <- cooks.distance(Q1b)
[1] 45
4/(200 - 1 - 1)
[1] 46
[1] 0.02020202
which(cooks_Q1 > 0.02020202)
[1] 47
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
names(which(cooks_Q1 > 0.02020202))
[1] 48
[1] "61"  "89"  "137" "141" "154" "163" "165" "175"
plot(Q1b, which = 4, main = "Question 1 Cook's distance")
[1] 49
abline(h = 0.02020202, col = "red")
[1] 50
Q1c <- lm(empathy_mean ~ poly(years_min, 2, raw = TRUE), data = data[-c(61, 
    89, 137, 141, 154, 163, 165, 175), ])
[1] 51
summary(Q1c)
[1] 52

Call:
lm(formula = empathy_mean ~ poly(years_min, 2, raw = TRUE), data = data[-c(61, 
    89, 137, 141, 154, 163, 165, 175), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5344 -1.1205  0.1144  1.2235  4.8795 

Coefficients:
                                Estimate Std. Error t value Pr(>|t|)    
(Intercept)                     -7.28939    0.74850  -9.739  < 2e-16 ***
poly(years_min, 2, raw = TRUE)1  1.93042    0.20785   9.288  < 2e-16 ***
poly(years_min, 2, raw = TRUE)2 -0.10772    0.01353  -7.962 1.54e-13 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.912 on 189 degrees of freedom
Multiple R-squared:  0.3587,	Adjusted R-squared:  0.3519 
F-statistic: 52.86 on 2 and 189 DF,  p-value: < 2.2e-16

Q2a <- lm(incidents ~ empathy_mean + years_min + training, data = data)
[1] 53
summary(Q2a)
[1] 54

Call:
lm(formula = incidents ~ empathy_mean + years_min + training, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.651636   0.033113  19.679  < 2e-16 ***
empathy_mean      0.025396   0.004735   5.363 2.29e-07 ***
years_min        -0.014085   0.003889  -3.622 0.000372 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

crPlots(Q2a, main = "Question 2 Component + Residual Plot")
[1] 55
residualPlot(Q2a, main = "Question 2 Resiudal Plot")
[1] 56
ncvTest(Q2a)
[1] 57
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
durbinWatsonTest(Q2a)
[1] 58
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.186
 Alternative hypothesis: rho != 0
vif(Q2a)
[1] 59
empathy_mean    years_min     training 
    1.092467     1.085089     1.020633 
shapiro.test(Q2a$residuals)
[1] 60

	Shapiro-Wilk normality test

data:  Q2a$residuals
W = 0.97994, p-value = 0.005838

qqPlot(Q2a, main = "Question 2 QQ plot testing for the normality of distributed errors")
[1] 61
hist(Q2a$residuals, main = "Question 2 Histogram of Residuals")
[1] 62
skew(data$empathy_mean)
[1] 63
[1] -0.371876
skew(data$years_min)
[1] 64
[1] 0.516562
skew(data$incidents)
[1] 65
[1] 0.3221457
skew(Q2a$residuals)
[1] 66
[1] 0.470533
studentised_res_Q2 <- MASS::studres(Q2a)
[1] 67
which(abs(studentised_res_Q2) > 2)
[1] 68
  7  13  35  74 159 165 176 181 
  7  13  35  74 159 165 176 181 
hats_Q2 <- hatvalues(Q2a)
[1] 69
which(hats_Q2 > 2 * mean(hats_Q2))
[1] 70
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
plot(Q2a, which = 5, main = "Question 2 Plot of Residuals against Leverages")
[1] 71
cooks_Q2 <- cooks.distance(Q2a)
[1] 72
4/(200 - 3 - 1)
[1] 73
[1] 0.02040816
which(cooks_Q2 > 0.02040816)
[1] 74
 13  35  74 137 165 
 13  35  74 137 165 
names(which(cooks_Q2 > 0.02040816))
[1] 75
[1] "13"  "35"  "74"  "137" "165"
plot(Q2a, which = 4, main = "Question 2 Cook's distance")
[1] 76
abline(h = 0.02040816, col = "red")
[1] 77
Q2b <- lm(incidents ~ empathy_mean + years_min + training, data = data[-c(13, 
    35, 74, 137, 165), ])
[1] 78
summary(Q2b)
[1] 79

Call:
lm(formula = incidents ~ empathy_mean + years_min + training, 
    data = data[-c(13, 35, 74, 137, 165), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28818 -0.11426 -0.00621  0.09990  0.40582 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.661426   0.032180  20.554  < 2e-16 ***
empathy_mean      0.028505   0.004568   6.240 2.76e-09 ***
years_min        -0.016177   0.003838  -4.215 3.84e-05 ***
trainingtraining -0.153846   0.021969  -7.003 4.16e-11 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1521 on 191 degrees of freedom
Multiple R-squared:  0.3042,	Adjusted R-squared:  0.2932 
F-statistic: 27.83 on 3 and 191 DF,  p-value: 5.621e-15

contrasts(data$feedback) <- contr.treatment(2, base = 1)
[1] 80
contrasts(data$feedback)
[1] 81
            2
no feedback 0
feedback    1
Q3a <- lm(incidents ~ empathy_mean + years_min + feedback, data = data)
[1] 82
summary(Q3a)
[1] 83

Call:
lm(formula = incidents ~ empathy_mean + years_min + feedback, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.499404   0.032378  15.424  < 2e-16 ***
empathy_mean  0.023187   0.004829   4.802 3.11e-06 ***
years_min    -0.012689   0.003975  -3.192  0.00165 ** 
feedback2     0.132132   0.023585   5.602 7.09e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

crPlots(Q3a, main = "Question 3 Component + Residual Plot")
[1] 84
residualPlot(Q3a, main = "Question 3 Residual Plot")
[1] 85
ncvTest(Q3a)
[1] 86
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
durbinWatsonTest(Q3a)
[1] 87
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(Q3a)
[1] 88
empathy_mean    years_min     feedback 
    1.079397     1.077467     1.005211 
shapiro.test(Q3a$residuals)
[1] 89

	Shapiro-Wilk normality test

data:  Q3a$residuals
W = 0.98772, p-value = 0.08174

qqPlot(Q3a, main = "Question 3 QQ plot testing for the normality of distributed errors")
[1] 90
hist(Q3a$residuals, main = "Question 3 Histogram of residuals")
[1] 91
studentised_res_Q3 <- MASS::studres(Q3a)
[1] 92
which(abs(studentised_res_Q3) > 2)
[1] 93
 13  21  73  74 150 156 159 160 165 176 181 
 13  21  73  74 150 156 159 160 165 176 181 
hats_Q3 <- hatvalues(Q3a)
[1] 94
which(hats_Q3 > 2 * mean(hats_Q3))
[1] 95
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
plot(Q3a, which = 5, main = "Question 3 Plot of Residuals against Leverages")
[1] 96
cooks_Q3 <- cooks.distance(Q3a)
[1] 97
4/(200 - 3 - 1)
[1] 98
[1] 0.02040816
which(cooks_Q3 > 0.02040816)
[1] 99
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
names(which(cooks_Q3 > 0.02040816))
[1] 100
[1] "73"  "74"  "89"  "137" "156" "160" "165" "176"
plot(Q3a, which = 4, main = "Question 3 Cook's distance")
[1] 101
abline(h = 0.02040816, col = "red")
[1] 102
Q3b <- lm(incidents ~ empathy_mean + years_min + feedback, data = data[-c(73, 
    74, 89, 137, 156, 160, 165, 176), ])
[1] 103
summary(Q3b)
[1] 104

Call:
lm(formula = incidents ~ empathy_mean + years_min + feedback, 
    data = data[-c(73, 74, 89, 137, 156, 160, 165, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.33584 -0.10475 -0.01065  0.11221  0.43819 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.483636   0.031187  15.507  < 2e-16 ***
empathy_mean  0.026288   0.004614   5.697 4.63e-08 ***
years_min    -0.011985   0.003870  -3.097  0.00225 ** 
feedback2     0.143324   0.021760   6.586 4.39e-10 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1506 on 188 degrees of freedom
Multiple R-squared:  0.2838,	Adjusted R-squared:  0.2724 
F-statistic: 24.83 on 3 and 188 DF,  p-value: 1.402e-13

AIC(Q2a, Q3a)
[1] 105
    df       AIC
Q2a  5 -154.1654
Q3a  5 -143.9591
BIC(Q2a, Q3a)
[1] 106
    df       BIC
Q2a  5 -137.6738
Q3a  5 -127.4675
Q5a <- lm(incidents ~ empathy_mean + years_min + training + feedback + 
    training:feedback, data = data)
[1] 107
summary(Q5a)
[1] 108

Call:
lm(formula = incidents ~ empathy_mean + years_min + training + 
    feedback + training:feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                            Estimate Std. Error t value Pr(>|t|)    
(Intercept)                 0.621718   0.033484  18.567  < 2e-16 ***
empathy_mean                0.028695   0.004328   6.630 3.25e-10 ***
years_min                  -0.015720   0.003518  -4.468 1.34e-05 ***
trainingtraining           -0.203496   0.029874  -6.812 1.18e-10 ***
feedback2                   0.085558   0.029299   2.920  0.00391 ** 
trainingtraining:feedback2  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

residualPlot(Q5a, main = "Question 5 Residual Plot")
[1] 109
ncvTest(Q5a)
[1] 110
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
durbinWatsonTest(Q5a)
[1] 111
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.214
 Alternative hypothesis: rho != 0
vif(Q5a)
[1] 112
     empathy_mean         years_min          training          feedback training:feedback 
         1.122147          1.092150          2.086826          2.007327          3.070068 
shapiro.test(Q5a$residuals)
[1] 113

	Shapiro-Wilk normality test

data:  Q5a$residuals
W = 0.98794, p-value = 0.08817

qqPlot(Q5a, main = "Question 5 QQ plot testing for the normality of distributed errors")
[1] 114
hist(Q5a$residuals, main = "Question 5 Histogram of residuals")
[1] 115
studentised_res_Q5 <- MASS::studres(Q5a)
[1] 116
which(abs(studentised_res_Q5) > 2)
[1] 117
 13  73 117 150 156 159 160 176 181 
 13  73 117 150 156 159 160 176 181 
hats_Q5 <- hatvalues(Q5a)
[1] 118
which(hats_Q5 > 2 * mean(hats_Q5))
[1] 119
 61  88  89 137 141 154 200 
 61  88  89 137 141 154 200 
plot(Q5a, which = 5, main = "Question 5 Plot of Residuals against Leverages")
[1] 120
cooks_Q5 <- cooks.distance(Q5a)
[1] 121
4/(200 - 4 - 1)
[1] 122
[1] 0.02051282
which(cooks_Q5 > 0.02051282)
[1] 123
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
names(which(cooks_Q5 > 0.02051282))
[1] 124
[1] "13"  "73"  "74"  "89"  "117" "137" "160" "165" "176"
plot(Q5a, which = 4, main = "Question 5 Cook's distance")
[1] 125
abline(h = 0.02051282, col = "red")
[1] 126
Q5b <- lm(incidents ~ empathy_mean + years_min + training + feedback + 
    training:feedback, data = data[-c(13, 73, 74, 89, 117, 137, 
    160, 165, 176), ])
[1] 127
summary(Q5b)
[1] 128

Call:
lm(formula = incidents ~ empathy_mean + years_min + training + 
    feedback + training:feedback, data = data[-c(13, 73, 74, 
    89, 117, 137, 160, 165, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28269 -0.09632  0.00081  0.09067  0.34167 

Coefficients:
                            Estimate Std. Error t value Pr(>|t|)    
(Intercept)                 0.610002   0.032099  19.004  < 2e-16 ***
empathy_mean                0.030839   0.004103   7.516 2.35e-12 ***
years_min                  -0.016135   0.003427  -4.708 4.89e-06 ***
trainingtraining           -0.184679   0.027340  -6.755 1.80e-10 ***
feedback2                   0.094956   0.027103   3.504 0.000576 ***
trainingtraining:feedback2  0.084936   0.038572   2.202 0.028899 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1315 on 185 degrees of freedom
Multiple R-squared:  0.4496,	Adjusted R-squared:  0.4348 
F-statistic: 30.23 on 5 and 185 DF,  p-value: < 2.2e-16

cat_plot(Q5a, pred = training, modx = feedback, plot.points = TRUE, 
    main = "Question 5 Interaction Plot")
[1] 129
cat_plot(Q5a, pred = training, modx = feedback, geom = "line", 
    main = "Question 5 Interaction Plot (lines)")
[1] 130
