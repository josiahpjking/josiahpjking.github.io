

	####### B113366 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 2
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library(lm.beta, quietly = T)
[1] 3
 [1] "lm.beta"   "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[11] "methods"   "base"     
library(interactions, quietly = T)
[1] 4
 [1] "interactions" "lm.beta"      "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [9] "grDevices"    "utils"        "datasets"     "methods"      "base"        
setwd("~/Desktop/RMS/coursework")
[1] 5
data <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 6
describeBy(data)
[1] 7
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
str(data)
[1] 8
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
data$training <- as.factor(data$training)
[1] 9
data$feedback <- as.factor(data$feedback)
[1] 10
str(data$training)
[1] 11
 Factor w/ 2 levels "1","2": 2 2 2 2 2 2 2 2 2 2 ...
NULL
summary(data$training)
[1] 12
  1   2 
100 100 
str(data$feedback)
[1] 13
 Factor w/ 2 levels "1","2": 2 1 2 1 2 1 2 1 2 1 ...
NULL
summary(data$feedback)
[1] 14
  1   2 
100 100 
data$training <- factor(data$training, labels = c("no training", 
    "training"))
[1] 15
summary(data$training)
[1] 16
no training    training 
        100         100 
data$feedback <- factor(data$feedback, labels = c("no feedback", 
    "feedback"))
[1] 17
summary(data$feedback)
[1] 18
no feedback    feedback 
        100         100 
describe(data)
[1] 19
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training*    3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
data$empathy_mean <- data$empathy - mean(data$empathy)
[1] 20
hist(data$empathy_mean)
[1] 21
m1 <- lm(empathy_mean ~ years, data = data)
[1] 22
summary(m1)
[1] 23

Call:
lm(formula = empathy_mean ~ years, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.76875    0.49085  -3.603 0.000397 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(cooks.distance(m1))
[1] 24
abline(h = cooks.distance(m1) > (4/(200 - 1 - 1)), col = "red")
[1] 25
which(cooks.distance(m1) > (4/(200 - 1 - 1)))
[1] 26
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
plot(m1, which = 4)
[1] 27
m1a <- lm(empathy_mean ~ years, data = data[-c(88, 137, 154), 
    ])
[1] 28
summary(m1a)
[1] 29

Call:
lm(formula = empathy_mean ~ years, data = data[-c(88, 137, 154), 
    ])

Residuals:
    Min      1Q  Median      3Q     Max 
-6.2211 -1.6555  0.0411  1.4756  5.7583 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -2.19556    0.49438  -4.441 1.50e-05 ***
years        0.28278    0.05778   4.894 2.07e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.325 on 195 degrees of freedom
Multiple R-squared:  0.1094,	Adjusted R-squared:  0.1048 
F-statistic: 23.95 on 1 and 195 DF,  p-value: 2.068e-06

summary(m1)
[1] 30

Call:
lm(formula = empathy_mean ~ years, data = data)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -1.76875    0.49085  -3.603 0.000397 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

qqPlot(m1)
[1] 31
shapiro.test(m1$residuals)
[1] 32

	Shapiro-Wilk normality test

data:  m1$residuals
W = 0.98911, p-value = 0.1321

residualPlots(m1)
[1] 33
ncvTest(m1)
[1] 34
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
durbinWatsonTest(m1)
[1] 35
 lag Autocorrelation D-W Statistic p-value
   1       0.1017162      1.769879   0.076
 Alternative hypothesis: rho != 0
crPlots(m1)
[1] 36
m1b <- lm(data$empathy_mean ~ poly(data$years, 2, raw = TRUE))
[1] 37
summary(m1b)
[1] 38

Call:
lm(formula = data$empathy_mean ~ poly(data$years, 2, raw = TRUE))

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                      -8.988644   0.791848  -11.35   <2e-16 ***
poly(data$years, 2, raw = TRUE)1  2.068508   0.181845   11.38   <2e-16 ***
poly(data$years, 2, raw = TRUE)2 -0.103645   0.009861  -10.51   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

plot(cooks.distance(m1b))
[1] 39
abline(h = cooks.distance(m1b) > (4/(200 - 1 - 1)), col = "red")
[1] 40
which(cooks.distance(m1b) > (4/(200 - 1 - 1)))
[1] 41
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(m1b, which = 4)
[1] 42
m1c <- lm(data$empathy_mean ~ poly(data$years, 2, raw = TRUE), 
    data = data[-c(89, 154, 175), ])
[1] 43
summary(m1c)
[1] 44

Call:
lm(formula = data$empathy_mean ~ poly(data$years, 2, raw = TRUE), 
    data = data[-c(89, 154, 175), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                      -8.988644   0.791848  -11.35   <2e-16 ***
poly(data$years, 2, raw = TRUE)1  2.068508   0.181845   11.38   <2e-16 ***
poly(data$years, 2, raw = TRUE)2 -0.103645   0.009861  -10.51   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

summary(m1b)
[1] 45

Call:
lm(formula = data$empathy_mean ~ poly(data$years, 2, raw = TRUE))

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                      -8.988644   0.791848  -11.35   <2e-16 ***
poly(data$years, 2, raw = TRUE)1  2.068508   0.181845   11.38   <2e-16 ***
poly(data$years, 2, raw = TRUE)2 -0.103645   0.009861  -10.51   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

qqPlot(m1b)
[1] 46
shapiro.test(m1b$residuals)
[1] 47

	Shapiro-Wilk normality test

data:  m1b$residuals
W = 0.9941, p-value = 0.6155

residualPlots(m1b)
[1] 48
ncvTest(m1b)
[1] 49
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(m1b)
[1] 50
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855    0.82
 Alternative hypothesis: rho != 0
crPlots(m1b)
[1] 51
m2 <- lm(incidents ~ training + empathy_mean + years, data = data)
[1] 52
summary(m2)
[1] 53

Call:
lm(formula = incidents ~ training + empathy_mean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy_mean      0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

vif(m2)
[1] 54
    training empathy_mean        years 
    1.020633     1.092467     1.085089 
plot(cooks.distance(m2))
[1] 55
abline(h = cooks.distance(m2) > (4/(200 - 3 - 1)), col = "red")
[1] 56
which(cooks.distance(m2) > (4/(200 - 3 - 1)))
[1] 57
 13  35  74 137 165 
 13  35  74 137 165 
plot(m2, which = 4)
[1] 58
m2a <- lm(incidents ~ training + empathy_mean + years, data = data[-c(13, 
    74, 137), ])
[1] 59
summary(m2a)
[1] 60

Call:
lm(formula = incidents ~ training + empathy_mean + years, data = data[-c(13, 
    74, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29350 -0.11585 -0.00812  0.10001  0.40267 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.681518   0.035735  19.071  < 2e-16 ***
trainingtraining -0.153719   0.022279  -6.900 7.28e-11 ***
empathy_mean      0.029033   0.004656   6.236 2.77e-09 ***
years            -0.016244   0.003864  -4.204 4.01e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1552 on 193 degrees of freedom
Multiple R-squared:  0.2988,	Adjusted R-squared:  0.2879 
F-statistic: 27.41 on 3 and 193 DF,  p-value: 8.212e-15

summary(m2)
[1] 61

Call:
lm(formula = incidents ~ training + empathy_mean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy_mean      0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

residualPlots(m2)
[1] 62
ncvTest(m2)
[1] 63
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
qqPlot(m2)
[1] 64
shapiro.test(m2$residuals)
[1] 65

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.97994, p-value = 0.005838

crPlots(m2)
[1] 66
durbinWatsonTest(m2)
[1] 67
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.178
 Alternative hypothesis: rho != 0
check <- lm(incidents ~ feedback, data = data)
[1] 68
checktraining <- lm(incidents ~ feedback + training, data = data)
[1] 69
summary(check)
[1] 70

Call:
lm(formula = incidents ~ feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.45333 -0.12000  0.00333  0.13000  0.50333 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.41333    0.01765   23.41  < 2e-16 ***
feedbackfeedback  0.12333    0.02496    4.94 1.66e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1765 on 198 degrees of freedom
Multiple R-squared:  0.1097,	Adjusted R-squared:  0.1052 
F-statistic: 24.41 on 1 and 198 DF,  p-value: 1.656e-06

summary(checktraining)
[1] 71

Call:
lm(formula = incidents ~ feedback + training, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.38667 -0.11167 -0.01333  0.07000  0.44667 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.48000    0.02005  23.937  < 2e-16 ***
feedbackfeedback  0.12333    0.02315   5.326 2.72e-07 ***
trainingtraining -0.13333    0.02315  -5.758 3.22e-08 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1637 on 197 degrees of freedom
Multiple R-squared:  0.238,	Adjusted R-squared:  0.2303 
F-statistic: 30.76 on 2 and 197 DF,  p-value: 2.359e-12

m3 <- lm(incidents ~ feedback + empathy_mean + years, data = data)
[1] 72
summary(m3)
[1] 73

Call:
lm(formula = incidents ~ feedback + empathy_mean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.512093   0.035846  14.286  < 2e-16 ***
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy_mean      0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

vif(m3)
[1] 74
    feedback empathy_mean        years 
    1.005211     1.079397     1.077467 
plot(cooks.distance(m3))
[1] 75
abline(h = cooks.distance(m3) > 4/(200 - 3 - 1), col = "red")
[1] 76
which(cooks.distance(m3) > 4/(200 - 3 - 1))
[1] 77
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(m3, which = 4)
[1] 78
m3a <- lm(incidents ~ feedback + empathy_mean + years, data = data[-c(74, 
    89, 137), ])
[1] 79
summary(m3a)
[1] 80

Call:
lm(formula = incidents ~ feedback + empathy_mean + years, data = data[-c(74, 
    89, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.34740 -0.11326 -0.01073  0.11335  0.53413 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.522720   0.036999  14.128  < 2e-16 ***
feedbackfeedback  0.128900   0.023282   5.537 9.99e-08 ***
empathy_mean      0.024888   0.004950   5.028 1.13e-06 ***
years            -0.013583   0.004147  -3.276  0.00125 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1633 on 193 degrees of freedom
Multiple R-squared:  0.2282,	Adjusted R-squared:  0.2162 
F-statistic: 19.02 on 3 and 193 DF,  p-value: 7.541e-11

summary(m3)
[1] 81

Call:
lm(formula = incidents ~ feedback + empathy_mean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.512093   0.035846  14.286  < 2e-16 ***
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy_mean      0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

residualPlots(m3)
[1] 82
ncvTest(m3)
[1] 83
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
qqPlot(m3)
[1] 84
shapiro.test(m3$residuals)
[1] 85

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.98772, p-value = 0.08174

crPlots(m3)
[1] 86
durbinWatsonTest(m3)
[1] 87
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
AIC(m2, m3)
[1] 88
   df       AIC
m2  5 -154.1654
m3  5 -143.9591
BIC(m2, m3)
[1] 89
   df       BIC
m2  5 -137.6738
m3  5 -127.4675
m5 <- lm(incidents ~ training + feedback + training * feedback, 
    data = data)
[1] 90
summary(m5)
[1] 91

Call:
lm(formula = incidents ~ training + feedback + training * feedback, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49333    0.02314  21.323  < 2e-16 ***
trainingtraining                  -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackfeedback                   0.09667    0.03272   2.954  0.00352 ** 
trainingtraining:feedbackfeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

qqPlot(m5)
[1] 92
residualPlot(m5)
[1] 93
durbinWatsonTest(m5)
[1] 94
 lag Autocorrelation D-W Statistic p-value
   1       0.1114255      1.770733   0.088
 Alternative hypothesis: rho != 0
cat_plot(m5, pred = training, modx = feedback, plot.points = TRUE, 
    x.label = "training", y.label = "incidents", legend.main = "Feedback")
[1] 95
