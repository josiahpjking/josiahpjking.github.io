

	####### B119033 R script #######

df <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 1
library(psych, quietly = T)
[1] 2
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(pastecs, quietly = T)
[1] 3
 [1] "pastecs"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 4
 [1] "car"       "carData"   "pastecs"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[11] "methods"   "base"     
library(lm.beta, quietly = T)
[1] 5
 [1] "lm.beta"   "car"       "carData"   "pastecs"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"    
[11] "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 6
 [1] "interactions" "lm.beta"      "car"          "carData"      "pastecs"      "psych"        "readr"        "stats"       
 [9] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(ggplot2, quietly = T)
[1] 7
 [1] "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "pastecs"      "psych"        "readr"       
 [9] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(dplyr, quietly = T)
[1] 8
 [1] "dplyr"        "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "pastecs"      "psych"       
 [9] "readr"        "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(effects, quietly = T)
[1] 9
 [1] "effects"      "dplyr"        "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "pastecs"     
 [9] "psych"        "readr"        "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"     
[17] "base"        
library(lmtest, quietly = T)
[1] 10
 [1] "lmtest"       "zoo"          "effects"      "dplyr"        "ggplot2"      "interactions" "lm.beta"      "car"         
 [9] "carData"      "pastecs"      "psych"        "readr"        "stats"        "graphics"     "grDevices"    "utils"       
[17] "datasets"     "methods"      "base"        
library(table1, quietly = T)
[1] 11
 [1] "table1"       "lmtest"       "zoo"          "effects"      "dplyr"        "ggplot2"      "interactions" "lm.beta"     
 [9] "car"          "carData"      "pastecs"      "psych"        "readr"        "stats"        "graphics"     "grDevices"   
[17] "utils"        "datasets"     "methods"      "base"        
describe(df)[c(2, 5, 6), c(2:4, 8, 9, 11, 12)]
[1] 12
            n  mean   sd  min   max  skew kurtosis
incidents 200  0.48 0.19 0.08  0.92  0.32    -0.31
empathy   200 10.18 2.54 3.00 16.00 -0.37     0.23
years     200  8.13 3.08 1.00 19.00  0.52     0.48
summary(df[, 3:4])
[1] 13
    training      feedback  
 Min.   :1.0   Min.   :1.0  
 1st Qu.:1.0   1st Qu.:1.0  
 Median :1.5   Median :1.5  
 Mean   :1.5   Mean   :1.5  
 3rd Qu.:2.0   3rd Qu.:2.0  
 Max.   :2.0   Max.   :2.0  
str(df)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
is.factor(df$training)
[1] 15
[1] FALSE
df$training <- factor(df$training, labels = c("No Training", 
    "Training"))
[1] 16
is.factor(df$feedback)
[1] 17
[1] FALSE
df$feedback <- factor(df$feedback, labels = c("No Feedback", 
    "Feedback"))
[1] 18
table1::label(df$empathy) <- "Empathy Score"
[1] 19
table1::label(df$years) <- "Years of Experience"
[1] 20
table1::label(df$incidents) <- "Bullying Intervention (%)"
[1] 21
table1::table1(~empathy + years + incidents, data = df)
[1] 22
table1::table1(~empathy + years + incidents | feedback + training, 
    data = df)
[1] 23
df$incidents <- round(df$incidents, 3)
[1] 24
plot(df$training, df$incidents, main = "Effect of Training on Bullying Intervention", 
    ylab = "Percentage of Bullying Intervention", pch = 16)
[1] 25
plot(df$feedback, df$incidents, main = "Effect of Feedback on Bullying Intervention", 
    ylab = "Percentage of Bullying Intervention", pch = 16)
[1] 26
plot(df$empathy, df$years, ylab = "Years of Experience", xlab = "Empathy Score", 
    pch = 16, main = "Experience vs Empathy Score")
[1] 27
df$empathy_mean <- df$empathy - mean(df$empathy)
[1] 28
df$years_mean <- df$years - mean(df$years)
[1] 29
M1 <- lm(empathy ~ years, data = df)
[1] 30
summary(M1)
[1] 31

Call:
lm(formula = empathy ~ years, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.40625    0.49085  17.126  < 2e-16 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

stdz <- MASS::studres(M1)
[1] 32
which(abs(stdz) > 2)
[1] 33
 61  68  70  88  89 137 141 142 154 175 200 
 61  68  70  88  89 137 141 142 154 175 200 
hats <- hatvalues(M1)
[1] 34
which(hats > 2 * mean(hats))
[1] 35
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
CVRs <- covratio(M1)
[1] 36
which(CVRs > 1.03 | CVRs < 0.97)
[1] 37
 68 109 142 175 190 
 68 109 142 175 190 
plot(M1, which = 4)
[1] 38
M1a <- lm(empathy ~ years, data = df[-c(88, 137, 154), ])
[1] 39
summary(M1a)
[1] 40

Call:
lm(formula = empathy ~ years, data = df[-c(88, 137, 154), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-6.2211 -1.6555  0.0411  1.4756  5.7583 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  7.97944    0.49438  16.140  < 2e-16 ***
years        0.28278    0.05778   4.894 2.07e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.325 on 195 degrees of freedom
Multiple R-squared:  0.1094,	Adjusted R-squared:  0.1048 
F-statistic: 23.95 on 1 and 195 DF,  p-value: 2.068e-06

M1_coef <- summary(M1)
[1] 41
M1a_coef <- summary(M1a)
[1] 42
comparison <- data.frame(round(M1_coef$coefficients[, 1], 3), 
    round(M1_coef$coefficients[, 4], 4), round(M1a_coef$coefficients[, 
        1], 3), round(M1a_coef$coefficients[, 4], 4))
[1] 43
colnames(comparison) <- c("M1 Coef", "M1 p-value", "M1a Coef", 
    "M1a p-value")
[1] 44
comparison

            M1 Coef M1 p-value M1a Coef M1a p-value
(Intercept)   8.406      0e+00    7.979           0
years         0.218      2e-04    0.283           0


plot(M1a, which = 4)
[1] 46
M1b <- lm(empathy ~ years, data = df[-c(61, 88, 89, 137, 154, 
    200), ])
[1] 47
summary(M1b)
[1] 48

Call:
lm(formula = empathy ~ years, data = df[-c(61, 88, 89, 137, 154, 
    200), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-5.7483 -1.5014 -0.0674  1.4050  5.6688 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.22062    0.49512  16.603  < 2e-16 ***
years        0.26382    0.05789   4.557 9.21e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.23 on 192 degrees of freedom
Multiple R-squared:  0.09761,	Adjusted R-squared:  0.09291 
F-statistic: 20.77 on 1 and 192 DF,  p-value: 9.212e-06

M1a_coef <- summary(M1a)
[1] 49
M1b_coef <- summary(M1b)
[1] 50
comparison.a <- data.frame(round(M1a_coef$coefficients[, 1], 
    3), round(M1a_coef$coefficients[, 4], 4), round(M1b_coef$coefficients[, 
    1], 3), round(M1b_coef$coefficients[, 4], 4))
[1] 51
colnames(comparison.a) <- c("M1a Coef", "M1a p-value", "M1b Coef", 
    "M1b p-value")
[1] 52
comparison.a

            M1a Coef M1a p-value M1b Coef M1b p-value
(Intercept)    7.979           0    8.221           0
years          0.283           0    0.264           0


plot(df$empathy_mean, df$years_mean, xlab = "Empathy Score", 
    ylab = "Years of Experience", main = "Experience vs. Empathy Score", 
    pch = 16)
[1] 54
abline(lm(empathy_mean ~ years_mean, data = df))
[1] 55
lines(lowess(df$empathy_mean, df$years_mean), col = "red")
[1] 56
M1c <- lm(empathy_mean ~ years_mean + I(years_mean^2), data = df)
[1] 57
crPlots(M1c, main = "Component Residual Plots for Model 1C")
[1] 58
qqPlot(M1c, main = "QQ Plot for Model 1C")
[1] 59
shapiro.test(M1c$residuals)
[1] 60

	Shapiro-Wilk normality test

data:  M1c$residuals
W = 0.9941, p-value = 0.6155

hist(M1c$residuals, main = "Model 1C Residuals Distribution")
[1] 61
residualPlots(M1c, main = "Residual Plots for Model 1C")
[1] 62
ncvTest(M1c)
[1] 63
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(M1c)
[1] 64
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.814
 Alternative hypothesis: rho != 0
vif(M1c)
[1] 65
     years_mean I(years_mean^2) 
       1.120963        1.120963 
summary(M1c)
[1] 66

Call:
lm(formula = empathy_mean ~ years_mean + I(years_mean^2), data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      0.977696   0.167423   5.840 2.13e-08 ***
years_mean       0.383236   0.047986   7.986 1.13e-13 ***
I(years_mean^2) -0.103645   0.009861 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

M2 <- lm(incidents ~ training + empathy + years, data = df)
[1] 67
stdz <- MASS::studres(M2)
[1] 68
which(abs(stdz) > 2)
[1] 69
  7  13  35  74 159 165 176 181 
  7  13  35  74 159 165 176 181 
hats <- hatvalues(M2)
[1] 70
which(hats > 2 * mean(hats))
[1] 71
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
CVRs <- covratio(M2)
[1] 72
which(CVRs > 1.06 | CVRs < 0.94)
[1] 73
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
  7  13  61  88  89 141 154 155 159 163 175 176 181 200 
plot(M2, which = 4)
[1] 74
M2a <- lm(incidents ~ training + empathy + years, data = df[-c(13, 
    74, 137), ])
[1] 75
summary(M2a)
[1] 76

Call:
lm(formula = incidents ~ training + empathy + years, data = df[-c(13, 
    74, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29319 -0.11555 -0.00815  0.09966  0.40296 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.386137   0.049901   7.738 5.49e-13 ***
trainingTraining -0.153734   0.022280  -6.900 7.26e-11 ***
empathy           0.029032   0.004656   6.235 2.78e-09 ***
years            -0.016242   0.003864  -4.203 4.03e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1552 on 193 degrees of freedom
Multiple R-squared:  0.2988,	Adjusted R-squared:  0.2879 
F-statistic: 27.41 on 3 and 193 DF,  p-value: 8.224e-15

M2_coef <- summary(M2)
[1] 77
M2a_coef <- summary(M2a)
[1] 78
comparison.b <- data.frame(round(M2_coef$coefficients[, 1], 3), 
    round(M2_coef$coefficients[, 4], 4), round(M2a_coef$coefficients[, 
        1], 3), round(M2a_coef$coefficients[, 4], 4))
[1] 79
colnames(comparison.b) <- c("M2 Coef", "M2 p-value", "M2a Coef", 
    "M2a p-value")
[1] 80
comparison.b

                 M2 Coef M2 p-value M2a Coef M2a p-value
(Intercept)        0.407      0e+00    0.386           0
trainingTraining  -0.152      0e+00   -0.154           0
empathy            0.025      0e+00    0.029           0
years             -0.014      4e-04   -0.016           0


qqPlot(M2, main = "QQ Plot of Model 2")
[1] 82
hist(M2$residuals, main = "Histogram of Model 2 Residuals")
[1] 83
shapiro.test(M2$residuals)
[1] 84

	Shapiro-Wilk normality test

data:  M2$residuals
W = 0.97993, p-value = 0.005816

df$incidents_sqrt <- sqrt(df$incidents)
[1] 85
M2a <- lm(incidents_sqrt ~ training + empathy + years, data = df)
[1] 86
plot(M2a, which = 4)
[1] 87
M2b <- lm(incidents ~ training + empathy + years, data = df[-c(30, 
    74, 137), ])
[1] 88
M2a_coef <- summary(M2a)
[1] 89
M2b_coef <- summary(M2b)
[1] 90
comparison.c <- data.frame(round(M2a_coef$coefficients[, 1], 
    3), round(M2a_coef$coefficients[, 4], 4), round(M2b_coef$coefficients[, 
    1], 3), round(M2b_coef$coefficients[, 4], 4))
[1] 91
colnames(comparison.c) <- c("M2a Coef", "M2a p-value", "M2b Coef", 
    "M2b p-value")
[1] 92
comparison.c

                 M2a Coef M2a p-value M2b Coef M2b p-value
(Intercept)         0.623       0e+00    0.403           0
trainingTraining   -0.118       0e+00   -0.145           0
empathy             0.020       0e+00    0.028           0
years              -0.011       2e-04   -0.017           0


qqPlot(M2a, main = "QQ Plot of Model 2A")
[1] 94
hist(M2a$residuals, main = "Histogram of Model 2A Residuals")
[1] 95
shapiro.test(M2a$residuals)
[1] 96

	Shapiro-Wilk normality test

data:  M2a$residuals
W = 0.99412, p-value = 0.6189

residualPlots(M2a, main = "Residual Plots for Model 2A")
[1] 97
ncvTest(M2a)
[1] 98
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 3.954031, Df = 1, p = 0.046759
bptest(M2a)
[1] 99

	studentized Breusch-Pagan test

data:  M2a
BP = 5.9993, df = 3, p-value = 0.1116

crPlots(M2a, main = "Component Residual Plots for Model 2A")
[1] 100
durbinWatsonTest(M2a)
[1] 101
 lag Autocorrelation D-W Statistic p-value
   1      -0.1220133      2.228791   0.104
 Alternative hypothesis: rho != 0
vif(M2a)
[1] 102
training  empathy    years 
1.020633 1.092467 1.085089 
summary(M2a)
[1] 103

Call:
lm(formula = incidents_sqrt ~ training + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30383 -0.08552  0.00130  0.07641  0.35249 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.622628   0.038529  16.160  < 2e-16 ***
trainingTraining -0.118016   0.017227  -6.851 9.26e-11 ***
empathy           0.019732   0.003521   5.604 7.05e-08 ***
years            -0.011013   0.002892  -3.809 0.000187 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1206 on 196 degrees of freedom
Multiple R-squared:  0.273,	Adjusted R-squared:  0.2619 
F-statistic: 24.54 on 3 and 196 DF,  p-value: 1.594e-13

M3 <- lm(incidents ~ feedback + empathy + years, data = df)
[1] 104
stdz <- MASS::studres(M3)
[1] 105
which(abs(stdz) > 2)
[1] 106
 13  21  73  74 150 156 159 160 165 176 181 
 13  21  73  74 150 156 159 160 165 176 181 
hats <- hatvalues(M3)
[1] 107
which(hats > 2 * mean(hats))
[1] 108
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
CVRs <- covratio(M3)
[1] 109
which(CVRs > 1.06 | CVRs < 0.94)
[1] 110
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
 13  61  88 108 137 141 150 154 155 156 159 160 163 175 176 181 190 200 
plot(M3, which = 4)
[1] 111
M3a <- lm(incidents ~ feedback + empathy + years, data = df[-c(74, 
    89, 137), ])
[1] 112
summary(M3a)
[1] 113

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df[-c(74, 
    89, 137), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-0.3474 -0.1133 -0.0111  0.1136  0.5344 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.269518   0.053309   5.056 9.92e-07 ***
feedbackFeedback  0.128917   0.023283   5.537 9.97e-08 ***
empathy           0.024884   0.004950   5.027 1.13e-06 ***
years            -0.013579   0.004147  -3.274  0.00126 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1633 on 193 degrees of freedom
Multiple R-squared:  0.2282,	Adjusted R-squared:  0.2162 
F-statistic: 19.02 on 3 and 193 DF,  p-value: 7.568e-11

M3_coef <- summary(M3)
[1] 114
M3a_coef <- summary(M3a)
[1] 115
comparison.d <- data.frame(round(M3_coef$coefficients[, 1], 3), 
    round(M3_coef$coefficients[, 4], 4), round(M3a_coef$coefficients[, 
        1], 3), round(M3a_coef$coefficients[, 4], 4))
[1] 116
colnames(comparison.d) <- c("M3 Coef", "M3 p-value", "M3a Coef", 
    "M3a p-value")
[1] 117
comparison.d

                 M3 Coef M3 p-value M3a Coef M3a p-value
(Intercept)        0.276     0.0000    0.270      0.0000
feedbackFeedback   0.132     0.0000    0.129      0.0000
empathy            0.023     0.0000    0.025      0.0000
years             -0.013     0.0016   -0.014      0.0013


qqPlot(M3, main = "QQ Plot of Model 3")
[1] 119
hist(M3$residuals, main = "Histogram of Model 3 Residuals")
[1] 120
shapiro.test(M3$residuals)
[1] 121

	Shapiro-Wilk normality test

data:  M3$residuals
W = 0.98768, p-value = 0.08073

residualPlots(M3, main = "Residual Plots of Model 3")
[1] 122
ncvTest(M3)
[1] 123
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01759807, Df = 1, p = 0.89446
crPlots(M3, main = "Component Residual Plots of Model 3")
[1] 124
durbinWatsonTest(M3)
[1] 125
 lag Autocorrelation D-W Statistic p-value
   1       0.2740484      1.443624       0
 Alternative hypothesis: rho != 0
dwtest(M3)
[1] 126

	Durbin-Watson test

data:  M3
DW = 1.4436, p-value = 5.063e-05
alternative hypothesis: true autocorrelation is greater than 0

vif(M3)
[1] 127
feedback  empathy    years 
1.005211 1.079397 1.077467 
summary(M3)
[1] 128

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35550 -0.11176 -0.01134  0.11123  0.53583 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276177   0.054110   5.104 7.84e-07 ***
feedbackFeedback  0.132139   0.023586   5.603 7.09e-08 ***
empathy           0.023189   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2056 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.931e-10

AIC(M2a, M3)
[1] 129
    df       AIC
M2a  5 -272.6674
M3   5 -143.9460
BIC(M2a, M3)
[1] 130
    df       BIC
M2a  5 -256.1759
M3   5 -127.4544
350/2
[1] 131
[1] 175
describeBy(df$incidents, group = list(df$training, df$feedback))
[1] 132

 Descriptive statistics by group 
: No Training
: No Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.49 0.17   0.42    0.48 0.12 0.25 0.92  0.67 0.82    -0.07 0.02
--------------------------------------------------------------------------------------------- 
: Training
: No Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.33 0.14   0.33    0.33 0.12 0.08 0.58   0.5 0.15    -0.96 0.02
--------------------------------------------------------------------------------------------- 
: No Training
: Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.59 0.17   0.58    0.59 0.12 0.25 0.92  0.67 0.05    -0.81 0.02
--------------------------------------------------------------------------------------------- 
: Training
: Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.48 0.17    0.5    0.48 0.12 0.08 0.92  0.83 0.23    -0.07 0.02
ggplot(df) + aes(x = training, y = incidents) + geom_boxplot() + 
    facet_wrap(~feedback) + theme(axis.title.x = element_blank()) + 
    labs(y = "Percentage of Bullying Intervention")
[1] 133
contrasts(df$training)
[1] 134
            Training
No Training        0
Training           1
contrasts(df$feedback)
[1] 135
            Feedback
No Feedback        0
Feedback           1
M5 <- lm(incidents ~ training + feedback + training * feedback, 
    data = df)
[1] 136
plot(M5, which = 4)
[1] 137
M5a <- lm(incidents ~ training + feedback + training * feedback, 
    data = df[-c(13, 160, 176), ])
[1] 138
M5_coef <- summary(M5)
[1] 139
M5a_coef <- summary(M5a)
[1] 140
comparison.e <- data.frame(round(M5_coef$coefficients[, 1], 3), 
    round(M5_coef$coefficients[, 4], 4), round(M5a_coef$coefficients[, 
        1], 3), round(M5a_coef$coefficients[, 4], 4))
[1] 141
colnames(comparison.e) <- c("M5 Coef", "M5 p-value", "M5a Coef", 
    "M5a p-value")
[1] 142
comparison.e

                                  M5 Coef M5 p-value M5a Coef M5a p-value
(Intercept)                         0.493     0.0000    0.476      0.0000
trainingTraining                   -0.160     0.0000   -0.142      0.0000
feedbackFeedback                    0.097     0.0035    0.114      0.0004
trainingTraining:feedbackFeedback   0.053     0.2506    0.027      0.5464


qqPlot(M5, main = "QQ Plot of Model 5")
[1] 144
hist(M5$residuals, main = "Histogram of Model 5 Residuals")
[1] 145
shapiro.test(M5$residuals)
[1] 146

	Shapiro-Wilk normality test

data:  M5$residuals
W = 0.97672, p-value = 0.002086

ncvTest(M5)
[1] 147
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.894243, Df = 1, p = 0.16872
durbinWatsonTest(M5)
[1] 148
 lag Autocorrelation D-W Statistic p-value
   1       0.1116037      1.770356    0.12
 Alternative hypothesis: rho != 0
vif(M5)
[1] 149
         training          feedback training:feedback 
                2                 2                 3 
summary(M5)
[1] 150

Call:
lm(formula = incidents ~ training + feedback + training * feedback, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40036 -0.10512 -0.00036  0.08364  0.43364 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49336    0.02314  21.324  < 2e-16 ***
trainingTraining                  -0.16000    0.03272  -4.890  2.1e-06 ***
feedbackFeedback                   0.09668    0.03272   2.955  0.00351 ** 
trainingTraining:feedbackFeedback  0.05332    0.04627   1.152  0.25061    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.824e-12

ggplot(df) + aes(x = training, color = feedback, group = feedback, 
    y = incidents) + labs(y = "Percentage of Bullying Intervention") + 
    stat_summary(fun.y = mean, geom = "point") + stat_summary(fun.y = mean, 
    geom = "line") + theme(axis.title.x = element_blank())
[1] 151
