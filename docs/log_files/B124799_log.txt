

	####### B124799 R script #######

install.packages("psych")
[1] 1
install.packages("car")
[1] 2
install.packages("jtools")
[1] 3
install.packages("interactions")
[1] 4
install.packages("MASS")
[1] 5
library(psych, quietly = T)
[1] 6
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 7
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(jtools, quietly = T)
[1] 8
 [1] "jtools"    "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"    
[10] "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 9
 [1] "interactions" "jtools"       "car"          "carData"      "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
data <- read.csv("../RMS2_report_1920.csv")
[1] 10
describe(data)
[1] 11
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
describe(data[, c(2:6)])[, c(2, 3, 4, 8, 9, 11, 12)]
[1] 12
            n  mean   sd  min   max  skew kurtosis
incidents 200  0.48 0.19 0.08  0.92  0.32    -0.31
training  200  1.50 0.50 1.00  2.00  0.00    -2.01
feedback  200  1.50 0.50 1.00  2.00  0.00    -2.01
empathy   200 10.18 2.54 3.00 16.00 -0.37     0.23
years     200  8.13 3.08 1.00 19.00  0.52     0.48
summary(data)
[1] 13
    subject         incidents          training      feedback      empathy          years      
 Min.   :  1.00   Min.   :0.08333   Min.   :1.0   Min.   :1.0   Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 50.75   1st Qu.:0.33333   1st Qu.:1.0   1st Qu.:1.0   1st Qu.: 9.00   1st Qu.: 6.00  
 Median :100.50   Median :0.41667   Median :1.5   Median :1.5   Median :10.00   Median : 8.00  
 Mean   :100.50   Mean   :0.47500   Mean   :1.5   Mean   :1.5   Mean   :10.18   Mean   : 8.13  
 3rd Qu.:150.25   3rd Qu.:0.58333   3rd Qu.:2.0   3rd Qu.:2.0   3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :200.00   Max.   :0.91667   Max.   :2.0   Max.   :2.0   Max.   :16.00   Max.   :19.00  
str(data)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
is.factor(data$training)
[1] 15
[1] FALSE
is.factor(data$feedback)
[1] 16
[1] FALSE
data$training <- factor(data$training, labels = c("No Training", 
    "Training"))
[1] 17
levels(data$training)
[1] 18
[1] "No Training" "Training"   
summary(data$training)
[1] 19
No Training    Training 
        100         100 
data$feedback <- factor(data$feedback, labels = c("No Feedback", 
    "Feedback"))
[1] 20
levels(data$feedback)
[1] 21
[1] "No Feedback" "Feedback"   
summary(data$feedback)
[1] 22
No Feedback    Feedback 
        100         100 
str(data)
[1] 23
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "No Training",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "No Feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
plot(data$training, data$incidents, xlab = "Training type", ylab = "Total incidents intervened (%)")
[1] 24
plot(data$feedback, data$incidents, xlab = "Feedback type", ylab = "Total incidents intervened (%)")
[1] 25
plot(data$empathy, data$incidents, xlab = "Level of Empathy", 
    ylab = "Total incidents intervened (%)")
[1] 26
plot(data$years, data$incidents, xlab = "Years of Teaching Experience", 
    ylab = "Total incidents interevened (%)")
[1] 27
plot(data$years, data$empathy, main = "Relationship between years of experience and empathy level", 
    xlab = "Years of experience", ylab = "Empathy level")
[1] 28
m1 <- lm(data$empathy ~ data$years)
[1] 29
abline(m1)
[1] 30
lines(lowess(data$years, data$empathy), col = "red")
[1] 31
m2 <- lm(data$empathy ~ data$years + I(data$years^2))
[1] 32
summary(m2)
[1] 33

Call:
lm(formula = data$empathy ~ data$years + I(data$years^2))

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
                 Estimate Std. Error t value Pr(>|t|)    
(Intercept)      1.186356   0.791848   1.498    0.136    
data$years       2.068508   0.181845  11.375   <2e-16 ***
I(data$years^2) -0.103645   0.009861 -10.510   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

crPlots(m2)
[1] 34
cooks_q1 <- cooks.distance(m2)
[1] 35
which(cooks_q1 > (4/(200 - 2 - 1)))
[1] 36
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(m2, which = 4)
[1] 37
m3 <- lm(empathy ~ years + I(years^2), data = data[-c(89, 154, 
    174), ])
[1] 38
summary(m3)
[1] 39

Call:
lm(formula = empathy ~ years + I(years^2), data = data[-c(89, 
    154, 174), ])

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5475 -1.1454  0.0222  1.2341  6.0673 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  0.95252    0.84044   1.133    0.258    
years        2.13257    0.20097  10.612   <2e-16 ***
I(years^2)  -0.10731    0.01137  -9.438   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.964 on 194 degrees of freedom
Multiple R-squared:  0.3944,	Adjusted R-squared:  0.3881 
F-statistic: 63.16 on 2 and 194 DF,  p-value: < 2.2e-16

cooks_q1b <- cooks.distance(m3)
[1] 40
which(cooks_q1b > (4/(197 - 2 - 1)))
[1] 41
 61 137 141 163 165 175 
 61 136 140 161 163 172 
plot(m3, which = 4)
[1] 42
hats <- hatvalues(m2)
[1] 43
which(hats > 2 * mean(hats))
[1] 44
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
qqPlot(m2)
[1] 45
hist((m2$residuals))
[1] 46
shapiro.test(m2$residuals)
[1] 47

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.9941, p-value = 0.6155

residualPlots(m2)
[1] 48
ncvTest(m2)
[1] 49
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
durbinWatsonTest(m2)
[1] 50
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.846
 Alternative hypothesis: rho != 0
data$years_m <- data$years - mean(data$years)
[1] 51
data$empathy_m <- data$empathy - mean(data$empathy)
[1] 52
model_training <- lm(incidents ~ training + years_m + empathy_m, 
    data = data)
[1] 53
summary(model_training)
[1] 54

Call:
lm(formula = incidents ~ training + years_m + empathy_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.551213   0.016298  33.821  < 2e-16 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
years_m          -0.014085   0.003889  -3.622 0.000372 ***
empathy_m         0.025396   0.004735   5.363 2.29e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

cooks_training <- cooks.distance(model_training)
[1] 55
names(which(cooks_training > 4/(200 - 3 - 1)))
[1] 56
[1] "13"  "35"  "74"  "137" "165"
plot(model_training, which = 4)
[1] 57
model_training2 <- lm(incidents ~ training + years_m + empathy_m, 
    data = data, subset = c(-13, -74, -137))
[1] 58
summary(model_training2)
[1] 59

Call:
lm(formula = incidents ~ training + years_m + empathy_m, data = data, 
    subset = c(-13, -74, -137))

Residuals:
     Min       1Q   Median       3Q      Max 
-0.29350 -0.11585 -0.00812  0.10001  0.40267 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.549455   0.015645  35.119  < 2e-16 ***
trainingTraining -0.153719   0.022279  -6.900 7.28e-11 ***
years_m          -0.016244   0.003864  -4.204 4.01e-05 ***
empathy_m         0.029033   0.004656   6.236 2.77e-09 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1552 on 193 degrees of freedom
Multiple R-squared:  0.2988,	Adjusted R-squared:  0.2879 
F-statistic: 27.41 on 3 and 193 DF,  p-value: 8.212e-15

cooks_training2 <- cooks.distance(model_training2)
[1] 60
names(which(cooks_training2 > 4/(197 - 3 - 1)))
[1] 61
[1] "7"   "35"  "41"  "60"  "77"  "165" "181"
plot(model_training2, which = 4)
[1] 62
qqPlot(model_training)
[1] 63
hist(model_training$residuals)
[1] 64
shapiro.test(model_training$residuals)
[1] 65

	Shapiro-Wilk normality test

data:  model_training$residuals
W = 0.97994, p-value = 0.005838

describe(data[, c(2, 3, 5, 6)])[, c(1, 11)]
[1] 66
          vars  skew
incidents    1  0.32
training*    2  0.00
empathy      3 -0.37
years        4  0.52
logincidents <- log(data$incidents + (-1 * min(data$incidents) + 
    1))
[1] 67
model_training3 <- lm(logincidents ~ training + years_m + empathy_m, 
    data = data)
[1] 68
summary(model_training3)
[1] 69

Call:
lm(formula = logincidents ~ training + years_m + empathy_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.377249   0.011606  32.504  < 2e-16 ***
trainingTraining -0.111288   0.016497  -6.746 1.67e-10 ***
years_m          -0.010283   0.002769  -3.713 0.000266 ***
empathy_m         0.018550   0.003372   5.501 1.17e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

qqPlot(model_training3)
[1] 70
shapiro.test(model_training3$residuals)
[1] 71

	Shapiro-Wilk normality test

data:  model_training3$residuals
W = 0.9905, p-value = 0.2109

residualPlots(model_training3)
[1] 72
ncvTest(model_training3)
[1] 73
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.036059, Df = 1, p = 0.30874
crPlots(model_training3)
[1] 74
durbinWatsonTest(model_training3)
[1] 75
 lag Autocorrelation D-W Statistic p-value
   1       -0.116516      2.217742    0.12
 Alternative hypothesis: rho != 0
vif(model_training3)
[1] 76
 training   years_m empathy_m 
 1.020633  1.085089  1.092467 
b1trainingcoeff <- (exp(model_training3$coefficients[2]) - 1)
[1] 77
model_feedback <- lm(incidents ~ feedback + years_m + empathy_m, 
    data = data)
[1] 78
summary(model_feedback)
[1] 79

Call:
lm(formula = incidents ~ feedback + years_m + empathy_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

cooks_feedback <- cooks.distance(model_feedback)
[1] 80
which(cooks_feedback > (4/(200 - 3 - 1)))
[1] 81
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(model_feedback, which = 4)
[1] 82
model_feedback2 <- lm(incidents ~ feedback + years_m + empathy_m, 
    data = data[-c(74, 89, 137), ])
[1] 83
summary(model_feedback2)
[1] 84

Call:
lm(formula = incidents ~ feedback + years_m + empathy_m, data = data[-c(74, 
    89, 137), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.34740 -0.11326 -0.01073  0.11335  0.53413 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.412290   0.016427  25.098  < 2e-16 ***
feedbackFeedback  0.128900   0.023282   5.537 9.99e-08 ***
years_m          -0.013583   0.004147  -3.276  0.00125 ** 
empathy_m         0.024888   0.004950   5.028 1.13e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1633 on 193 degrees of freedom
Multiple R-squared:  0.2282,	Adjusted R-squared:  0.2162 
F-statistic: 19.02 on 3 and 193 DF,  p-value: 7.541e-11

cooks_feedback2 <- cooks.distance(model_feedback2)
[1] 85
which(cooks_feedback2 > (4/(197 - 3 - 1)))
[1] 86
 17  73 154 156 160 165 176 181 
 17  73 151 153 157 162 173 178 
plot(model_feedback2, which = 4)
[1] 87
durbinWatsonTest(model_feedback)
[1] 88
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
datanew <- data[order(runif(nrow(data))), ]
[1] 89
model_feedback3 <- lm(incidents ~ feedback + years_m + empathy_m, 
    data = datanew)
[1] 90
summary(model_feedback3)
[1] 91

Call:
lm(formula = incidents ~ feedback + years_m + empathy_m, data = datanew)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

durbinWatsonTest(model_feedback3)
[1] 92
 lag Autocorrelation D-W Statistic p-value
   1     0.007001905      1.985814   0.902
 Alternative hypothesis: rho != 0
qqPlot(model_feedback3)
[1] 93
shapiro.test(model_feedback3$residuals)
[1] 94

	Shapiro-Wilk normality test

data:  model_feedback3$residuals
W = 0.98772, p-value = 0.08174

residualPlots(model_feedback3)
[1] 95
ncvTest(model_feedback3)
[1] 96
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(model_feedback3)
[1] 97
vif(model_feedback3)
[1] 98
 feedback   years_m empathy_m 
 1.005211  1.077467  1.079397 
AIC(model_training3, model_feedback3)
[1] 99
                df       AIC
model_training3  5 -289.9740
model_feedback3  5 -143.9591
BIC(model_training3, model_feedback3)
[1] 100
                df       BIC
model_training3  5 -273.4824
model_feedback3  5 -127.4675
(abs(model_feedback3$coefficients[2]) - abs(b1trainingcoeff)) * 
    100
[1] 101
feedbackFeedback 
        2.681246 
summary(model_training3)
[1] 102

Call:
lm(formula = logincidents ~ training + years_m + empathy_m, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.377249   0.011606  32.504  < 2e-16 ***
trainingTraining -0.111288   0.016497  -6.746 1.67e-10 ***
years_m          -0.010283   0.002769  -3.713 0.000266 ***
empathy_m         0.018550   0.003372   5.501 1.17e-07 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

summary(model_feedback3)
[1] 103

Call:
lm(formula = incidents ~ feedback + years_m + empathy_m, data = datanew)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.408934   0.016655  24.553  < 2e-16 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
years_m          -0.012689   0.003975  -3.192  0.00165 ** 
empathy_m         0.023187   0.004829   4.802 3.11e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

describeBy(data$incidents, group = list(data$feedback, data$training), 
    mat = T)
[1] 104
    item      group1      group2 vars  n      mean        sd    median   trimmed     mad        min       max
X11    1 No Feedback No Training    1 50 0.4933333 0.1673794 0.4166667 0.4770833 0.12355 0.25000000 0.9166667
X12    2    Feedback No Training    1 50 0.5900000 0.1707327 0.5833333 0.5875000 0.12355 0.25000000 0.9166667
X13    3 No Feedback    Training    1 50 0.3333333 0.1398493 0.3333333 0.3270833 0.12355 0.08333333 0.5833333
        range       skew   kurtosis         se
X11 0.6666667 0.81813067 -0.0698501 0.02367103
X12 0.6666667 0.04793352 -0.8075298 0.02414525
X13 0.5000000 0.15233791 -0.9575614 0.01977768
 [ reached 'max' / getOption("max.print") -- omitted 1 rows ]
model_interaction <- lm(incidents ~ training + feedback + empathy_m + 
    years_m + training:feedback, data = data)
[1] 105
summary(model_interaction)
[1] 106

Call:
lm(formula = incidents ~ training + feedback + empathy_m + years_m + 
    training:feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.509636   0.020807  24.494  < 2e-16 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
empathy_m                          0.028695   0.004328   6.630 3.25e-10 ***
years_m                           -0.015720   0.003518  -4.468 1.34e-05 ***
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

cooks_interaction <- cooks.distance(model_interaction)
[1] 107
which(cooks_interaction > (4/(200 - 5 - 1)))
[1] 108
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
plot(model_interaction, which = 4)
[1] 109
model_interaction2 <- lm(incidents ~ training + feedback + empathy_m + 
    years_m + training:feedback, data = data[-c(13, 137, 176), 
    ])
[1] 110
cooks_interaction2 <- cooks.distance(model_interaction2)
[1] 111
which(cooks_interaction2 > (4/(197 - 5 - 1)))
[1] 112
 35  73  74 117 156 159 160 165 181 
 34  72  73 116 154 157 158 163 178 
plot(model_interaction2, which = 4)
[1] 113
ncvTest(model_interaction)
[1] 114
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
residualPlots(model_interaction)
[1] 115
model_interaction3 <- lm(logincidents ~ training + feedback + 
    empathy_m + years_m + training:feedback, data = data)
[1] 116
summary(model_interaction3)
[1] 117

Call:
lm(formula = logincidents ~ training + feedback + empathy_m + 
    years_m + training:feedback, data = data)

Residuals:
      Min        1Q    Median        3Q       Max 
-0.226383 -0.071808 -0.000811  0.069089  0.284822 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.348968   0.014712  23.720  < 2e-16 ***
trainingTraining                  -0.151903   0.021123  -7.191 1.36e-11 ***
feedbackFeedback                   0.058376   0.020716   2.818  0.00533 ** 
empathy_m                          0.021048   0.003060   6.878 8.14e-11 ***
years_m                           -0.011505   0.002488  -4.625 6.84e-06 ***
trainingTraining:feedbackFeedback  0.077604   0.029583   2.623  0.00940 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1034 on 194 degrees of freedom
Multiple R-squared:  0.4176,	Adjusted R-squared:  0.4026 
F-statistic: 27.82 on 5 and 194 DF,  p-value: < 2.2e-16

ncvTest(model_interaction3)
[1] 118
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.577295, Df = 1, p = 0.44737
residualPlots(model_interaction3)
[1] 119
qqPlot(model_interaction3)
[1] 120
shapiro.test(model_interaction3$residuals)
[1] 121

	Shapiro-Wilk normality test

data:  model_interaction3$residuals
W = 0.99434, p-value = 0.6515

durbinWatsonTest(model_interaction3)
[1] 122
 lag Autocorrelation D-W Statistic p-value
   1      0.09726586      1.794988   0.148
 Alternative hypothesis: rho != 0
vif(model_interaction3)
[1] 123
         training          feedback         empathy_m           years_m training:feedback 
         2.086826          2.007327          1.122147          1.092150          3.070068 
cat_plot(model_interaction3, pred = feedback, modx = training, 
    data = data, geom = "line", interval = TRUE, y.label = "Log values of Incidents", 
    x.label = "Feedback", legend.main = "Training")
[1] 124
b5interactioncoeff <- exp(model_interaction3$coefficients[6]) - 
    1
[1] 125
