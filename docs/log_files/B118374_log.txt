

	####### B118374 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 2
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(interactions, quietly = T)
[1] 3
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [8] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(sandwich, quietly = T)
[1] 4
 [1] "sandwich"     "interactions" "car"          "carData"      "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
setwd(setwd("~/Documents/My Documents/Education/Uni of Edinburgh/Psychology/Year 3/RMS/Report/Report"))
[1] 5
data <- read.csv("../RMS2_report_1920.csv")
[1] 6
describe(data)
[1] 7
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
str(data)
[1] 8
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
data$training <- as.factor(data$training)
[1] 9
data$feedback <- as.factor(data$feedback)
[1] 10
str(data$training)
[1] 11
 Factor w/ 2 levels "1","2": 2 2 2 2 2 2 2 2 2 2 ...
NULL
summary(data$training)
[1] 12
  1   2 
100 100 
data$training <- factor(data$training, labels = c("no training", 
    "training"))
[1] 13
summary(data$training)
[1] 14
no training    training 
        100         100 
str(data$training)
[1] 15
 Factor w/ 2 levels "no training",..: 2 2 2 2 2 2 2 2 2 2 ...
NULL
str(data$feedback)
[1] 16
 Factor w/ 2 levels "1","2": 2 1 2 1 2 1 2 1 2 1 ...
NULL
summary(data$feedback)
[1] 17
  1   2 
100 100 
data$feedback <- factor(data$feedback, labels = c("no feedback", 
    "feedback"))
[1] 18
summary(data$feedback)
[1] 19
no feedback    feedback 
        100         100 
str(data$feedback)
[1] 20
 Factor w/ 2 levels "no feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
NULL
plot(data$training, data$incidents)
[1] 21
plot(data$feedback, data$incidents)
[1] 22
before <- lm(incidents ~ training + feedback + empathy + years, 
    data = data)
[1] 23
summary(before)
[1] 24

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.331953   0.048708   6.815 1.15e-10 ***
trainingtraining -0.153824   0.021128  -7.281 7.98e-12 ***
feedbackfeedback  0.133715   0.020968   6.377 1.28e-09 ***
empathy           0.027191   0.004328   6.283 2.12e-09 ***
years            -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

cooks <- cooks.distance(before)
[1] 25
names(which(cooks > (4/198)))
[1] 26
 [1] "13"  "35"  "74"  "117" "131" "137" "141" "156" "160" "176"
plot(before, which = 4)
[1] 27
after <- lm(incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 137, 176), ])
[1] 28
summary(after)
[1] 29

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 137, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31479 -0.10102 -0.00300  0.09041  0.35676 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.322487   0.046151   6.988 4.48e-11 ***
trainingtraining -0.153003   0.020113  -7.607 1.22e-12 ***
feedbackfeedback  0.132020   0.019981   6.607 3.76e-10 ***
empathy           0.029143   0.004167   6.993 4.34e-11 ***
years            -0.017169   0.003489  -4.921 1.85e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.14 on 192 degrees of freedom
Multiple R-squared:  0.4232,	Adjusted R-squared:  0.4112 
F-statistic: 35.22 on 4 and 192 DF,  p-value: < 2.2e-16

hats <- hatvalues(before)
[1] 30
head(hats, 20)
[1] 31
         1          2          3          4          5          6          7          8          9         10 
0.01712163 0.01549576 0.02001541 0.01701625 0.02394476 0.01751286 0.02125280 0.02488761 0.01874782 0.01688360 
        11         12         13         14         15         16         17         18         19         20 
0.01833535 0.02484967 0.01655041 0.01759398 0.01655041 0.04465575 0.03320873 0.01701625 0.02001541 0.02623618 
which(hats > 2 * mean(hats))
[1] 32
 61  88  89  92 137 141 154 175 200 
 61  88  89  92 137 141 154 175 200 
after2 <- lm(incidents ~ training + feedback + empathy + years, 
    data = data[-c(61, 88, 89, 94, 137, 141, 154, 175, 200), 
        ])
[1] 33
summary(after2)
[1] 34

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data[-c(61, 88, 89, 94, 137, 141, 154, 175, 200), 
        ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32391 -0.10171 -0.01101  0.08703  0.47041 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.335906   0.055250   6.080 6.68e-09 ***
trainingtraining -0.151189   0.021796  -6.937 6.44e-11 ***
feedbackfeedback  0.136447   0.021580   6.323 1.86e-09 ***
empathy           0.028149   0.005094   5.526 1.10e-07 ***
years            -0.017114   0.004220  -4.055 7.35e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1484 on 186 degrees of freedom
Multiple R-squared:  0.3601,	Adjusted R-squared:  0.3463 
F-statistic: 26.16 on 4 and 186 DF,  p-value: < 2.2e-16

data$empathy <- scale(data$empathy)
[1] 35
m1 <- lm(empathy ~ years, data = data)
[1] 36
summary(m1)
[1] 37

Call:
lm(formula = empathy ~ years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.69717    0.19347  -3.603 0.000397 ***
years        0.08575    0.02226   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(data$empathy ~ data$years, ylab = "empathy", xlab = "years", 
    main = "Linearity test")
[1] 38
abline(lm(empathy ~ years, data = data))
[1] 39
lines(lowess(data$years, data$empathy))
[1] 40
cor.test(data$empathy, data$years, method = "spearman", exact = FALSE)
[1] 41

	Spearman's rank correlation rho

data:  data$empathy and data$years
S = 923838, p-value = 9.723e-06
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho 
0.3071045 

r <- cor(data$empathy, data$years, method = "spearman")
[1] 42
r * sqrt((200 - 2)/(1 - r^2))
[1] 43
         [,1]
[1,] 4.540772
plot(data$training, data$incidents)
[1] 44
plot(data$feedback, data$incidents)
[1] 45
m2 <- lm(incidents ~ training + empathy + years, data = data)
[1] 46
summary(m2)
[1] 47

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.064430   0.012014   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

qqPlot(m2)
[1] 48
hist(m2$residuals, xlab = "Residuals", main = "Histogram of Residuals")
[1] 49
shapiro.test(m2$residuals)
[1] 50

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.97994, p-value = 0.005838

log.incidents <- log(data$incidents + (-1 * min(data$incidents) + 
    1))
[1] 51
summary(log.incidents)
[1] 52
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.2231  0.2877  0.3216  0.4055  0.6061 
m3 <- lm(log.incidents ~ training + empathy + years, data = data)
[1] 53
summary(m3)
[1] 54

Call:
lm(formula = log.incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.460852   0.026028  17.706  < 2e-16 ***
trainingtraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy           0.047061   0.008555   5.501 1.17e-07 ***
years            -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

shapiro.test(m3$residuals)
[1] 55

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.9905, p-value = 0.2109

hist(m3$residuals, xlab = "Residuals", main = "Histogram of Residuals")
[1] 56
ncvTest(m3)
[1] 57
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.036059, Df = 1, p = 0.30874
residualPlot(m3)
[1] 58
crPlots(m3)
[1] 59
durbinWatsonTest(m3)
[1] 60
 lag Autocorrelation D-W Statistic p-value
   1       -0.116516      2.217742   0.128
 Alternative hypothesis: rho != 0
vif(m3)
[1] 61
training  empathy    years 
1.020633 1.092467 1.085089 
m4 <- lm(log.incidents ~ feedback + empathy + years, data = data)
[1] 62
summary(m4)
[1] 63

Call:
lm(formula = log.incidents ~ feedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27663 -0.07576 -0.00237  0.08302  0.35261 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.349057   0.025597  13.637  < 2e-16 ***
feedbackfeedback  0.095615   0.016841   5.677 4.87e-08 ***
empathy           0.042942   0.008748   4.909 1.92e-06 ***
years            -0.009257   0.002839  -3.261  0.00131 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1188 on 196 degrees of freedom
Multiple R-squared:  0.2235,	Adjusted R-squared:  0.2116 
F-statistic:  18.8 on 3 and 196 DF,  p-value: 9.283e-11

qqPlot(m4, main = "QQ-Plot")
[1] 64
shapiro.test(m4$residuals)
[1] 65

	Shapiro-Wilk normality test

data:  m4$residuals
W = 0.99572, p-value = 0.8487

hist(m4$residuals, xlab = "residuals", main = "Histogram of residuals")
[1] 66
ncvTest(m4)
[1] 67
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.6746094, Df = 1, p = 0.41145
residualPlot(m4)
[1] 68
crPlots(m4)
[1] 69
durbinWatsonTest(m4)
[1] 70
 lag Autocorrelation D-W Statistic p-value
   1       0.2794347      1.431864       0
 Alternative hypothesis: rho != 0
vif(m4)
[1] 71
feedback  empathy    years 
1.005211 1.079397 1.077467 
BIC(m3, m4)
[1] 72
   df       BIC
m3  5 -273.4824
m4  5 -262.1757
summary(m3)
[1] 73

Call:
lm(formula = log.incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.460852   0.026028  17.706  < 2e-16 ***
trainingtraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy           0.047061   0.008555   5.501 1.17e-07 ***
years            -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

summary(m4)
[1] 74

Call:
lm(formula = log.incidents ~ feedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27663 -0.07576 -0.00237  0.08302  0.35261 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.349057   0.025597  13.637  < 2e-16 ***
feedbackfeedback  0.095615   0.016841   5.677 4.87e-08 ***
empathy           0.042942   0.008748   4.909 1.92e-06 ***
years            -0.009257   0.002839  -3.261  0.00131 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1188 on 196 degrees of freedom
Multiple R-squared:  0.2235,	Adjusted R-squared:  0.2116 
F-statistic:  18.8 on 3 and 196 DF,  p-value: 9.283e-11

m5 <- lm(log.incidents ~ training + feedback + training * feedback, 
    data = data)
[1] 75
summary(m5)
[1] 76

Call:
lm(formula = log.incidents ~ training + feedback + training * 
    feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32886 -0.07357  0.00614  0.07068  0.27727 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.33701    0.01649  20.442  < 2e-16 ***
trainingtraining                  -0.12001    0.02332  -5.147  6.4e-07 ***
feedbackfeedback                   0.06653    0.02332   2.853  0.00479 ** 
trainingtraining:feedbackfeedback  0.04534    0.03297   1.375  0.17072    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1166 on 196 degrees of freedom
Multiple R-squared:  0.252,	Adjusted R-squared:  0.2405 
F-statistic: 22.01 on 3 and 196 DF,  p-value: 2.515e-12

cat_plot(m5, pred = training, modx = feedback, data = data, plot.points = TRUE, 
    main = "Interaction of training and feedback")
[1] 77
interaction.plot(data$training, data$feedback, log.incidents, 
    main = "Interaction of training and feedback")
[1] 78
qqPlot(m5)
[1] 79
shapiro.test(m5$residuals)
[1] 80

	Shapiro-Wilk normality test

data:  m5$residuals
W = 0.98649, p-value = 0.05345

hist(m5$residuals, xlab = "residuals", main = "histogram of residuals")
[1] 81
ncvTest(m5)
[1] 82
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.04011943, Df = 1, p = 0.84125
durbinWatsonTest(m5)
[1] 83
 lag Autocorrelation D-W Statistic p-value
   1       0.1133615      1.766819   0.134
 Alternative hypothesis: rho != 0
vif(m5)
[1] 84
         training          feedback training:feedback 
                2                 2                 3 
