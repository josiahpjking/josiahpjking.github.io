

	####### B099644 R script #######

install.packages("psych")
[1] 1
install.packages("car")
[1] 2
install.packages("ggplot2")
[1] 3
install.packages("stats")
[1] 4
install.packages("interactions")
[1] 5
library(psych, quietly = T)
[1] 6
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 7
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library(stats, quietly = T)
[1] 8
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library(ggplot2, quietly = T)
[1] 9
 [1] "ggplot2"   "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[11] "methods"   "base"     
library(interactions, quietly = T)
[1] 10
 [1] "interactions" "ggplot2"      "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [9] "grDevices"    "utils"        "datasets"     "methods"      "base"        
data <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 11
str(data)
[1] 12
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
data$training <- factor(data$training, levels = c(1, 2), labels = c("No Training", 
    "Training"))
[1] 13
data$feedback <- factor(data$feedback, levels = c(1, 2), labels = c("No Feedback", 
    "Feedback"))
[1] 14
str(data)
[1] 15
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "No Training",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "No Feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
summary(data)
[1] 16
    subject         incidents              training          feedback      empathy          years      
 Min.   :  1.00   Min.   :0.08333   No Training:100   No Feedback:100   Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 50.75   1st Qu.:0.33333   Training   :100   Feedback   :100   1st Qu.: 9.00   1st Qu.: 6.00  
 Median :100.50   Median :0.41667                                       Median :10.00   Median : 8.00  
 Mean   :100.50   Mean   :0.47500                                       Mean   :10.18   Mean   : 8.13  
 3rd Qu.:150.25   3rd Qu.:0.58333                                       3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :200.00   Max.   :0.91667                                       Max.   :16.00   Max.   :19.00  
summary(data[, 3:4])
[1] 17
        training          feedback  
 No Training:100   No Feedback:100  
 Training   :100   Feedback   :100  
describe(data)[c(2, 5, 6), c(2:4, 8, 9, 11)]
[1] 18
            n  mean   sd  min   max  skew
incidents 200  0.48 0.19 0.08  0.92  0.32
empathy   200 10.18 2.54 3.00 16.00 -0.37
years     200  8.13 3.08 1.00 19.00  0.52
model1 <- lm(scale(empathy) ~ scale(years), data = data)
[1] 19
summary(model1)
[1] 20

Call:
lm(formula = scale(empathy) ~ scale(years), data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.419e-16  6.837e-02   0.000 1.000000    
scale(years)  2.640e-01  6.854e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

cooks1 <- cooks.distance(model1)
[1] 21
which(cooks1 > (4/(200 - 1 - 1)))
[1] 22
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
plot(model1, which = 4)
[1] 23
cutoff1 <- 4/(200 - 1 - 1)
[1] 24
abline(h = cutoff1, col = "red", lty = 3)
[1] 25
model1a <- lm(scale(empathy) ~ scale(years), data = data[-c(16, 
    61, 88, 89, 94, 108, 137, 141, 154, 163, 171, 175, 192, 200), 
    ])
[1] 26
summary(model1a)
[1] 27

Call:
lm(formula = scale(empathy) ~ scale(years), data = data[-c(16, 
    61, 88, 89, 94, 108, 137, 141, 154, 163, 171, 175, 192, 200), 
    ])

Residuals:
     Min       1Q   Median       3Q      Max 
-2.15789 -0.63505  0.00367  0.60248  2.55045 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.271e-17  6.975e-02   0.000        1    
scale(years)  3.160e-01  6.994e-02   4.518 1.11e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9513 on 184 degrees of freedom
Multiple R-squared:  0.09986,	Adjusted R-squared:  0.09497 
F-statistic: 20.41 on 1 and 184 DF,  p-value: 1.114e-05

data[c(16, 61, 88, 89, 94, 108, 137, 141, 154, 163, 171, 175, 
    192, 200), ]
[1] 28
    subject  incidents    training    feedback empathy years
16       16 0.16666667    Training No Feedback       5     3
61       61 0.41666667    Training    Feedback       3     2
88       88 0.16666667    Training No Feedback       3     1
89       89 0.08333333    Training    Feedback       6    15
94       94 0.08333333    Training No Feedback       8    14
108     108 0.33333333 No Training No Feedback       8    14
137     137 0.58333333 No Training    Feedback       6    18
141     141 0.33333333 No Training    Feedback       3     2
 [ reached 'max' / getOption("max.print") -- omitted 6 rows ]
qqPlot(model1)
[1] 29
shapiro.test(model1$residuals)
[1] 30

	Shapiro-Wilk normality test

data:  model1$residuals
W = 0.98911, p-value = 0.1321

residualPlots(model1)
[1] 31
ncvTest(model1)
[1] 32
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
crPlots(model1)
[1] 33
durbinWatsonTest(model1)
[1] 34
 lag Autocorrelation D-W Statistic p-value
   1       0.1017162      1.769879   0.106
 Alternative hypothesis: rho != 0
data$quad_term <- (scale(data$years))^2
[1] 35
model1b <- lm(scale(data$empathy) ~ scale(data$years) + data$quad_term)
[1] 36
summary(model1b)
[1] 37

Call:
lm(formula = scale(data$empathy) ~ scale(data$years) + data$quad_term)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)        0.38537    0.06599   5.840 2.13e-08 ***
scale(data$years)  0.46511    0.05824   7.986 1.13e-13 ***
data$quad_term    -0.38731    0.03685 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

cooks2 <- cooks.distance(model1b)
[1] 38
which(cooks2 > (4/(200 - 1 - 1)))
[1] 39
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(model1b, which = 4)
[1] 40
cutoff2 <- 4/(200 - 1 - 1)
[1] 41
abline(h = cutoff2, col = "red", lty = 3)
[1] 42
model1c <- lm(scale(empathy) ~ scale(years) + quad_term, data = data[-c(61, 
    89, 137, 141, 154, 163, 165, 175), ])
[1] 43
summary(model1c)
[1] 44

Call:
lm(formula = scale(empathy) ~ scale(years) + quad_term, data = data[-c(61, 
    89, 137, 141, 154, 163, 165, 175), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-1.90901 -0.47173  0.04816  0.51509  2.05428 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.34912    0.07279   4.796 3.27e-06 ***
scale(years)  0.46177    0.05917   7.804 3.97e-13 ***
quad_term    -0.42993    0.05400  -7.962 1.54e-13 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.805 on 189 degrees of freedom
Multiple R-squared:  0.3587,	Adjusted R-squared:  0.3519 
F-statistic: 52.86 on 2 and 189 DF,  p-value: < 2.2e-16

qqPlot(model1b)
[1] 45
shapiro.test(model1b$residuals)
[1] 46

	Shapiro-Wilk normality test

data:  model1b$residuals
W = 0.9941, p-value = 0.6155

residualPlots(model1b)
[1] 47
ncvTest(model1b)
[1] 48
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
crPlots(model1b)
[1] 49
durbinWatsonTest(model1b)
[1] 50
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855    0.86
 Alternative hypothesis: rho != 0
with(data, plot(years, empathy, col = "darkgrey", xlab = "Years of Experience", 
    ylab = "Empathy"))
[1] 51
model1b_plotted <- lm(empathy ~ poly(years, 2, raw = TRUE), data = data)
[1] 52
years = seq(min(data$years), max(data$years), length = 1000)
[1] 53
pred = data.frame(years, empathy = predict(model1b_plotted, newdata = data.frame(years)))
[1] 54
with(pred, lines(years, empathy, col = "darkred", type = "l", 
    cex = 10))
[1] 55
cf = coef(model1b_plotted)
[1] 56
D1 = 2 * cf[3] * pred$years + cf[2]
[1] 57
max_x = (-cf[2])/(2 * cf[3])
[1] 58
max_y = cf[1] + cf[2] * max_x + cf[3] * (max_x^2)
[1] 59
points(max_x, max_y, pch = 16, col = "red")
[1] 60
NULL
text(max_x, max_y, label = round(max_x, 2), adj = c(0.5, -1), 
    cex = 0.8)
[1] 61
NULL
model2 <- lm(incidents ~ training + empathy + years, data = data)
[1] 62
summary(model2)
[1] 63

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

cooks3 <- cooks.distance(model2)
[1] 64
which(cooks3 > (4/(200 - 3 - 1)))
[1] 65
 13  35  74 137 165 
 13  35  74 137 165 
plot(model2, which = 4)
[1] 66
cutoff3 <- 4/(200 - 3 - 1)
[1] 67
abline(h = cutoff3, col = "red", lty = 3)
[1] 68
model2a <- lm(incidents ~ training + empathy + years, data = data[-c(13, 
    35, 74, 137, 165), ])
[1] 69
summary(model2a)
[1] 70

Call:
lm(formula = incidents ~ training + empathy + years, data = data[-c(13, 
    35, 74, 137, 165), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28818 -0.11426 -0.00621  0.09990  0.40582 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.387561   0.049420   7.842 3.04e-13 ***
trainingTraining -0.153846   0.021969  -7.003 4.16e-11 ***
empathy           0.028505   0.004568   6.240 2.76e-09 ***
years            -0.016177   0.003838  -4.215 3.84e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1521 on 191 degrees of freedom
Multiple R-squared:  0.3042,	Adjusted R-squared:  0.2932 
F-statistic: 27.83 on 3 and 191 DF,  p-value: 5.621e-15

qqPlot(model2)
[1] 71
shapiro.test(model2$residuals)
[1] 72

	Shapiro-Wilk normality test

data:  model2$residuals
W = 0.97994, p-value = 0.005838

hist(model2$residuals)
[1] 73
residualPlots(model2)
[1] 74
ncvTest(model2)
[1] 75
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(model2)
[1] 76
durbinWatsonTest(model2)
[1] 77
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.178
 Alternative hypothesis: rho != 0
vif(model2)
[1] 78
training  empathy    years 
1.020633 1.092467 1.085089 
ggplot(data = data, aes(training, incidents)) + geom_jitter(alpha = 0.5, 
    width = 0.08, height = 0, size = 2.5) + theme_grey(base_size = 15) + 
    stat_summary(fun.y = "mean", geom = "line", aes(group = 1), 
        col = "red") + stat_summary(fun.y = mean, colour = "Red", 
    geom = "point", size = 3) + stat_summary(fun.data = mean_se, 
    geom = "errorbar", width = 0.1) + labs(x = "Training condition", 
    y = "Percentage of incidents intervened on")
[1] 79
model3 <- lm(incidents ~ feedback + empathy + years, data = data)
[1] 80
summary(model3)
[1] 81

Call:
lm(formula = incidents ~ feedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276161   0.054108   5.104 7.84e-07 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy           0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

cooks4 <- cooks.distance(model3)
[1] 82
which(cooks4 > (4/(200 - 3 - 1)))
[1] 83
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(model3, which = 4)
[1] 84
cutoff4 <- 4/(200 - 3 - 1)
[1] 85
abline(h = cutoff4, col = "red", lty = 3)
[1] 86
qqPlot(model3)
[1] 87
shapiro.test(model3$residuals)
[1] 88

	Shapiro-Wilk normality test

data:  model3$residuals
W = 0.98772, p-value = 0.08174

residualPlots(model3)
[1] 89
ncvTest(model3)
[1] 90
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(model3)
[1] 91
durbinWatsonTest(model3)
[1] 92
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(model3)
[1] 93
feedback  empathy    years 
1.005211 1.079397 1.077467 
ggplot(data = data, aes(feedback, incidents)) + geom_jitter(alpha = 0.5, 
    width = 0.08, height = 0, size = 2.5) + theme_grey(base_size = 15) + 
    stat_summary(fun.y = "mean", geom = "line", aes(group = 1), 
        col = "red") + stat_summary(fun.y = mean, colour = "Red", 
    geom = "point", size = 3) + stat_summary(fun.data = mean_se, 
    geom = "errorbar", width = 0.1) + labs(x = "Feedback condition", 
    y = "Percentage of incidents intervened on")
[1] 94
AIC(model2, model3)
[1] 95
       df       AIC
model2  5 -154.1654
model3  5 -143.9591
BIC(model2, model3)
[1] 96
       df       BIC
model2  5 -137.6738
model3  5 -127.4675
model5 <- lm(incidents ~ training + feedback + empathy + years + 
    training * feedback, data = data)
[1] 97
summary(model5)
[1] 98

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training * feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.345467   0.048515   7.121 2.04e-11 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
empathy                            0.028695   0.004328   6.630 3.25e-10 ***
years                             -0.015720   0.003518  -4.468 1.34e-05 ***
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

cooks5 <- cooks.distance(model5)
[1] 99
which(cooks5 > (4/(200 - 5 - 1)))
[1] 100
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
plot(model5, which = 4)
[1] 101
cutoff5 <- 4/(200 - 5 - 1)
[1] 102
abline(h = cutoff5, col = "red", lty = 3)
[1] 103
model5c <- lm(incidents ~ training + feedback + empathy + years + 
    training * feedback, data = data[-c(13, 73, 74, 89, 117, 
    137, 160, 165, 176), ])
[1] 104
summary(model5c)
[1] 105

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    training * feedback, data = data[-c(13, 73, 74, 89, 117, 
    137, 160, 165, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.28269 -0.09632  0.00081  0.09067  0.34167 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.312353   0.044361   7.041 3.62e-11 ***
trainingTraining                  -0.184679   0.027340  -6.755 1.80e-10 ***
feedbackFeedback                   0.094956   0.027103   3.504 0.000576 ***
empathy                            0.030839   0.004103   7.516 2.35e-12 ***
years                             -0.016135   0.003427  -4.708 4.89e-06 ***
trainingTraining:feedbackFeedback  0.084936   0.038572   2.202 0.028899 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1315 on 185 degrees of freedom
Multiple R-squared:  0.4496,	Adjusted R-squared:  0.4348 
F-statistic: 30.23 on 5 and 185 DF,  p-value: < 2.2e-16

data_num <- read.csv("~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 106
data_num$training_dummy <- data_num$training - 1
[1] 107
data_num$feedback_dummy <- data_num$feedback - 1
[1] 108
data_num$interact_term <- data_num$training_dummy * data_num$feedback_dummy
[1] 109
data$interact_term <- factor(data_num$interact_term)
[1] 110
model5a <- lm(incidents ~ training + feedback + empathy + years + 
    interact_term, data = data)
[1] 111
summary(model5a)
[1] 112

Call:
lm(formula = incidents ~ training + feedback + empathy + years + 
    interact_term, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.345467   0.048515   7.121 2.04e-11 ***
trainingTraining -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback  0.085558   0.029299   2.920  0.00391 ** 
empathy           0.028695   0.004328   6.630 3.25e-10 ***
years            -0.015720   0.003518  -4.468 1.34e-05 ***
interact_term1    0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

qqPlot(model5)
[1] 113
shapiro.test(model5$residuals)
[1] 114

	Shapiro-Wilk normality test

data:  model5$residuals
W = 0.98794, p-value = 0.08817

residualPlots(model5)
[1] 115
ncvTest(model5)
[1] 116
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
crPlots(model5a)
[1] 117
durbinWatsonTest(model5)
[1] 118
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.216
 Alternative hypothesis: rho != 0
vif(model5)
[1] 119
         training          feedback           empathy             years training:feedback 
         2.086826          2.007327          1.122147          1.092150          3.070068 
cat_plot(model5, training, modx = feedback, geom = "line", interval = TRUE, 
    int.type = "confidence", int.width = 0.95, x.label = "Training Condition", 
    errorbar.width = 0.2, y.label = "Percentage of Incidents Intervened on", 
    legend.main = "Feedback Condition")
[1] 120
