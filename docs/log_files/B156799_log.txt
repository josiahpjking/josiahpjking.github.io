

	####### B156799 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 2
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
rm(list = ls())
[1] 3
df <- read.csv("../RMS2_report_1920.csv", header = TRUE)
[1] 4
df$training <- as.factor(df$training)
[1] 5
df$feedback <- as.factor(df$feedback)
[1] 6
str(df$training)
[1] 7
 Factor w/ 2 levels "1","2": 2 2 2 2 2 2 2 2 2 2 ...
NULL
summary(df$training)
[1] 8
  1   2 
100 100 
str(df$feedback)
[1] 9
 Factor w/ 2 levels "1","2": 2 1 2 1 2 1 2 1 2 1 ...
NULL
summary(df$feedback)
[1] 10
  1   2 
100 100 
df$training <- factor(df$training, labels = c("No training", 
    "Training"))
[1] 11
str(df$training)
[1] 12
 Factor w/ 2 levels "No training",..: 2 2 2 2 2 2 2 2 2 2 ...
NULL
summary(df$training)
[1] 13
No training    Training 
        100         100 
df$feedback <- factor(df$feedback, labels = c("No feedback", 
    "Feedback"))
[1] 14
str(df$feedback)
[1] 15
 Factor w/ 2 levels "No feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
NULL
summary(df$feedback)
[1] 16
No feedback    Feedback 
        100         100 
str(df)
[1] 17
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "No training",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "No feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
describe(df)
[1] 18
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training*    3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
describe(df)[, c(2:4, 8, 9)]
[1] 19
            n   mean    sd  min    max
subject   200 100.50 57.88 1.00 200.00
incidents 200   0.48  0.19 0.08   0.92
training* 200   1.50  0.50 1.00   2.00
feedback* 200   1.50  0.50 1.00   2.00
empathy   200  10.18  2.54 3.00  16.00
years     200   8.13  3.08 1.00  19.00
m1 <- lm(empathy ~ years, data = df)
[1] 20
summary(m1)
[1] 21

Call:
lm(formula = empathy ~ years, data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-7.5399 -1.5160  0.0708  1.6357  5.8533 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)  8.40625    0.49085  17.126  < 2e-16 ***
years        0.21756    0.05648   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 2.453 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

qqPlot(m1)
[1] 22
hist(m1$residuals)
[1] 23
shapiro.test(m1$residuals)
[1] 24

	Shapiro-Wilk normality test

data:  m1$residuals
W = 0.98911, p-value = 0.1321

residualPlots(m1)
[1] 25
ncvTest(m1)
[1] 26
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
plot(empathy ~ years, data = df, pch = 19, main = "Relationship between empathy and years", 
    ylab = "Empathy", xlab = "Years of experience")
[1] 27
abline(m1, col = "red")
[1] 28
lines(lowess(df$empathy ~ df$years), col = "blue")
[1] 29
empathy_m <- df$empathy - mean(df$empathy)
[1] 30
years_m <- df$years - mean(df$years)
[1] 31
m1a <- lm(empathy_m ~ years_m + I(years_m^2), data = df)
[1] 32
summary(m1a)
[1] 33

Call:
lm(formula = empathy_m ~ years_m + I(years_m^2), data = df)

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.977696   0.167423   5.840 2.13e-08 ***
years_m       0.383236   0.047986   7.986 1.13e-13 ***
I(years_m^2) -0.103645   0.009861 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

qqPlot(m1a)
[1] 34
hist(m1a$residuals)
[1] 35
shapiro.test(m1a$residuals)
[1] 36

	Shapiro-Wilk normality test

data:  m1a$residuals
W = 0.9941, p-value = 0.6155

residualPlots(m1a)
[1] 37
ncvTest(m1a)
[1] 38
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
crPlots(m1a)
[1] 39
durbinWatsonTest(m1a)
[1] 40
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.896
 Alternative hypothesis: rho != 0
vif(m1a)
[1] 41
     years_m I(years_m^2) 
    1.120963     1.120963 
cooks <- cooks.distance(m1a)
[1] 42
which(cooks > (4/(200 - 2 - 1)))
[1] 43
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(m1a, which = 4)
[1] 44
m1b <- lm(empathy_m ~ years_m + I(years_m^2), data = df[-c(89, 
    154, 175)])
[1] 45
summary(m1b)
[1] 46

Call:
lm(formula = empathy_m ~ years_m + I(years_m^2), data = df[-c(89, 
    154, 175)])

Residuals:
    Min      1Q  Median      3Q     Max 
-4.5069 -1.4011 -0.0835  1.1707  6.0622 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)   0.977696   0.167423   5.840 2.13e-08 ***
years_m       0.383236   0.047986   7.986 1.13e-13 ***
I(years_m^2) -0.103645   0.009861 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 1.969 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

m1a_coef <- summary(m1a)
[1] 47
m1b_coef <- summary(m1b)
[1] 48
compare <- data.frame(round(m1a_coef$coefficients[, 1], 3), round(m1a_coef$coefficients[, 
    4], 4), round(m1b_coef$coefficients[, 1], 3), round(m1b_coef$coefficients[, 
    4], 4))
[1] 49
colnames(compare) <- c("M1a Coef", "M1a p-value", "M1b Coef", 
    "M1b p-value")
[1] 50
compare

             M1a Coef M1a p-value M1b Coef M1b p-value
(Intercept)     0.978           0    0.978           0
years_m         0.383           0    0.383           0
I(years_m^2)   -0.104           0   -0.104           0


m2 <- lm(incidents ~ training + empathy + years, data = df)
[1] 52
summary(m2)
[1] 53

Call:
lm(formula = incidents ~ training + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

qqPlot(m2)
[1] 54
hist(m2$residuals)
[1] 55
shapiro.test(m2$residuals)
[1] 56

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.97994, p-value = 0.005838

residualPlots(m2)
[1] 57
ncvTest(m2)
[1] 58
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(m2)
[1] 59
durbinWatsonTest(m2)
[1] 60
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.142
 Alternative hypothesis: rho != 0
vif(m2)
[1] 61
training  empathy    years 
1.020633 1.092467 1.085089 
cooks2 <- cooks.distance(m2)
[1] 62
which(cooks2 > (4/(200 - 3 - 1)))
[1] 63
 13  35  74 137 165 
 13  35  74 137 165 
plot(m2, which = 4)
[1] 64
m2a <- lm(incidents ~ training + empathy + years, data = df[-c(13, 
    74, 137)])
[1] 65
summary(m2a)
[1] 66

Call:
lm(formula = incidents ~ training + empathy + years, data = df[-c(13, 
    74, 137)])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

m2_coef <- summary(m2)
[1] 67
m2a_coef <- summary(m2a)
[1] 68
compare <- data.frame(round(m2_coef$coefficients[, 1], 3), round(m2_coef$coefficients[, 
    4], 4), round(m2a_coef$coefficients[, 1], 3), round(m2a_coef$coefficients[, 
    4], 4))
[1] 69
colnames(compare) <- c("M2 Coef", "M2 p-value", "M2a Coef", "M2a p-value")
[1] 70
compare

                 M2 Coef M2 p-value M2a Coef M2a p-value
(Intercept)        0.407      0e+00    0.407       0e+00
trainingTraining  -0.152      0e+00   -0.152       0e+00
empathy            0.025      0e+00    0.025       0e+00
years             -0.014      4e-04   -0.014       4e-04


m3 <- lm(incidents ~ feedback + empathy + years, data = df)
[1] 72
summary(m3)
[1] 73

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276161   0.054108   5.104 7.84e-07 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy           0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

qqPlot(m3)
[1] 74
hist(m3$residuals)
[1] 75
shapiro.test(m3$residuals)
[1] 76

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.98772, p-value = 0.08174

residualPlots(m3)
[1] 77
ncvTest(m3)
[1] 78
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(m3)
[1] 79
durbinWatsonTest(m3)
[1] 80
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(m3)
[1] 81
feedback  empathy    years 
1.005211 1.079397 1.077467 
cooks3 <- cooks.distance(m3)
[1] 82
which(cooks3 > (4/(200 - 3 - 1)))
[1] 83
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(m3, which = 4)
[1] 84
m3a <- lm(incidents ~ feedback + empathy + years, data = df[-c(74, 
    89, 137)])
[1] 85
summary(m3a)
[1] 86

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df[-c(74, 
    89, 137)])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276161   0.054108   5.104 7.84e-07 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy           0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

m3_coef <- summary(m3)
[1] 87
m3a_coef <- summary(m3a)
[1] 88
compare <- data.frame(round(m3_coef$coefficients[, 1], 3), round(m3_coef$coefficients[, 
    4], 4), round(m3a_coef$coefficients[, 1], 3), round(m3a_coef$coefficients[, 
    4], 4))
[1] 89
colnames(compare) <- c("M3 Coef", "M3 p-value", "M3a Coef", "M3a p-value")
[1] 90
compare

                 M3 Coef M3 p-value M3a Coef M3a p-value
(Intercept)        0.276     0.0000    0.276      0.0000
feedbackFeedback   0.132     0.0000    0.132      0.0000
empathy            0.023     0.0000    0.023      0.0000
years             -0.013     0.0016   -0.013      0.0016


0.2565 > 0.2175
[1] 92
[1] TRUE
AIC(m2, m3)
[1] 93
   df       AIC
m2  5 -154.1654
m3  5 -143.9591
BIC(m2, m3)
[1] 94
   df       BIC
m2  5 -137.6738
m3  5 -127.4675
describeBy(df$incidents, group = list(df$training, df$feedback))
[1] 95

 Descriptive statistics by group 
: No training
: No feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.49 0.17   0.42    0.48 0.12 0.25 0.92  0.67 0.82    -0.07 0.02
--------------------------------------------------------------------------------------- 
: Training
: No feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.33 0.14   0.33    0.33 0.12 0.08 0.58   0.5 0.15    -0.96 0.02
--------------------------------------------------------------------------------------- 
: No training
: Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.59 0.17   0.58    0.59 0.12 0.25 0.92  0.67 0.05    -0.81 0.02
--------------------------------------------------------------------------------------- 
: Training
: Feedback
   vars  n mean   sd median trimmed  mad  min  max range skew kurtosis   se
X1    1 50 0.48 0.17    0.5    0.48 0.12 0.08 0.92  0.83 0.23    -0.07 0.02
m4 <- lm(incidents ~ training + feedback + training:feedback, 
    data = df)
[1] 96
summary(m4)
[1] 97

Call:
lm(formula = incidents ~ training + feedback + training:feedback, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49333    0.02314  21.323  < 2e-16 ***
trainingTraining                  -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackFeedback                   0.09667    0.03272   2.954  0.00352 ** 
trainingTraining:feedbackFeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

interaction.plot(x.factor = df$training, trace.factor = df$feedback, 
    response = df$incidents, fun = mean, xlab = "Training conditions", 
    ylab = "Incidents", main = "Interaction plot between training and feedback", 
    trace.label = "Feedback conditions", type = "b", pch = (19), 
    lty = "solid", col = c("blue", "orange"))
[1] 98
qqPlot(m4)
[1] 99
hist(m4$residuals)
[1] 100
shapiro.test(m4$residuals)
[1] 101

	Shapiro-Wilk normality test

data:  m4$residuals
W = 0.9767, p-value = 0.002072

ncvTest(m4)
[1] 102
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.881673, Df = 1, p = 0.17014
durbinWatsonTest(m4)
[1] 103
 lag Autocorrelation D-W Statistic p-value
   1       0.1114255      1.770733   0.102
 Alternative hypothesis: rho != 0
vif(m4)
[1] 104
         training          feedback training:feedback 
                2                 2                 3 
cooks4 <- cooks.distance(m4)
[1] 105
which(cooks4 > (4/(200 - 3 - 1)))
[1] 106
  7  13  89 131 150 159 160 165 176 181 
  7  13  89 131 150 159 160 165 176 181 
plot(m4, which = 4)
[1] 107
m4a <- lm(incidents ~ training + feedback + training:feedback, 
    data = df[-c(13, 160, 176)])
[1] 108
summary(m4a)
[1] 109

Call:
lm(formula = incidents ~ training + feedback + training:feedback, 
    data = df[-c(13, 160, 176)])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49333    0.02314  21.323  < 2e-16 ***
trainingTraining                  -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackFeedback                   0.09667    0.03272   2.954  0.00352 ** 
trainingTraining:feedbackFeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

m4_coef <- summary(m4)
[1] 110
m4a_coef <- summary(m4a)
[1] 111
compare <- data.frame(round(m4_coef$coefficients[, 1], 3), round(m4_coef$coefficients[, 
    4], 4), round(m4a_coef$coefficients[, 1], 3), round(m4a_coef$coefficients[, 
    4], 4))
[1] 112
colnames(compare) <- c("M4 Coef", "M4 p-value", "M4a Coef", "M4a p-value")
[1] 113
compare

                                  M4 Coef M4 p-value M4a Coef M4a p-value
(Intercept)                         0.493     0.0000    0.493      0.0000
trainingTraining                   -0.160     0.0000   -0.160      0.0000
feedbackFeedback                    0.097     0.0035    0.097      0.0035
trainingTraining:feedbackFeedback   0.053     0.2505    0.053      0.2505


