

	####### B122719 R script #######

library(psych, quietly = T)
[1] 1
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(dplyr, quietly = T)
[1] 2
 [1] "dplyr"     "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[10] "base"     
library(Rcpp, quietly = T)
[1] 3
 [1] "Rcpp"      "dplyr"     "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(car, quietly = T)
[1] 4
 [1] "car"       "carData"   "Rcpp"      "dplyr"     "psych"     "readr"     "stats"     "graphics"  "grDevices"
[10] "utils"     "datasets"  "methods"   "base"     
library(pastecs, quietly = T)
[1] 5
 [1] "pastecs"   "car"       "carData"   "Rcpp"      "dplyr"     "psych"     "readr"     "stats"     "graphics" 
[10] "grDevices" "utils"     "datasets"  "methods"   "base"     
library(lsr, quietly = T)
[1] 6
 [1] "lsr"       "pastecs"   "car"       "carData"   "Rcpp"      "dplyr"     "psych"     "readr"     "stats"    
[10] "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 7
 [1] "lsr"       "pastecs"   "car"       "carData"   "Rcpp"      "dplyr"     "psych"     "readr"     "stats"    
[10] "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(corrplot, quietly = T)
[1] 8
 [1] "corrplot"  "lsr"       "pastecs"   "car"       "carData"   "Rcpp"      "dplyr"     "psych"     "readr"    
[10] "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(ggplot2, quietly = T)
[1] 9
 [1] "ggplot2"   "corrplot"  "lsr"       "pastecs"   "car"       "carData"   "Rcpp"      "dplyr"     "psych"    
[10] "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 10
 [1] "interactions" "ggplot2"      "corrplot"     "lsr"          "pastecs"      "car"          "carData"     
 [8] "Rcpp"         "dplyr"        "psych"        "readr"        "stats"        "graphics"     "grDevices"   
[15] "utils"        "datasets"     "methods"      "base"        
library(jtools, quietly = T)
[1] 11
 [1] "jtools"       "interactions" "ggplot2"      "corrplot"     "lsr"          "pastecs"      "car"         
 [8] "carData"      "Rcpp"         "dplyr"        "psych"        "readr"        "stats"        "graphics"    
[15] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(devtools, quietly = T)
[1] 12
 [1] "devtools"     "usethis"      "jtools"       "interactions" "ggplot2"      "corrplot"     "lsr"         
 [8] "pastecs"      "car"          "carData"      "Rcpp"         "dplyr"        "psych"        "readr"       
[15] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(sjPlot, quietly = T)
[1] 13
 [1] "sjPlot"       "devtools"     "usethis"      "jtools"       "interactions" "ggplot2"      "corrplot"    
 [8] "lsr"          "pastecs"      "car"          "carData"      "Rcpp"         "dplyr"        "psych"       
[15] "readr"        "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"     
[22] "base"        
data <- read.csv("../RMS2_report_1920.csv", header = T)
[1] 14
setwd("~/Desktop/Stats year 2")
[1] 15
describe(data)
[1] 16
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
str(data)
[1] 17
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
question1 <- data[, c(5:6)]
[1] 18
describe(question1)
[1] 19
        vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
empathy    1 200 10.18 2.54     10   10.24 2.97   3  16    13 -0.37     0.23 0.18
years      2 200  8.13 3.08      8    7.97 2.97   1  19    18  0.52     0.48 0.22
data$empathymean <- data$empathy - mean(data$empathy)
[1] 20
summary(question1)
[1] 21
    empathy          years      
 Min.   : 3.00   Min.   : 1.00  
 1st Qu.: 9.00   1st Qu.: 6.00  
 Median :10.00   Median : 8.00  
 Mean   :10.18   Mean   : 8.13  
 3rd Qu.:12.00   3rd Qu.:10.00  
 Max.   :16.00   Max.   :19.00  
describe(question1)
[1] 22
        vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se
empathy    1 200 10.18 2.54     10   10.24 2.97   3  16    13 -0.37     0.23 0.18
years      2 200  8.13 3.08      8    7.97 2.97   1  19    18  0.52     0.48 0.22
plot(data$years, data$empathymean, xlab = "years of experience", 
    ylab = "empathy score", pch = 16, )
[1] 23
qqnorm(data$years)
[1] 24
$x
 [1]  0.502949184 -0.488776411 -1.356311745 -0.474701147  1.091620367  0.517223714 -0.043880072  0.531604424
 [9] -0.460719309  0.221118713 -0.868720547  0.868720547 -0.446826965 -0.433020331 -0.419295753 -1.918876226
[17]  1.388450197 -0.405649708 -1.325516200  1.114651015  0.887146559 -1.722383890 -0.031337982 -0.392078788
[25] -0.378579699 -0.850584865 -0.365149249 -0.351784345 -0.832724719 -1.295928846 -0.338481986 -0.018800820
[33] -1.267434417  0.233980651  1.422090432 -1.239933478 -1.669592577 -1.213339622  0.905878812 -1.187577263
[41] -1.162579875  0.246881415  1.138288582 -1.621082251 -1.138288582 -0.006266612 -0.815126333 -0.797776846
[49] -0.780664237 -1.576111974
 [ reached getOption("max.print") -- omitted 150 entries ]

$y
 [1] 10  7  5  7 12 10  8 10  7  9  6 11  7  7  7  3 13  7  5 12 11  4  8  7  7  6  7  7  6  5  7  8  5  9 13  5  4
[38]  5 11  5  5  9 12  4  5  8  6  6  6  4
 [ reached getOption("max.print") -- omitted 150 entries ]

qqnorm(data$empathymean)
[1] 25
$x
 [1]  0.09413741 -0.39207879 -0.37857970 -0.78066424  0.50294918  0.10673401  1.06915463  1.35631175  0.51722371
[10]  0.53160442  0.11934757 -0.76377724 -0.74710530  0.54609593 -0.73063848 -2.00465446 -0.71436744 -0.69828337
[19] -0.36514925 -0.35178434 -0.33848199 -0.32523926 -0.31205332  0.56070303  0.13198014  0.57543077  0.14463381
[28]  0.59028439 -0.29892142 -1.91887623 -0.94433204  1.09162037 -0.68237794  0.60526941  1.11465101 -0.28584087
[37] -0.92493446  0.62039160  1.38845020 -1.45742174 -1.42209043  0.63565701  0.15731068 -1.38845020 -1.35631175
[46] -0.27280905  0.17001289  0.65107202 -0.66664331 -1.32551620
 [ reached getOption("max.print") -- omitted 150 entries ]

$y
 [1]  0.825 -0.175 -0.175 -1.175  1.825  0.825  2.825  3.825  1.825  1.825  0.825 -1.175 -1.175  1.825 -1.175 -5.175
[17] -1.175 -1.175 -0.175 -0.175 -0.175 -0.175 -0.175  1.825  0.825  1.825  0.825  1.825 -0.175 -5.175 -2.175  2.825
[33] -1.175  1.825  2.825 -0.175 -2.175  1.825  3.825 -3.175 -3.175  1.825  0.825 -3.175 -3.175 -0.175  0.825  1.825
[49] -1.175 -3.175
 [ reached getOption("max.print") -- omitted 150 entries ]

shapiro.test(data$years)
[1] 26

	Shapiro-Wilk normality test

data:  data$years
W = 0.97276, p-value = 0.0006279

shapiro.test(data$empathymean)
[1] 27

	Shapiro-Wilk normality test

data:  data$empathymean
W = 0.97073, p-value = 0.0003477

cov(data$years, data$empathymean, method = c("spearman"))
[1] 28
[1] 1012.956
cor.test(data$years, data$empathy, method = c("spearman"))
[1] 29

	Spearman's rank correlation rho

data:  data$years and data$empathy
S = 923838, p-value = 9.723e-06
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho 
0.3071045 

data$training <- as.factor(data$training)
[1] 30
str(data$training)
[1] 31
 Factor w/ 2 levels "1","2": 2 2 2 2 2 2 2 2 2 2 ...
NULL
summary(data$training)
[1] 32
  1   2 
100 100 
data$training <- factor(data$training, labels = c("no training", 
    "training"))
[1] 33
summary(data$training)
[1] 34
no training    training 
        100         100 
M1 <- lm(incidents ~ training + empathymean + years, data = data)
[1] 35
summary(M1)
[1] 36

Call:
lm(formula = incidents ~ training + empathymean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathymean       0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

cooks.distance(M1)
[1] 37
           1            2            3            4            5            6            7            8            9 
8.944216e-03 6.037640e-04 1.580166e-03 1.157586e-04 2.267305e-03 2.463011e-03 1.984548e-02 5.677361e-04 1.944568e-04 
          10           11           12           13           14           15           16           17           18 
8.352021e-03 1.128037e-02 4.313448e-06 3.236546e-02 1.944568e-04 4.507881e-03 1.199988e-02 5.292933e-03 3.038642e-04 
          19           20           21           22           23           24           25           26           27 
1.388896e-02 1.191856e-03 5.545830e-03 2.331353e-04 4.149247e-05 1.916593e-03 3.842138e-05 7.640178e-03 4.412825e-04 
          28           29           30           31           32           33           34           35           36 
2.090638e-03 6.876907e-06 1.807617e-02 9.838395e-05 1.163536e-04 9.397321e-04 3.097993e-05 3.081942e-02 6.774535e-05 
          37           38           39           40           41           42           43           44           45 
1.941980e-03 1.641118e-03 3.582645e-03 8.038933e-03 1.947800e-02 3.097993e-05 1.902071e-04 3.790865e-03 6.225899e-04 
          46           47           48           49           50 
2.110962e-03 2.233083e-03 1.764713e-03 1.280276e-03 1.044204e-02 
 [ reached getOption("max.print") -- omitted 150 entries ]
plot(cooks.distance(M1))
[1] 38
plot(M1, which = 4)
[1] 39
M1.1 <- lm(incidents ~ training + empathymean + years, data = data[-c(13, 
    74, 137)])
[1] 40
summary(M1.1)
[1] 41

Call:
lm(formula = incidents ~ training + empathymean + years, data = data[-c(13, 
    74, 137)])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathymean       0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

plot(M1, 1)
[1] 42
crPlots(M1)
[1] 43
residualPlots(M1)
[1] 44
durbinWatsonTest(M1)
[1] 45
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.158
 Alternative hypothesis: rho != 0
vif(M1)
[1] 46
   training empathymean       years 
   1.020633    1.092467    1.085089 
qqPlot(M1)
[1] 47
shapiro.test(M1$residuals)
[1] 48

	Shapiro-Wilk normality test

data:  M1$residuals
W = 0.97994, p-value = 0.005838

hist(M1$residuals)
[1] 49
ncvTest(M1)
[1] 50
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
log.incidents <- log(data$incidents + -1 * min(data$incidents) + 
    1)
[1] 51
M1a <- lm(log.incidents ~ training + empathymean + years, data = data)
[1] 52
summary(M1a)
[1] 53

Call:
lm(formula = log.incidents ~ training + empathymean + years, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.460852   0.026028  17.706  < 2e-16 ***
trainingtraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathymean       0.018550   0.003372   5.501 1.17e-07 ***
years            -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

qqPlot(M1a)
[1] 54
shapiro.test(M1a$residuals)
[1] 55

	Shapiro-Wilk normality test

data:  M1a$residuals
W = 0.9905, p-value = 0.2109

hist(M1a$residuals)
[1] 56
ncvTest(M1a)
[1] 57
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.036059, Df = 1, p = 0.30874
plot(M1a, 1)
[1] 58
crPlots(M1a)
[1] 59
residualPlots(M1a)
[1] 60
durbinWatsonTest(M1a)
[1] 61
 lag Autocorrelation D-W Statistic p-value
   1       -0.116516      2.217742   0.142
 Alternative hypothesis: rho != 0
vif(M1a)
[1] 62
   training empathymean       years 
   1.020633    1.092467    1.085089 
data$feedback <- as.factor(data$feedback)
[1] 63
data$feedback <- factor(data$feedback, labels = c("no feedback", 
    "feedback"))
[1] 64
summary(data$feedback)
[1] 65
no feedback    feedback 
        100         100 
M2 <- lm(incidents ~ feedback + empathymean + years, data = data)
[1] 66
summary(M2)
[1] 67

Call:
lm(formula = incidents ~ feedback + empathymean + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.512093   0.035846  14.286  < 2e-16 ***
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathymean       0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

cooks.distance(M2)
[1] 68
           1            2            3            4            5            6            7            8            9 
1.873002e-03 7.194706e-04 8.794665e-03 4.551627e-05 2.053035e-04 2.671890e-03 8.382252e-03 6.486186e-04 1.333265e-03 
          10           11           12           13           14           15           16           17           18 
8.551926e-03 3.550983e-03 2.393311e-05 1.576958e-02 1.501788e-04 3.180520e-04 1.315136e-02 1.995184e-02 4.199670e-04 
          19           20           21           22           23           24           25           26           27 
4.457524e-03 6.809539e-04 1.496142e-02 2.925582e-04 1.375906e-03 1.758325e-03 2.786451e-03 7.794658e-03 6.211162e-04 
          28           29           30           31           32           33           34           35           36 
2.218461e-03 2.579049e-03 1.922770e-02 3.676785e-03 8.607889e-05 7.066542e-03 6.336034e-05 1.007571e-02 1.087641e-04 
          37           38           39           40           41           42           43           44           45 
3.582766e-04 1.567128e-03 2.234738e-05 8.497195e-03 4.816737e-03 6.336034e-05 5.193219e-03 4.238396e-03 1.550410e-03 
          46           47           48           49           50 
2.276701e-03 2.026724e-06 1.650845e-03 1.995120e-04 1.091958e-02 
 [ reached getOption("max.print") -- omitted 150 entries ]
plot(cooks.distance(M2))
[1] 69
plot(M2, which = 4)
[1] 70
plot(M2, 5)
[1] 71
M2.2 <- lm(incidents ~ feedback + empathymean + years, data = data[-c(74, 
    89, 137)])
[1] 72
summary(M2.2)
[1] 73

Call:
lm(formula = incidents ~ feedback + empathymean + years, data = data[-c(74, 
    89, 137)])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.512093   0.035846  14.286  < 2e-16 ***
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathymean       0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

plot(M2, 1)
[1] 74
crPlots(M2)
[1] 75
residualPlots(M2)
[1] 76
ncvTest(M2)
[1] 77
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
durbinWatsonTest(M2)
[1] 78
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(M2)
[1] 79
   feedback empathymean       years 
   1.005211    1.079397    1.077467 
qqPlot(M2)
[1] 80
hist(M2$residuals)
[1] 81
shapiro.test(M2$residuals)
[1] 82

	Shapiro-Wilk normality test

data:  M2$residuals
W = 0.98772, p-value = 0.08174

BIC(M1a, M2)
[1] 83
    df       BIC
M1a  5 -273.4824
M2   5 -127.4675
AIC(M1a, M2)
[1] 84
    df       AIC
M1a  5 -289.9740
M2   5 -143.9591
trainingandfeedbackwithconfounds <- lm(incidents ~ training + 
    feedback + empathymean + years + training * feedback, data = data)
[1] 85
summary(trainingandfeedbackwithconfounds)
[1] 86

Call:
lm(formula = incidents ~ training + feedback + empathymean + 
    years + training * feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.637438   0.036309  17.556  < 2e-16 ***
trainingtraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackfeedback                   0.085558   0.029299   2.920  0.00391 ** 
empathymean                        0.028695   0.004328   6.630 3.25e-10 ***
years                             -0.015720   0.003518  -4.468 1.34e-05 ***
trainingtraining:feedbackfeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

cooks.distance(trainingandfeedbackwithconfounds)
[1] 87
           1            2            3            4            5            6            7            8            9 
6.098024e-03 3.530955e-05 8.401261e-03 3.001752e-03 9.144864e-05 4.738831e-04 1.589300e-02 2.138040e-04 7.248803e-04 
          10           11           12           13           14           15           16           17           18 
5.522340e-03 8.291397e-03 2.972169e-03 3.374707e-02 2.703540e-03 2.084847e-03 2.339903e-03 1.382228e-02 3.493265e-04 
          19           20           21           22           23           24           25           26           27 
9.882739e-03 8.477814e-03 1.507815e-02 5.817974e-04 7.818364e-04 7.571669e-03 2.333517e-03 3.886011e-03 1.672631e-04 
          28           29           30           31           32           33           34           35           36 
3.255841e-04 1.873516e-03 6.380355e-03 2.337533e-03 2.369321e-03 6.052129e-03 8.977552e-04 1.987897e-02 8.695217e-04 
          37           38           39           40           41           42           43           44           45 
1.770039e-05 6.755880e-03 2.535936e-04 2.664510e-03 1.179401e-02 8.977552e-04 3.261500e-03 2.688995e-04 2.270568e-04 
          46           47           48           49           50 
4.793762e-04 2.754126e-04 7.056800e-03 2.308944e-05 3.845940e-03 
 [ reached getOption("max.print") -- omitted 150 entries ]
plot(cooks.distance(trainingandfeedbackwithconfounds))
[1] 88
plot(trainingandfeedbackwithconfounds, which = 4)
[1] 89
qqPlot(trainingandfeedbackwithconfounds)
[1] 90
shapiro.test(trainingandfeedbackwithconfounds$residuals)
[1] 91

	Shapiro-Wilk normality test

data:  trainingandfeedbackwithconfounds$residuals
W = 0.98794, p-value = 0.08817

plot(trainingandfeedbackwithconfounds, 1)
[1] 92
plot(trainingandfeedbackwithconfounds$residuals)
[1] 93
residualPlots(trainingandfeedbackwithconfounds)
[1] 94
ncvTest(trainingandfeedbackwithconfounds)
[1] 95
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 4.398557, Df = 1, p = 0.035969
durbinWatsonTest(trainingandfeedbackwithconfounds)
[1] 96
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048   0.178
 Alternative hypothesis: rho != 0
catplotfeedbackandtraining <- cat_plot(trainingandfeedbackwithconfounds, 
    pred = training, modx = feedback)
[1] 97
catplotfeedbackandtraining



trainingandfeedbackwithoutinteraction <- lm(incidents ~ training + 
    feedback + empathymean + years, data = data)
[1] 99
summary(trainingandfeedbackwithoutinteraction)
[1] 100

Call:
lm(formula = incidents ~ training + feedback + empathymean + 
    years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.608620   0.034515  17.634  < 2e-16 ***
trainingtraining -0.153824   0.021128  -7.281 7.98e-12 ***
feedbackfeedback  0.133715   0.020968   6.377 1.28e-09 ***
empathymean       0.027191   0.004328   6.283 2.12e-09 ***
years            -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

