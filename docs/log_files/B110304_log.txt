

	####### B110304 R script #######

rm(list = ls())
[1] 1
setwd("~/hi")
[1] 2
data <- read.csv("../RMS2_report_1920.csv")
[1] 3
library(psych, quietly = T)
[1] 4
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(gdata, quietly = T)
[1] 5
 [1] "gdata"     "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[10] "base"     
library(car, quietly = T)
[1] 6
 [1] "car"       "carData"   "gdata"     "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"    
[10] "datasets"  "methods"   "base"     
library(interactions, quietly = T)
[1] 7
 [1] "interactions" "car"          "carData"      "gdata"        "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(sandwich, quietly = T)
[1] 8
 [1] "sandwich"     "interactions" "car"          "carData"      "gdata"        "psych"        "readr"       
 [8] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
which(data$years > 30)
[1] 9
integer(0)
which(data$empathy > 20)
[1] 10
integer(0)
which(data$incidents > 1)
[1] 11
integer(0)
describe(data)
[1] 12
          vars   n   mean    sd median trimmed   mad  min    max  range skew kurtosis   se
subject      1 200 100.50 57.88 100.50  100.50 74.13 1.00 200.00 199.00 0.00    -1.22 4.09
incidents    2 200   0.48  0.19   0.42    0.47  0.12 0.08   0.92   0.83 0.32    -0.31 0.01
training     3 200   1.50  0.50   1.50    1.50  0.74 1.00   2.00   1.00 0.00    -2.01 0.04
 [ reached 'max' / getOption("max.print") -- omitted 3 rows ]
as.factor(data$training)
[1] 13
 [1] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: 1 2
as.factor(data$feedback)
[1] 14
 [1] 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1 2 1
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: 1 2
data$training <- factor(data$training, labels = c("no training", 
    "training"))
[1] 15
summary(data$training)
[1] 16
no training    training 
        100         100 
data$feedback <- factor(data$feedback, labels = c("no feedback", 
    "feedback"))
[1] 17
summary(data$feedback)
[1] 18
no feedback    feedback 
        100         100 
data$empathy <- scale(data$empathy)
[1] 19
before <- lm(incidents ~ training + feedback + empathy + years, 
    data = data)
[1] 20
summary(before)
[1] 21

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31626 -0.10096 -0.00949  0.09165  0.46650 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.608620   0.034515  17.634  < 2e-16 ***
trainingtraining -0.153824   0.021128  -7.281 7.98e-12 ***
feedbackfeedback  0.133715   0.020968   6.377 1.28e-09 ***
empathy           0.068984   0.010980   6.283 2.12e-09 ***
years            -0.015199   0.003551  -4.281 2.92e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1479 on 195 degrees of freedom
Multiple R-squared:  0.3848,	Adjusted R-squared:  0.3721 
F-statistic: 30.49 on 4 and 195 DF,  p-value: < 2.2e-16

cooks <- cooks.distance(before)
[1] 22
names(which(cooks > (4/195)))
[1] 23
 [1] "13"  "35"  "74"  "117" "131" "137" "141" "156" "160" "176"
plot(before, which = 4)
[1] 24
after <- lm(incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 137, 176), ])
[1] 25
summary(after)
[1] 26

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 137, 176), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.31479 -0.10102 -0.00300  0.09041  0.35676 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.619020   0.033412  18.527  < 2e-16 ***
trainingtraining -0.153003   0.020113  -7.607 1.22e-12 ***
feedbackfeedback  0.132020   0.019981   6.607 3.76e-10 ***
empathy           0.073938   0.010573   6.993 4.34e-11 ***
years            -0.017169   0.003489  -4.921 1.85e-06 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.14 on 192 degrees of freedom
Multiple R-squared:  0.4232,	Adjusted R-squared:  0.4112 
F-statistic: 35.22 on 4 and 192 DF,  p-value: < 2.2e-16

hats <- hatvalues(before)
[1] 27
head(hats, 20)
[1] 28
         1          2          3          4          5          6          7          8          9         10 
0.01712163 0.01549576 0.02001541 0.01701625 0.02394476 0.01751286 0.02125280 0.02488761 0.01874782 0.01688360 
        11         12         13         14         15         16         17         18         19         20 
0.01833535 0.02484967 0.01655041 0.01759398 0.01655041 0.04465575 0.03320873 0.01701625 0.02001541 0.02623618 
which(hats > 2 * mean(hats))
[1] 29
 61  88  89  92 137 141 154 175 200 
 61  88  89  92 137 141 154 175 200 
after2 <- lm(incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 61, 88, 89, 92, 137, 141, 154, 175, 176, 
        200), ])
[1] 30
summary(after2)
[1] 31

Call:
lm(formula = incidents ~ training + feedback + empathy + years, 
    data = data[-c(13, 61, 88, 89, 92, 137, 141, 154, 175, 176, 
        200), ])

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32233 -0.09934 -0.00664  0.08943  0.35847 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.625018   0.037258  16.776  < 2e-16 ***
trainingtraining -0.153011   0.020815  -7.351 6.24e-12 ***
feedbackfeedback  0.137953   0.020620   6.690 2.60e-10 ***
empathy           0.075181   0.012256   6.134 5.12e-09 ***
years            -0.018121   0.004032  -4.494 1.23e-05 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.141 on 184 degrees of freedom
Multiple R-squared:  0.3975,	Adjusted R-squared:  0.3844 
F-statistic: 30.35 on 4 and 184 DF,  p-value: < 2.2e-16

m1 <- lm(empathy ~ years, data = data)
[1] 32
summary(m1)
[1] 33

Call:
lm(formula = empathy ~ years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.69717    0.19347  -3.603 0.000397 ***
years        0.08575    0.02226   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(data$empathy ~ data$years)
[1] 34
abline(lm(empathy ~ years, data = data))
[1] 35
lines(lowess(data$years, data$empathy))
[1] 36
cor.test(data$empathy, data$years, method = "spearman", exact = FALSE)
[1] 37

	Spearman's rank correlation rho

data:  data$empathy and data$years
S = 923838, p-value = 9.723e-06
alternative hypothesis: true rho is not equal to 0
sample estimates:
      rho 
0.3071045 

r <- cor(data$empathy, data$years, method = "spearman")
[1] 38
r * sqrt((200 - 2)/(1 - r^2))
[1] 39
         [,1]
[1,] 4.540772
plot(data$training, data$incidents, ylab = "incidents", xlab = "tranining or no training", 
    main = "incidents and training")
[1] 40
m2 <- lm(incidents ~ training + empathy + years, data = data)
[1] 41
summary(m2)
[1] 42

Call:
lm(formula = incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.064430   0.012014   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

qqPlot(m2$residuals)
[1] 43
hist(m2$residuals, main = "histogram of m2")
[1] 44
shapiro.test(m2$residuals)
[1] 45

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.97994, p-value = 0.005838

log.incidents <- log(data$incidents + (-1 * min(data$incidents) + 
    1))
[1] 46
summary(log.incidents)
[1] 47
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.0000  0.2231  0.2877  0.3216  0.4055  0.6061 
m2log <- lm(log.incidents ~ training + empathy + years, data = data)
[1] 48
summary(m2log)
[1] 49

Call:
lm(formula = log.incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.460852   0.026028  17.706  < 2e-16 ***
trainingtraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy           0.047061   0.008555   5.501 1.17e-07 ***
years            -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

hist(m2log$residuals, main = "histogram of m2log")
[1] 50
shapiro.test(m2log$residuals)
[1] 51

	Shapiro-Wilk normality test

data:  m2log$residuals
W = 0.9905, p-value = 0.2109

ncvTest(m2log)
[1] 52
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.036059, Df = 1, p = 0.30874
residualPlot(m2log)
[1] 53
durbinWatsonTest(m2log)
[1] 54
 lag Autocorrelation D-W Statistic p-value
   1       -0.116516      2.217742   0.158
 Alternative hypothesis: rho != 0
crPlots(m2log)
[1] 55
vif(m2log)
[1] 56
training  empathy    years 
1.020633 1.092467 1.085089 
m3 <- lm(log.incidents ~ feedback + empathy + years, data = data)
[1] 57
summary(m3)
[1] 58

Call:
lm(formula = log.incidents ~ feedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27663 -0.07576 -0.00237  0.08302  0.35261 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.349057   0.025597  13.637  < 2e-16 ***
feedbackfeedback  0.095615   0.016841   5.677 4.87e-08 ***
empathy           0.042942   0.008748   4.909 1.92e-06 ***
years            -0.009257   0.002839  -3.261  0.00131 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1188 on 196 degrees of freedom
Multiple R-squared:  0.2235,	Adjusted R-squared:  0.2116 
F-statistic:  18.8 on 3 and 196 DF,  p-value: 9.283e-11

plot(data$feedback, data$incidents, ylab = "interventions", xlab = "feedback or no feedback", 
    main = "feedback on incidents")
[1] 59
qqPlot(m3)
[1] 60
hist(m3$residuals)
[1] 61
residualPlot(m3)
[1] 62
durbinWatsonTest(m3)
[1] 63
 lag Autocorrelation D-W Statistic p-value
   1       0.2794347      1.431864       0
 Alternative hypothesis: rho != 0
shapiro.test(m3$residuals)
[1] 64

	Shapiro-Wilk normality test

data:  m3$residuals
W = 0.99572, p-value = 0.8487

crPlots(m3)
[1] 65
BIC(m2log, m3)
[1] 66
      df       BIC
m2log  5 -273.4824
m3     5 -262.1757
summary(m2log)
[1] 67

Call:
lm(formula = log.incidents ~ training + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27676 -0.08678 -0.00271  0.07438  0.35035 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.460852   0.026028  17.706  < 2e-16 ***
trainingtraining -0.111288   0.016497  -6.746 1.67e-10 ***
empathy           0.047061   0.008555   5.501 1.17e-07 ***
years            -0.010283   0.002769  -3.713 0.000266 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1155 on 196 degrees of freedom
Multiple R-squared:  0.2661,	Adjusted R-squared:  0.2549 
F-statistic: 23.69 on 3 and 196 DF,  p-value: 3.963e-13

summary(m3)
[1] 68

Call:
lm(formula = log.incidents ~ feedback + empathy + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.27663 -0.07576 -0.00237  0.08302  0.35261 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.349057   0.025597  13.637  < 2e-16 ***
feedbackfeedback  0.095615   0.016841   5.677 4.87e-08 ***
empathy           0.042942   0.008748   4.909 1.92e-06 ***
years            -0.009257   0.002839  -3.261  0.00131 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1188 on 196 degrees of freedom
Multiple R-squared:  0.2235,	Adjusted R-squared:  0.2116 
F-statistic:  18.8 on 3 and 196 DF,  p-value: 9.283e-11

m5 <- lm(log.incidents ~ training + feedback + training * feedback, 
    data = data)
[1] 69
summary(m5)
[1] 70

Call:
lm(formula = log.incidents ~ training + feedback + training * 
    feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32886 -0.07357  0.00614  0.07068  0.27727 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.33701    0.01649  20.442  < 2e-16 ***
trainingtraining                  -0.12001    0.02332  -5.147  6.4e-07 ***
feedbackfeedback                   0.06653    0.02332   2.853  0.00479 ** 
trainingtraining:feedbackfeedback  0.04534    0.03297   1.375  0.17072    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1166 on 196 degrees of freedom
Multiple R-squared:  0.252,	Adjusted R-squared:  0.2405 
F-statistic: 22.01 on 3 and 196 DF,  p-value: 2.515e-12

interaction.plot(data$training, data$feedback, log.incidents)
[1] 71
shapiro.test(m5$residuals)
[1] 72

	Shapiro-Wilk normality test

data:  m5$residuals
W = 0.98649, p-value = 0.05345

hist(m5$residuals)
[1] 73
qqPlot(m5$residuals)
[1] 74
ncvTest(m5)
[1] 75
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.04011943, Df = 1, p = 0.84125
durbinWatsonTest(m5)
[1] 76
 lag Autocorrelation D-W Statistic p-value
   1       0.1133615      1.766819   0.126
 Alternative hypothesis: rho != 0
vif(m5)
[1] 77
         training          feedback training:feedback 
                2                 2                 3 
summary(m5)
[1] 78

Call:
lm(formula = log.incidents ~ training + feedback + training * 
    feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.32886 -0.07357  0.00614  0.07068  0.27727 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.33701    0.01649  20.442  < 2e-16 ***
trainingtraining                  -0.12001    0.02332  -5.147  6.4e-07 ***
feedbackfeedback                   0.06653    0.02332   2.853  0.00479 ** 
trainingtraining:feedbackfeedback  0.04534    0.03297   1.375  0.17072    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1166 on 196 degrees of freedom
Multiple R-squared:  0.252,	Adjusted R-squared:  0.2405 
F-statistic: 22.01 on 3 and 196 DF,  p-value: 2.515e-12

