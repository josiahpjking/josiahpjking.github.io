

	####### B094170 R script #######

install.packages("car")
[1] 1
install.packages("lm.beta")
[1] 2
install.packages("interactions")
[1] 3
install.packages("ggplot2")
[1] 4
install.packages("psych")
[1] 5
install.packages("stats")
[1] 6
library(car, quietly = T)
[1] 7
 [1] "car"       "carData"   "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(lm.beta, quietly = T)
[1] 8
 [1] "lm.beta"   "car"       "carData"   "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"  
[11] "base"     
library(interactions, quietly = T)
[1] 9
 [1] "interactions" "lm.beta"      "car"          "carData"      "readr"        "stats"        "graphics"     "grDevices"   
 [9] "utils"        "datasets"     "methods"      "base"        
library(ggplot2, quietly = T)
[1] 10
 [1] "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "readr"        "stats"        "graphics"    
 [9] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(psych, quietly = T)
[1] 11
 [1] "psych"        "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "readr"        "stats"       
 [9] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(stats, quietly = T)
[1] 12
 [1] "psych"        "ggplot2"      "interactions" "lm.beta"      "car"          "carData"      "readr"        "stats"       
 [9] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
df <- read.csv(file = "~/Desktop/rms2/code_check/RMS2_report_1920.csv")
[1] 13
str(df)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
df$training <- factor(df$training, labels = c("No Training", 
    "Training"))
[1] 15
df$feedback <- factor(df$feedback, labels = c("No Feedback", 
    "Feedback"))
[1] 16
str(df)
[1] 17
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : Factor w/ 2 levels "No Training",..: 2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : Factor w/ 2 levels "No Feedback",..: 2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
levels(df$training)
[1] 18
[1] "No Training" "Training"   
levels(df$feedback)
[1] 19
[1] "No Feedback" "Feedback"   
table(df$training)
[1] 20

No Training    Training 
        100         100 
table(df$feedback)
[1] 21

No Feedback    Feedback 
        100         100 
which(is.na(df))
[1] 22
integer(0)
describe(df)[c(2, 5, 6), c(2:4, 8, 9, 11, 12)]
[1] 23
            n  mean   sd  min   max  skew kurtosis
incidents 200  0.48 0.19 0.08  0.92  0.32    -0.31
empathy   200 10.18 2.54 3.00 16.00 -0.37     0.23
years     200  8.13 3.08 1.00 19.00  0.52     0.48
par(mfrow = c(1, 2))
[1] 24
$mfrow
[1] 1 1

plot(df$empathy, df$incidents, xlab = "Empathy Score", ylab = "Incidents Reported", 
    main = "Scatterplot Empathy", pch = 16)
[1] 25
abline(lm(incidents ~ empathy, data = df), lwd = 3, col = "red")
[1] 26
plot(df$years, df$incidents, xlab = "Years", ylab = "Incidents Reported", 
    main = "Scatterplot Years", pch = 16)
[1] 27
abline(lm(incidents ~ years, data = df), lwd = 3, col = "green")
[1] 28
plot(df$training, df$incidents, xlab = "Training", ylab = "Incidents Reported", 
    main = "Boxplot Training")
[1] 29
plot(df$feedback, df$incidents, xlab = "Feedback", ylab = "Incidents Reported", 
    main = "Boxplot Feedback")
[1] 30
m1 <- lm(scale(empathy) ~ scale(years), data = df)
[1] 31
summary(m1)
[1] 32

Call:
lm(formula = scale(empathy) ~ scale(years), data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
               Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -3.419e-16  6.837e-02   0.000 1.000000    
scale(years)  2.640e-01  6.854e-02   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

summary(m1)$r.squared
[1] 33
[1] 0.0697155
leverage <- hatvalues(m1)
[1] 34
which(leverage > 2 * mean(leverage))
[1] 35
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
 61  88  89  92  94 108 109 116 131 137 140 141 154 155 163 190 200 
par(mfrow = c(1, 2))
[1] 36
$mfrow
[1] 1 2

cooks <- cooks.distance(m1)
[1] 37
which(cooks > (4/(200 - 1 - 1)))
[1] 38
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
 16  61  88  89  94 108 137 141 154 163 171 175 192 200 
plot(m1, which = 4)
[1] 39
par(mfrow = c(2, 2))
[1] 40
$mfrow
[1] 1 2

residualPlots(m1)
[1] 41
ncvTest(m1)
[1] 42
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.9815033, Df = 1, p = 0.32183
par(mfrow = c(1, 1))
[1] 43
$mfrow
[1] 2 2

crPlots(m1)
[1] 44
df$quad <- (scale(df$years))^2
[1] 45
m2 <- lm(scale(df$empathy) ~ scale(df$years) + df$quad)
[1] 46
summary(m2)
[1] 47

Call:
lm(formula = scale(df$empathy) ~ scale(df$years) + df$quad)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
                Estimate Std. Error t value Pr(>|t|)    
(Intercept)      0.38537    0.06599   5.840 2.13e-08 ***
scale(df$years)  0.46511    0.05824   7.986 1.13e-13 ***
df$quad         -0.38731    0.03685 -10.510  < 2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

summary(m2)$r.squared
[1] 48
[1] 0.4039514
sqrt(summary(m2)$r.squared)
[1] 49
[1] 0.6355717
0.4039514 - 0.0697155
[1] 50
[1] 0.3342359
leverage <- hatvalues(m2)
[1] 51
which(leverage > 2 * mean(leverage))
[1] 52
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
 16  61  88  89  92 116 137 141 154 155 165 171 190 200 
par(mfrow = c(1, 1))
[1] 53
$mfrow
[1] 1 1

cooks <- cooks.distance(m2)
[1] 54
which(cooks > (4/(200 - 1 - 1)))
[1] 55
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(m2, which = 4)
[1] 56
cov_rats <- covratio(m2)
[1] 57
which(cov_rats > 1.03)
[1] 58
 16  37  44  50  61  87  88  89  92  94 108 109 116 131 134 137 140 141 146 154 155 169 171 190 200 
 16  37  44  50  61  87  88  89  92  94 108 109 116 131 134 137 140 141 146 154 155 169 171 190 200 
which(cov_rats < 0.97)
[1] 59
 30  59  68  69  70  74  76 122 136 142 162 175 
 30  59  68  69  70  74  76 122 136 142 162 175 
residualPlots(m2)
[1] 60
ncvTest(m2)
[1] 61
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
par(mfrow = c(1, 2))
[1] 62
$mfrow
[1] 1 1

qqPlot(m2)
[1] 63
hist(m2$residuals)
[1] 64
shapiro.test(m2$residuals)
[1] 65

	Shapiro-Wilk normality test

data:  m2$residuals
W = 0.9941, p-value = 0.6155

durbinWatsonTest(m2)
[1] 66
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.802
 Alternative hypothesis: rho != 0
crPlots(m2)
[1] 67
par(mfrow = c(1, 1))
[1] 68
$mfrow
[1] 1 2

scatterplot(df$empathy ~ df$years, reg.line = TRUE, xlim = c(0, 
    20), ylim = c(0, 20), main = "Relationship between Empathy and Years", 
    xlab = "Years of Experience", ylab = "Empathy")
[1] 69
abline(lm(empathy ~ years, data = df), col = "blue", lwd = 3)
[1] 70
lines(lowess(df$years, df$empathy), col = "blue", lwd = 1)
[1] 71
m_training <- lm(incidents ~ training + empathy + years, data = df)
[1] 72
summary(m_training)
[1] 73

Call:
lm(formula = incidents ~ training + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

summary(m_training)$r.squared
[1] 74
[1] 0.2564555
leverage <- hatvalues(m_training)
[1] 75
which(leverage > 2 * mean(leverage))
[1] 76
 61  88  89  92  94 137 141 154 163 175 200 
 61  88  89  92  94 137 141 154 163 175 200 
par(mfrow = c(1, 1))
[1] 77
$mfrow
[1] 1 1

cooks <- cooks.distance(m_training)
[1] 78
which(cooks > (4/(200 - 3 - 1)))
[1] 79
 13  35  74 137 165 
 13  35  74 137 165 
plot(m_training, which = 4)
[1] 80
residualPlots(m_training)
[1] 81
ncvTest(m_training)
[1] 82
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
par(mfrow = c(1, 2))
[1] 83
$mfrow
[1] 1 1

qqPlot(m_training)
[1] 84
hist(m_training$residuals)
[1] 85
shapiro.test(m_training$residuals)
[1] 86

	Shapiro-Wilk normality test

data:  m_training$residuals
W = 0.97994, p-value = 0.005838

durbinWatsonTest(m_training)
[1] 87
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.194
 Alternative hypothesis: rho != 0
crPlots(m_training)
[1] 88
vif(m_training)
[1] 89
training  empathy    years 
1.020633 1.092467 1.085089 
m_feedback <- lm(incidents ~ feedback + empathy + years, data = df)
[1] 90
summary(m_feedback)
[1] 91

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276161   0.054108   5.104 7.84e-07 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy           0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

summary(m_feedback)$r.squared
[1] 92
[1] 0.2175265
leverage <- hatvalues(m_feedback)
[1] 93
which(leverage > 2 * mean(leverage))
[1] 94
 61  88  89  92 137 141 154 163 175 200 
 61  88  89  92 137 141 154 163 175 200 
par(mfrow = c(1, 1))
[1] 95
$mfrow
[1] 1 2

cooks <- cooks.distance(m_feedback)
[1] 96
which(cooks > (4/(200 - 3 - 1)))
[1] 97
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(m_feedback, which = 4)
[1] 98
residualPlots(m_feedback)
[1] 99
ncvTest(m_feedback)
[1] 100
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
par(mfrow = c(1, 2))
[1] 101
$mfrow
[1] 1 1

qqPlot(m_feedback)
[1] 102
hist(m_feedback$residuals)
[1] 103
shapiro.test(m_feedback$residuals)
[1] 104

	Shapiro-Wilk normality test

data:  m_feedback$residuals
W = 0.98772, p-value = 0.08174

durbinWatsonTest(m_feedback)
[1] 105
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
crPlots(m_feedback)
[1] 106
vif(m_feedback)
[1] 107
feedback  empathy    years 
1.005211 1.079397 1.077467 
AIC(m_training, m_feedback)
[1] 108
           df       AIC
m_training  5 -154.1654
m_feedback  5 -143.9591
BIC(m_training, m_feedback)
[1] 109
           df       BIC
m_training  5 -137.6738
m_feedback  5 -127.4675
m_training <- lm(incidents ~ training + empathy + years, data = df)
[1] 110
summary(m_training)
[1] 111

Call:
lm(formula = incidents ~ training + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.407320   0.051814   7.861 2.48e-13 ***
trainingTraining -0.152427   0.023166  -6.580 4.20e-10 ***
empathy           0.025396   0.004735   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

summary(m_training)$r.squared
[1] 112
[1] 0.2564555
m_feedback <- lm(incidents ~ feedback + empathy + years, data = df)
[1] 113
summary(m_feedback)
[1] 114

Call:
lm(formula = incidents ~ feedback + empathy + years, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.276161   0.054108   5.104 7.84e-07 ***
feedbackFeedback  0.132132   0.023585   5.602 7.09e-08 ***
empathy           0.023187   0.004829   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

summary(m_feedback)$r.squared
[1] 115
[1] 0.2175265
interaction <- lm(incidents ~ training + feedback + training * 
    feedback, data = df)
[1] 116
summary(interaction)
[1] 117

Call:
lm(formula = incidents ~ training + feedback + training * feedback, 
    data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49333    0.02314  21.323  < 2e-16 ***
trainingTraining                  -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackFeedback                   0.09667    0.03272   2.954  0.00352 ** 
trainingTraining:feedbackFeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

summary(interaction)$r.squared
[1] 118
[1] 0.2431263
par(mfrow = c(1, 1))
[1] 119
$mfrow
[1] 1 2

cat_plot(interaction, pred = training, modx = feedback, data = df, 
    geom = "line", interval = TRUE, pred.labels = c("No", "Yes"), 
    modx.labels = c("No", "Yes"), x.label = "Training", y.label = "Incidents Reported (%)", 
    main.title = "Interaction Plot with 95% Confidence Interval", 
    legend.main = "Feedback")
[1] 120
means_table <- describeBy(df$incidents, group = list(df$training, 
    df$feedback), mat = TRUE)
[1] 121
means_table <- means_table[, c(1, 2, 3, 5, 6)]
[1] 122
print(means_table, digits = 2)
[1] 123
    item      group1      group2  n mean
X11    1 No Training No Feedback 50 0.49
X12    2    Training No Feedback 50 0.33
X13    3 No Training    Feedback 50 0.59
X14    4    Training    Feedback 50 0.48
    item      group1      group2  n      mean
X11    1 No Training No Feedback 50 0.4933333
X12    2    Training No Feedback 50 0.3333333
X13    3 No Training    Feedback 50 0.5900000
X14    4    Training    Feedback 50 0.4833333
means_table

    item      group1      group2  n      mean
X11    1 No Training No Feedback 50 0.4933333
X12    2    Training No Feedback 50 0.3333333
X13    3 No Training    Feedback 50 0.5900000
X14    4    Training    Feedback 50 0.4833333


par(mfrow = c(1, 2))
[1] 125
$mfrow
[1] 1 1

cooks <- cooks.distance(interaction)
[1] 126
which(cooks > (4/(200 - 2 - 1)))
[1] 127
  7  13  89 131 150 159 160 165 176 181 
  7  13  89 131 150 159 160 165 176 181 
plot(interaction, which = 4)
[1] 128
residualPlots(interaction)
[1] 129
ncvTest(interaction)
[1] 130
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.881673, Df = 1, p = 0.17014
par(mfrow = c(1, 2))
[1] 131
$mfrow
[1] 1 2

qqPlot(interaction)
[1] 132
hist(interaction$residuals)
[1] 133
shapiro.test(interaction$residuals)
[1] 134

	Shapiro-Wilk normality test

data:  interaction$residuals
W = 0.9767, p-value = 0.002072

durbinWatsonTest(interaction)
[1] 135
 lag Autocorrelation D-W Statistic p-value
   1       0.1114255      1.770733   0.124
 Alternative hypothesis: rho != 0
inter_cov <- lm(incidents ~ training + feedback + years + empathy + 
    training * feedback, data = df)
[1] 136
summary(inter_cov)
[1] 137

Call:
lm(formula = incidents ~ training + feedback + years + empathy + 
    training * feedback, data = df)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.30367 -0.10365 -0.00795  0.08806  0.44359 

Coefficients:
                                   Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.345467   0.048515   7.121 2.04e-11 ***
trainingTraining                  -0.203496   0.029874  -6.812 1.18e-10 ***
feedbackFeedback                   0.085558   0.029299   2.920  0.00391 ** 
years                             -0.015720   0.003518  -4.468 1.34e-05 ***
empathy                            0.028695   0.004328   6.630 3.25e-10 ***
trainingTraining:feedbackFeedback  0.097334   0.041840   2.326  0.02103 *  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1462 on 194 degrees of freedom
Multiple R-squared:  0.4015,	Adjusted R-squared:  0.386 
F-statistic: 26.02 on 5 and 194 DF,  p-value: < 2.2e-16

summary(inter_cov)$r.squared
[1] 138
[1] 0.4014612
par(mfrow = c(1, 1))
[1] 139
$mfrow
[1] 1 2

cooks <- cooks.distance(inter_cov)
[1] 140
which(cooks > (4/(200 - 4 - 1)))
[1] 141
 13  73  74  89 117 137 160 165 176 
 13  73  74  89 117 137 160 165 176 
plot(inter_cov, which = 4)
[1] 142
residualPlots(inter_cov)
[1] 143
par(mfrow = c(1, 2))
[1] 144
$mfrow
[1] 1 1

qqPlot(inter_cov)
[1] 145
hist(inter_cov$residuals)
[1] 146
shapiro.test(inter_cov$residuals)
[1] 147

	Shapiro-Wilk normality test

data:  inter_cov$residuals
W = 0.98794, p-value = 0.08817

durbinWatsonTest(inter_cov)
[1] 148
 lag Autocorrelation D-W Statistic p-value
   1      0.09456969      1.801048    0.18
 Alternative hypothesis: rho != 0
