

	####### B109770 R script #######

install.packages("psych")
[1] 1
install.packages("car")
[1] 2
install.packages("interactions")
[1] 3
install.packages("lm.beta")
[1] 4
install.packages("ggplot2")
[1] 5
library(psych, quietly = T)
[1] 6
[1] "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets"  "methods"   "base"     
library(car, quietly = T)
[1] 7
 [1] "car"       "carData"   "psych"     "readr"     "stats"     "graphics"  "grDevices" "utils"     "datasets" 
[10] "methods"   "base"     
library(interactions, quietly = T)
[1] 8
 [1] "interactions" "car"          "carData"      "psych"        "readr"        "stats"        "graphics"    
 [8] "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(lm.beta, quietly = T)
[1] 9
 [1] "lm.beta"      "interactions" "car"          "carData"      "psych"        "readr"        "stats"       
 [8] "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
library(ggplot2, quietly = T)
[1] 10
 [1] "ggplot2"      "lm.beta"      "interactions" "car"          "carData"      "psych"        "readr"       
 [8] "stats"        "graphics"     "grDevices"    "utils"        "datasets"     "methods"      "base"        
data <- read.csv("../RMS2_report_1920.csv", header = T)
[1] 11
data

  subject incidents training feedback empathy years
1       1 0.6666667        2        2      11    10
2       2 0.3333333        2        1      10     7
3       3 0.3333333        2        2      10     5
4       4 0.4166667        2        1       9     7
5       5 0.5000000        2        2      12    12
6       6 0.2500000        2        1      11    10
7       7 0.8333333        2        2      13     8
8       8 0.4166667        2        1      14    10
 [ reached 'max' / getOption("max.print") -- omitted 192 rows ]


describe(data)[, c(2:4, 8, 9)]
[1] 13
            n   mean    sd  min    max
subject   200 100.50 57.88 1.00 200.00
incidents 200   0.48  0.19 0.08   0.92
training  200   1.50  0.50 1.00   2.00
feedback  200   1.50  0.50 1.00   2.00
empathy   200  10.18  2.54 3.00  16.00
years     200   8.13  3.08 1.00  19.00
str(data)
[1] 14
'data.frame':	200 obs. of  6 variables:
 $ subject  : int  1 2 3 4 5 6 7 8 9 10 ...
 $ incidents: num  0.667 0.333 0.333 0.417 0.5 ...
 $ training : int  2 2 2 2 2 2 2 2 2 2 ...
 $ feedback : int  2 1 2 1 2 1 2 1 2 1 ...
 $ empathy  : int  11 10 10 9 12 11 13 14 12 12 ...
 $ years    : int  10 7 5 7 12 10 8 10 7 9 ...
NULL
sum(is.na(data))
[1] 15
[1] 0
data$training <- factor(data$training, levels = c("1", "2"), 
    labels = c("no training", "training"))
[1] 16
data$feedback <- factor(data$feedback, levels = c("1", "2"), 
    labels = c("no feedback", "feedback"))
[1] 17
data$training
[1] 18
 [1] training training training training training training training training training training training training
[13] training training training training training training training training training training training training
[25] training training training training training training training training training training training training
[37] training training training training training training training training training training training training
[49] training training
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: no training training
data$feedback
[1] 19
 [1] feedback    no feedback feedback    no feedback feedback    no feedback feedback    no feedback feedback   
[10] no feedback feedback    no feedback feedback    no feedback feedback    no feedback feedback    no feedback
[19] feedback    no feedback feedback    no feedback feedback    no feedback feedback    no feedback feedback   
[28] no feedback feedback    no feedback feedback    no feedback feedback    no feedback feedback    no feedback
[37] feedback    no feedback feedback    no feedback feedback    no feedback feedback    no feedback feedback   
[46] no feedback feedback    no feedback feedback    no feedback
 [ reached getOption("max.print") -- omitted 150 entries ]
Levels: no feedback feedback
table(data$training, data$feedback)
[1] 20
             
              no feedback feedback
  no training          50       50
  training             50       50
M1 <- lm(scale(empathy) ~ years, data = data)
[1] 21
M1


Call:
lm(formula = scale(empathy) ~ years, data = data)

Coefficients:
(Intercept)        years  
   -0.69717      0.08575  



summary(M1)
[1] 23

Call:
lm(formula = scale(empathy) ~ years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-2.97192 -0.59754  0.02792  0.64474  2.30713 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) -0.69717    0.19347  -3.603 0.000397 ***
years        0.08575    0.02226   3.852 0.000158 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.9669 on 198 degrees of freedom
Multiple R-squared:  0.06972,	Adjusted R-squared:  0.06502 
F-statistic: 14.84 on 1 and 198 DF,  p-value: 0.0001582

plot(data$years, data$empathy, xlab = "Empathy (1=Low, 20=High)", 
    ylab = "Experience (years)", main = "Relationship between Empathy and Experience", 
    pch = 16)
[1] 24
abline(coefficients(M1))
[1] 25
plot(M1, which = 1)
[1] 26
M1a <- lm(scale(empathy) ~ years + I(years^2), data = data)
[1] 27
M1a


Call:
lm(formula = scale(empathy) ~ years + I(years^2), data = data)

Coefficients:
(Intercept)        years   I(years^2)  
   -3.54297      0.81532     -0.04085  



summary(M1a)
[1] 29

Call:
lm(formula = scale(empathy) ~ years + I(years^2), data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.77645 -0.55225 -0.03293  0.46143  2.38949 

Coefficients:
             Estimate Std. Error t value Pr(>|t|)    
(Intercept) -3.542969   0.312115  -11.35   <2e-16 ***
years        0.815324   0.071676   11.38   <2e-16 ***
I(years^2)  -0.040853   0.003887  -10.51   <2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.776 on 197 degrees of freedom
Multiple R-squared:  0.404,	Adjusted R-squared:  0.3979 
F-statistic: 66.75 on 2 and 197 DF,  p-value: < 2.2e-16

sqrt(0.06972)
[1] 30
[1] 0.2640455
cooks <- cooks.distance(M1a)
[1] 31
which(cooks > (4/(200 - 1 - 1)))
[1] 32
 61  89 137 141 154 163 165 175 
 61  89 137 141 154 163 165 175 
plot(M1a, which = 4)
[1] 33
abline(h = cooks.distance(M1a) > (4/(200 - 2 - 1)))
[1] 34
plot(M1a, which = 5)
[1] 35
qqPlot(M1a)
[1] 36
hist(M1a$residuals)
[1] 37
shapiro.test(M1a$residuals)
[1] 38

	Shapiro-Wilk normality test

data:  M1a$residuals
W = 0.9941, p-value = 0.6155

describe(residuals.lm(M1a))
[1] 39
   vars   n mean   sd median trimmed  mad   min  max range skew kurtosis   se
X1    1 200    0 0.77  -0.03       0 0.75 -1.78 2.39  4.17 0.09    -0.12 0.05
residualPlots(M1a)
[1] 40
ncvTest(M1a)
[1] 41
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.5107658, Df = 1, p = 0.47481
crPlots(M1a)
[1] 42
durbinWatsonTest(M1a)
[1] 43
 lag Autocorrelation D-W Statistic p-value
   1      0.01288905      1.973855   0.866
 Alternative hypothesis: rho != 0
M2 <- lm(data$incidents ~ training + scale(empathy) + years, 
    data = data)
[1] 44
M2


Call:
lm(formula = data$incidents ~ training + scale(empathy) + years, 
    data = data)

Coefficients:
     (Intercept)  trainingtraining    scale(empathy)             years  
         0.66572          -0.15243           0.06443          -0.01408  



summary(M2)
[1] 46

Call:
lm(formula = data$incidents ~ training + scale(empathy) + years, 
    data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35648 -0.12270 -0.01474  0.10105  0.53180 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.665721   0.036551  18.214  < 2e-16 ***
trainingtraining -0.152427   0.023166  -6.580 4.20e-10 ***
scale(empathy)    0.064430   0.012014   5.363 2.29e-07 ***
years            -0.014085   0.003889  -3.622 0.000372 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1621 on 196 degrees of freedom
Multiple R-squared:  0.2565,	Adjusted R-squared:  0.2451 
F-statistic: 22.53 on 3 and 196 DF,  p-value: 1.408e-12

plot(M2, which = 1)
[1] 47
cooks <- cooks.distance(M2)
[1] 48
which(cooks > (4/(200 - 3 - 1)))
[1] 49
 13  35  74 137 165 
 13  35  74 137 165 
plot(M2, which = 4)
[1] 50
abline(h = cooks.distance(M2) > (4/(200 - 3 - 1)), col = "pink")
[1] 51
plot(M2, which = 5)
[1] 52
qqPlot(M2)
[1] 53
hist(M2$residuals)
[1] 54
shapiro.test(M2$residuals)
[1] 55

	Shapiro-Wilk normality test

data:  M2$residuals
W = 0.97994, p-value = 0.005838

residualPlots(M2)
[1] 56
ncvTest(M2)
[1] 57
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.0293323, Df = 1, p = 0.86401
crPlots(M2)
[1] 58
durbinWatsonTest(M2)
[1] 59
 lag Autocorrelation D-W Statistic p-value
   1      -0.1072849      2.199897   0.206
 Alternative hypothesis: rho != 0
vif(M2)
[1] 60
      training scale(empathy)          years 
      1.020633       1.092467       1.085089 
M3 <- lm(incidents ~ feedback + scale(empathy) + years, data = data)
[1] 61
M3


Call:
lm(formula = incidents ~ feedback + scale(empathy) + years, data = data)

Coefficients:
     (Intercept)  feedbackfeedback    scale(empathy)             years  
         0.51209           0.13213           0.05883          -0.01269  



summary(M3)
[1] 63

Call:
lm(formula = incidents ~ feedback + scale(empathy) + years, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.35580 -0.11148 -0.01097  0.11092  0.53552 

Coefficients:
                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)       0.512093   0.035846  14.286  < 2e-16 ***
feedbackfeedback  0.132132   0.023585   5.602 7.09e-08 ***
scale(empathy)    0.058827   0.012251   4.802 3.11e-06 ***
years            -0.012689   0.003975  -3.192  0.00165 ** 
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1663 on 196 degrees of freedom
Multiple R-squared:  0.2175,	Adjusted R-squared:  0.2055 
F-statistic: 18.16 on 3 and 196 DF,  p-value: 1.933e-10

plot(M3, which = 1)
[1] 64
cooks <- cooks.distance(M3)
[1] 65
which(cooks > (4/(200 - 3 - 1)))
[1] 66
 73  74  89 137 156 160 165 176 
 73  74  89 137 156 160 165 176 
plot(M3, which = 4)
[1] 67
abline(h = cooks.distance(M3) > (4/(200 - 3 - 1)), col = "pink")
[1] 68
plot(M3, which = 5)
[1] 69
qqPlot(M3)
[1] 70
hist(M3$residuals)
[1] 71
shapiro.test(M3$residuals)
[1] 72

	Shapiro-Wilk normality test

data:  M3$residuals
W = 0.98772, p-value = 0.08174

residualPlots(M3)
[1] 73
ncvTest(M3)
[1] 74
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 0.01731234, Df = 1, p = 0.89532
crPlots(M3)
[1] 75
durbinWatsonTest(M3)
[1] 76
 lag Autocorrelation D-W Statistic p-value
   1       0.2738264      1.444081       0
 Alternative hypothesis: rho != 0
vif(M3)
[1] 77
      feedback scale(empathy)          years 
      1.005211       1.079397       1.077467 
BIC(M2, M3)
[1] 78
   df       BIC
M2  5 -137.6738
M3  5 -127.4675
M4 <- lm(incidents ~ training * feedback, data = data)
[1] 79
M4


Call:
lm(formula = incidents ~ training * feedback, data = data)

Coefficients:
                      (Intercept)                   trainingtraining                   feedbackfeedback  
                          0.49333                           -0.16000                            0.09667  
trainingtraining:feedbackfeedback  
                          0.05333  



summary(M4)
[1] 81

Call:
lm(formula = incidents ~ training * feedback, data = data)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.40000 -0.10500  0.00000  0.08333  0.43333 

Coefficients:
                                  Estimate Std. Error t value Pr(>|t|)    
(Intercept)                        0.49333    0.02314  21.323  < 2e-16 ***
trainingtraining                  -0.16000    0.03272  -4.890 2.09e-06 ***
feedbackfeedback                   0.09667    0.03272   2.954  0.00352 ** 
trainingtraining:feedbackfeedback  0.05333    0.04627   1.153  0.25047    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 0.1636 on 196 degrees of freedom
Multiple R-squared:  0.2431,	Adjusted R-squared:  0.2315 
F-statistic: 20.99 on 3 and 196 DF,  p-value: 7.827e-12

ggplot(data, aes(x = feedback, y = incidents, fill = training)) + 
    geom_boxplot()
[1] 82
cooks <- cooks.distance(M4)
[1] 83
which(cooks > (4/(200 - 3 - 1)))
[1] 84
  7  13  89 131 150 159 160 165 176 181 
  7  13  89 131 150 159 160 165 176 181 
plot(M4, which = 4)
[1] 85
abline(h = cooks.distance(M4) > (4/(200 - 3 - 1)), col = "pink")
[1] 86
plot(M4, which = 5)
[1] 87
qqPlot(M4)
[1] 88
hist(M4$residuals)
[1] 89
shapiro.test(M4$residuals)
[1] 90

	Shapiro-Wilk normality test

data:  M4$residuals
W = 0.9767, p-value = 0.002072

residualPlots(M4)
[1] 91
ncvTest(M4)
[1] 92
Non-constant Variance Score Test 
Variance formula: ~ fitted.values 
Chisquare = 1.881673, Df = 1, p = 0.17014
durbinWatsonTest(M4)
[1] 93
 lag Autocorrelation D-W Statistic p-value
   1       0.1114255      1.770733   0.116
 Alternative hypothesis: rho != 0
vif(M4)
[1] 94
         training          feedback training:feedback 
                2                 2                 3 
